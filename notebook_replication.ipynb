{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hanhluukim/replication-topic-modelling-in-embedding-space/blob/main/notebook_replication.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PJ7P852F7yzU"
      },
      "source": [
        "# **Das Projekt aus dem Github klonen und in den Projektsordner**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "riOxinNHJcIB",
        "outputId": "372ac7e4-b877-47ee-8b8e-d151b0304357"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Cloning into 'replication-topic-modelling-in-embedding-space'...\n",
            "remote: Enumerating objects: 271, done.\u001b[K\n",
            "remote: Counting objects: 100% (46/46), done.\u001b[K\n",
            "remote: Compressing objects: 100% (29/29), done.\u001b[K\n",
            "remote: Total 271 (delta 28), reused 35 (delta 17), pack-reused 225\u001b[K\n",
            "Receiving objects: 100% (271/271), 4.48 MiB | 6.67 MiB/s, done.\n",
            "Resolving deltas: 100% (138/138), done.\n"
          ]
        }
      ],
      "source": [
        "#wenn die Ordner noch nicht geklont ist, soll dieser Fehler zuerst durchgeführt werden.\n",
        "!git clone https://github.com/hanhluukim/replication-topic-modelling-in-embedding-space.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B_6em-5qJg5e",
        "outputId": "e78062d7-8c31-4fb1-ffd2-32004d0e985b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content/replication-topic-modelling-in-embedding-space\n"
          ]
        }
      ],
      "source": [
        "cd /content/replication-topic-modelling-in-embedding-space"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6AAG98vV1JCg"
      },
      "source": [
        "#**Die benötige Paketen für das Projekt mittels requirements.txt installieren**\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YcBay625sD5D",
        "outputId": "d3924bac-1de4-4a98-94c6-3667439c6f43"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: gensim in /usr/local/lib/python3.7/dist-packages (from -r /content/replication-topic-modelling-in-embedding-space/requirements.txt (line 1)) (3.6.0)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.7/dist-packages (from -r /content/replication-topic-modelling-in-embedding-space/requirements.txt (line 2)) (3.2.5)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from -r /content/replication-topic-modelling-in-embedding-space/requirements.txt (line 3)) (1.21.6)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from -r /content/replication-topic-modelling-in-embedding-space/requirements.txt (line 4)) (1.0.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from -r /content/replication-topic-modelling-in-embedding-space/requirements.txt (line 5)) (1.4.1)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.7/dist-packages (from -r /content/replication-topic-modelling-in-embedding-space/requirements.txt (line 6)) (1.11.0+cu113)\n",
            "Collecting transformers\n",
            "  Downloading transformers-4.18.0-py3-none-any.whl (4.0 MB)\n",
            "\u001b[K     |████████████████████████████████| 4.0 MB 5.1 MB/s \n",
            "\u001b[?25hCollecting umap-learn\n",
            "  Downloading umap-learn-0.5.3.tar.gz (88 kB)\n",
            "\u001b[K     |████████████████████████████████| 88 kB 4.6 MB/s \n",
            "\u001b[?25hCollecting plotly==5.7.0\n",
            "  Downloading plotly-5.7.0-py2.py3-none-any.whl (28.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 28.8 MB 5.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: pathlib in /usr/local/lib/python3.7/dist-packages (from -r /content/replication-topic-modelling-in-embedding-space/requirements.txt (line 10)) (1.0.1)\n",
            "Collecting pyyaml==5.4.1\n",
            "  Downloading PyYAML-5.4.1-cp37-cp37m-manylinux1_x86_64.whl (636 kB)\n",
            "\u001b[K     |████████████████████████████████| 636 kB 43.1 MB/s \n",
            "\u001b[?25hCollecting kaleido\n",
            "  Downloading kaleido-0.2.1-py2.py3-none-manylinux1_x86_64.whl (79.9 MB)\n",
            "\u001b[K     |████████████████████████████████| 79.9 MB 94 kB/s \n",
            "\u001b[?25hRequirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from plotly==5.7.0->-r /content/replication-topic-modelling-in-embedding-space/requirements.txt (line 9)) (1.15.0)\n",
            "Requirement already satisfied: tenacity>=6.2.0 in /usr/local/lib/python3.7/dist-packages (from plotly==5.7.0->-r /content/replication-topic-modelling-in-embedding-space/requirements.txt (line 9)) (8.0.1)\n",
            "Requirement already satisfied: smart-open>=1.2.1 in /usr/local/lib/python3.7/dist-packages (from gensim->-r /content/replication-topic-modelling-in-embedding-space/requirements.txt (line 1)) (6.0.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->-r /content/replication-topic-modelling-in-embedding-space/requirements.txt (line 4)) (3.1.0)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->-r /content/replication-topic-modelling-in-embedding-space/requirements.txt (line 4)) (1.1.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch->-r /content/replication-topic-modelling-in-embedding-space/requirements.txt (line 6)) (4.2.0)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers->-r /content/replication-topic-modelling-in-embedding-space/requirements.txt (line 7)) (4.11.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers->-r /content/replication-topic-modelling-in-embedding-space/requirements.txt (line 7)) (4.64.0)\n",
            "Collecting sacremoses\n",
            "  Downloading sacremoses-0.0.53.tar.gz (880 kB)\n",
            "\u001b[K     |████████████████████████████████| 880 kB 40.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers->-r /content/replication-topic-modelling-in-embedding-space/requirements.txt (line 7)) (2019.12.20)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers->-r /content/replication-topic-modelling-in-embedding-space/requirements.txt (line 7)) (21.3)\n",
            "Collecting tokenizers!=0.11.3,<0.13,>=0.11.1\n",
            "  Downloading tokenizers-0.12.1-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (6.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 6.6 MB 28.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers->-r /content/replication-topic-modelling-in-embedding-space/requirements.txt (line 7)) (3.6.0)\n",
            "Collecting huggingface-hub<1.0,>=0.1.0\n",
            "  Downloading huggingface_hub-0.5.1-py3-none-any.whl (77 kB)\n",
            "\u001b[K     |████████████████████████████████| 77 kB 5.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers->-r /content/replication-topic-modelling-in-embedding-space/requirements.txt (line 7)) (2.23.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers->-r /content/replication-topic-modelling-in-embedding-space/requirements.txt (line 7)) (3.0.8)\n",
            "Requirement already satisfied: numba>=0.49 in /usr/local/lib/python3.7/dist-packages (from umap-learn->-r /content/replication-topic-modelling-in-embedding-space/requirements.txt (line 8)) (0.51.2)\n",
            "Collecting pynndescent>=0.5\n",
            "  Downloading pynndescent-0.5.6.tar.gz (1.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.1 MB 34.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: llvmlite<0.35,>=0.34.0.dev0 in /usr/local/lib/python3.7/dist-packages (from numba>=0.49->umap-learn->-r /content/replication-topic-modelling-in-embedding-space/requirements.txt (line 8)) (0.34.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from numba>=0.49->umap-learn->-r /content/replication-topic-modelling-in-embedding-space/requirements.txt (line 8)) (57.4.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers->-r /content/replication-topic-modelling-in-embedding-space/requirements.txt (line 7)) (3.8.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers->-r /content/replication-topic-modelling-in-embedding-space/requirements.txt (line 7)) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers->-r /content/replication-topic-modelling-in-embedding-space/requirements.txt (line 7)) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers->-r /content/replication-topic-modelling-in-embedding-space/requirements.txt (line 7)) (2021.10.8)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers->-r /content/replication-topic-modelling-in-embedding-space/requirements.txt (line 7)) (3.0.4)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers->-r /content/replication-topic-modelling-in-embedding-space/requirements.txt (line 7)) (7.1.2)\n",
            "Building wheels for collected packages: umap-learn, pynndescent, sacremoses\n",
            "  Building wheel for umap-learn (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for umap-learn: filename=umap_learn-0.5.3-py3-none-any.whl size=82829 sha256=233f20d9bd1e3089dda02a68bf8ba7a40acb0f0b5315cfa0d8f20285098f3d42\n",
            "  Stored in directory: /root/.cache/pip/wheels/b3/52/a5/1fd9e3e76a7ab34f134c07469cd6f16e27ef3a37aeff1fe821\n",
            "  Building wheel for pynndescent (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pynndescent: filename=pynndescent-0.5.6-py3-none-any.whl size=53943 sha256=cfc50bc9bb8fb998f19ab1bff88d13999b531e107bb6b693ffa8362d6f57d3da\n",
            "  Stored in directory: /root/.cache/pip/wheels/03/f1/56/f80d72741e400345b5a5b50ec3d929aca581bf45e0225d5c50\n",
            "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sacremoses: filename=sacremoses-0.0.53-py3-none-any.whl size=895260 sha256=2ab1f7b4cb1b5baf919c4bf04c35464e805a162970033ae6bd6de5b958a1ee26\n",
            "  Stored in directory: /root/.cache/pip/wheels/87/39/dd/a83eeef36d0bf98e7a4d1933a4ad2d660295a40613079bafc9\n",
            "Successfully built umap-learn pynndescent sacremoses\n",
            "Installing collected packages: pyyaml, tokenizers, sacremoses, pynndescent, huggingface-hub, umap-learn, transformers, plotly, kaleido\n",
            "  Attempting uninstall: pyyaml\n",
            "    Found existing installation: PyYAML 3.13\n",
            "    Uninstalling PyYAML-3.13:\n",
            "      Successfully uninstalled PyYAML-3.13\n",
            "  Attempting uninstall: plotly\n",
            "    Found existing installation: plotly 5.5.0\n",
            "    Uninstalling plotly-5.5.0:\n",
            "      Successfully uninstalled plotly-5.5.0\n",
            "Successfully installed huggingface-hub-0.5.1 kaleido-0.2.1 plotly-5.7.0 pynndescent-0.5.6 pyyaml-5.4.1 sacremoses-0.0.53 tokenizers-0.12.1 transformers-4.18.0 umap-learn-0.5.3\n"
          ]
        }
      ],
      "source": [
        "# Falls die Packages noch nicht installiert wurden, \n",
        "!pip install -r \"/content/replication-topic-modelling-in-embedding-space/requirements.txt\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k7xiPgja8eZe"
      },
      "source": [
        "# **Gebrauchte Paketen importieren**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uV7KZhGq1P7g",
        "outputId": "30dcd895-49b6-42de-ee02-351ff5b439f1"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/distributed/config.py:20: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.\n",
            "  defaults = yaml.load(f)\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "from pathlib import Path\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "import umap.umap_ as umap\n",
        "import time\n",
        "import plotly.express as px\n",
        "from sklearn import cluster\n",
        "from sklearn import metrics"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QzWqQhPQdJWV"
      },
      "source": [
        "# **Vorverarbeitung und BOW-Repräsentationen für Textdaten durchführen**\n",
        "1. Vocabular erstellen\n",
        "2. BOW-Repräsentationen für allen Teildatensätzen"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "1OCULr82pfgk"
      },
      "outputs": [],
      "source": [
        "from src.preprare_dataset import TextDataLoader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cy0PpjxEpbrR",
        "outputId": "22657bc5-ad23-406e-9637-640e20fa5e99"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "loading texts: ...\n",
            "finished load!\n",
            "check some sample texts of the dataset\n",
            "['From', ':', 'lerxst', '@', 'wam', '.', 'umd', '.', 'edu', '(', \"where's\", 'my', 'thing', ')', 'Subject', ':', 'WHAT', 'car', 'is', 'this', '!', '?', 'Nntp', 'Posting', 'Host', ':', 'rac3', '.', 'wam', '.', 'umd', '.', 'edu', 'Organization', ':', 'University', 'of', 'Maryland', ',', 'College', 'Park', 'Lines', ':', '15', 'I', 'was', 'wondering', 'if', 'anyone', 'out', 'there', 'could', 'enlighten', 'me', 'on', 'this', 'car', 'I', 'saw', 'the', 'other', 'day', '.', 'It', 'was', 'a', '2', 'door', 'sports', 'car', ',', 'looked', 'to', 'be', 'from', 'the', 'late', '60s', '/', 'early', '70s', '.', 'It', 'was', 'called', 'a', 'Bricklin', '.', 'The', 'doors', 'were', 'really', 'small', '.', 'In', 'addition', ',', 'the', 'front', 'bumper', 'was', 'separate', 'from', 'the', 'rest', 'of', 'the', 'body', '.', 'This', 'is', 'all', 'I', 'know', '.', 'If', 'anyone', 'can', 'tellme', 'a', 'model', 'name', ',', 'engine', 'specs', ',', 'years', 'of', 'production', ',', 'where', 'this', 'car', 'is', 'made', ',', 'history', ',', 'or', 'whatever', 'info', 'you', 'have', 'on', 'this', 'funky', 'looking', 'car', ',', 'please', 'e', 'mail', '.', 'Thanks', ',', 'IL', 'brought', 'to', 'you', 'by', 'your', 'neighborhood', 'Lerxst']\n",
            "====================================================================================================\n",
            "['From', ':', 'guykuo', '@', 'carson', '.', 'u', '.', 'washington', '.', 'edu', '(', 'Guy', 'Kuo', ')', 'Subject', ':', 'SI', 'Clock', 'Poll', 'Final', 'Call', 'Summary', ':', 'Final', 'call', 'for', 'SI', 'clock', 'reports', 'Keywords', ':', 'SI', ',', 'acceleration', ',', 'clock', ',', 'upgrade', 'Article', 'I', '.', 'D', '.', ':', 'shelley', '.', '1qvfo9INNc3s', 'Organization', ':', 'University', 'of', 'Washington', 'Lines', ':', '11', 'NNTP', 'Posting', 'Host', ':', 'carson', '.', 'u', '.', 'washington', '.', 'edu', 'A', 'fair', 'number', 'of', 'brave', 'souls', 'who', 'upgraded', 'their', 'SI', 'clock', 'oscillator', 'have', 'shared', 'their', 'experiences', 'for', 'this', 'poll', '.', 'Please', 'send', 'a', 'brief', 'message', 'detailing', 'your', 'experiences', 'with', 'the', 'procedure', '.', 'Top', 'speed', 'attained', ',', 'CPU', 'rated', 'speed', ',', 'add', 'on', 'cards', 'and', 'adapters', ',', 'heat', 'sinks', ',', 'hour', 'of', 'usage', 'per', 'day', ',', 'floppy', 'disk', 'functionality', 'with', '800', 'and', '1', '.', '4', 'm', 'floppies', 'are', 'especially', 'requested', '.', 'I', 'will', 'be', 'summarizing', 'in', 'the', 'next', 'two', 'days', ',', 'so', 'please', 'add', 'to', 'the', 'network', 'knowledge', 'base', 'if', 'you', 'have', 'done', 'the', 'clock', 'upgrade', 'and', \"haven't\", 'answered', 'this', 'poll', '.', 'Thanks', '.', 'Guy', 'Kuo', '<', 'guykuo', '@', 'u', '.', 'washington', '.', 'edu', '>']\n",
            "====================================================================================================\n"
          ]
        }
      ],
      "source": [
        "# init TextDataLoader für die Datenquelle 20 News Groups\n",
        "# Daten abrufen vom Sklearn, tokenisieren und besondere Charaktern entfernen\n",
        "textsloader = TextDataLoader(source=\"20newsgroups\", train_size=None, test_size=None)\n",
        "textsloader.load_tokenize_texts(\"20newsgroups\")\n",
        "# Beispiel von Textdaten\n",
        "textsloader.show_example_raw_texts(n_docs=2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5odpQDJ7qPTt",
        "outputId": "415ba533-bdde-4e45-f1b3-4d642bb6b0d5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "start: preprocessing: ...\n",
            "finised: preprocessing!\n"
          ]
        }
      ],
      "source": [
        "# Vorverarbeitung von Daten mit folgenden Schritten:\n",
        "textsloader.preprocess_texts(length_one_remove=True, punctuation_lower = True, stopwords_filter = True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PRRCNPa9qXfq",
        "outputId": "5cbd27db-3d34-4e62-980e-a80a885edc88"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "permuted indices for the train set: [ 56  51  98 182 139  63 121  45  46  12 223 136  66 158  21]\n",
            "start creating vocabulary ...\n",
            "length of the vocabulary: 348\n",
            "sample ten words of the vocabulary: ['coming', 'understanding', 'cost', 'windows', 'world', 'engineering', 'question', 'light', 'takes', 'months']\n",
            "length word2id list: 348\n",
            "length id2word list: 348\n",
            "finished: creating vocabulary\n"
          ]
        }
      ],
      "source": [
        "# Daten zerlegen für Train, Test und Validation. Erstellen Vocabular aus dem Trainset\n",
        "textsloader.split_and_create_voca_from_trainset(max_df=0.7, min_df=10, stopwords_remove_from_voca=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "etzyjh_nqi19",
        "outputId": "f846d62e-a042-42a8-9abe-5883e099e45f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "length train-documents-indices : 4470\n",
            "length of the vocabulary: 348\n",
            "\n",
            "\n",
            "start: creating bow representation...\n",
            "top 10 - word-id of the doc: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
            "max word-id: 347\n",
            "min word-id: 0\n",
            "max doc-id: 149\n",
            "min doc-id: 0\n",
            "all docs: 4470\n",
            "all words: 4470\n",
            "docidx unique 150\n",
            "words unique: 348\n",
            "ndocs: 150\n",
            "vocab-size: 348\n",
            "finised creating bow input!\n",
            "\n",
            "start: creating bow representation...\n",
            "top 10 - word-id of the doc: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
            "max word-id: 347\n",
            "min word-id: 0\n",
            "max doc-id: 49\n",
            "min doc-id: 0\n",
            "all docs: 1465\n",
            "all words: 1465\n",
            "docidx unique 50\n",
            "words unique: 325\n",
            "ndocs: 50\n",
            "vocab-size: 348\n",
            "finised creating bow input!\n",
            "\n",
            "start: creating bow representation...\n",
            "top 10 - word-id of the doc: [3, 4, 5, 6, 9, 12, 13, 14, 15, 19]\n",
            "max word-id: 347\n",
            "min word-id: 3\n",
            "max doc-id: 49\n",
            "min doc-id: 0\n",
            "all docs: 719\n",
            "all words: 719\n",
            "docidx unique 50\n",
            "words unique: 240\n",
            "ndocs: 50\n",
            "vocab-size: 348\n",
            "finised creating bow input!\n",
            "\n",
            "start: creating bow representation...\n",
            "top 10 - word-id of the doc: [0, 1, 2, 3, 4, 6, 7, 8, 9, 10]\n",
            "max word-id: 347\n",
            "min word-id: 0\n",
            "max doc-id: 49\n",
            "min doc-id: 0\n",
            "all docs: 746\n",
            "all words: 746\n",
            "docidx unique 50\n",
            "words unique: 269\n",
            "ndocs: 50\n",
            "vocab-size: 348\n",
            "finised creating bow input!\n",
            "\n",
            "start: creating bow representation...\n",
            "top 10 - word-id of the doc: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
            "max word-id: 347\n",
            "min word-id: 0\n",
            "max doc-id: 99\n",
            "min doc-id: 0\n",
            "all docs: 3179\n",
            "all words: 3179\n",
            "docidx unique 100\n",
            "words unique: 348\n",
            "ndocs: 100\n",
            "vocab-size: 348\n",
            "finised creating bow input!\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Erstellen BOW-Repräsentation für ETM Modell\n",
        "for_lda_model = False \n",
        "word2id, id2word, train_set, test_set, val_set = textsloader.create_bow_and_savebow_for_each_set(for_lda_model=for_lda_model)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r-DXUMguC8zM"
      },
      "source": [
        "# **Vocabular und IDs anzeigen als Beispiel**\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "6RBJYhLHCfwy",
        "outputId": "99e7d90c-bc75-429a-8fd9-84d6a7e8d796"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-a1573c11-6165-4cd3-b303-82e15fd316bb\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>word</th>\n",
              "      <th>id</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>coming</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>understanding</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>cost</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>windows</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>world</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>95</th>\n",
              "      <td>public</td>\n",
              "      <td>95</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>96</th>\n",
              "      <td>good</td>\n",
              "      <td>96</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>97</th>\n",
              "      <td>early</td>\n",
              "      <td>97</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>98</th>\n",
              "      <td>small</td>\n",
              "      <td>98</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>99</th>\n",
              "      <td>gov</td>\n",
              "      <td>99</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>100 rows × 2 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-a1573c11-6165-4cd3-b303-82e15fd316bb')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-a1573c11-6165-4cd3-b303-82e15fd316bb button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-a1573c11-6165-4cd3-b303-82e15fd316bb');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "             word  id\n",
              "0          coming   0\n",
              "1   understanding   1\n",
              "2            cost   2\n",
              "3         windows   3\n",
              "4           world   4\n",
              "..            ...  ..\n",
              "95         public  95\n",
              "96           good  96\n",
              "97          early  97\n",
              "98          small  98\n",
              "99            gov  99\n",
              "\n",
              "[100 rows x 2 columns]"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# show for samples: 100 word2id and id2 word\n",
        "word2id_df_100 = pd.DataFrame()\n",
        "word2id_df_100['word'] = list(word2id.keys())[:100]\n",
        "word2id_df_100['id'] = list(word2id.values())[:100]\n",
        "word2id_df_100"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tupeI6Pw85_L"
      },
      "source": [
        "# **Die Größe von Datensätzen kontrollieren**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n1d-5ji3qwE8",
        "outputId": "51897353-66cb-4da5-83fc-f31402b606f9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Size of the vocabulary after prprocessing ist: 348\n",
            "Size of train set: 150\n",
            "Size of val set: 100\n",
            "Size of test set: 50\n"
          ]
        }
      ],
      "source": [
        "# Kontrollieren die Größen von verschiedenen Datensätzen\n",
        "print(f'Size of the vocabulary after prprocessing ist: {len(textsloader.vocabulary)}')\n",
        "print(f'Size of train set: {len(train_set[\"tokens\"])}')\n",
        "print(f'Size of val set: {len(val_set[\"tokens\"])}')\n",
        "print(f'Size of test set: {len(test_set[\"test\"][\"tokens\"])}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bxQL5jQtDb1c"
      },
      "source": [
        "# **Dokumenten wiederstellen für Word2Vec Embedding**\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "PDXEEBHfq3Cy",
        "outputId": "bc339332-5a3b-4fcd-d772-f2fdb92b9492"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-8b8ec72f-5801-450c-96cd-90bc5996f644\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text-after-preprocessing</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>washington keywords article nntp posting host ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>state university religion religion christian b...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>ac uk free distribution world department compu...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>nasa gov related nasa research center usa nntp...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>ca university love question bible long time qu...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>95</th>\n",
              "      <td>hp reply robert message apr nntp posting host ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>96</th>\n",
              "      <td>de point view reply de center university david...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>97</th>\n",
              "      <td>big nntp posting host university article write...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>98</th>\n",
              "      <td>info summary hard nntp posting host university...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>99</th>\n",
              "      <td>mark originator keywords nntp posting host rep...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>100 rows × 1 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-8b8ec72f-5801-450c-96cd-90bc5996f644')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-8b8ec72f-5801-450c-96cd-90bc5996f644 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-8b8ec72f-5801-450c-96cd-90bc5996f644');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "                             text-after-preprocessing\n",
              "0   washington keywords article nntp posting host ...\n",
              "1   state university religion religion christian b...\n",
              "2   ac uk free distribution world department compu...\n",
              "3   nasa gov related nasa research center usa nntp...\n",
              "4   ca university love question bible long time qu...\n",
              "..                                                ...\n",
              "95  hp reply robert message apr nntp posting host ...\n",
              "96  de point view reply de center university david...\n",
              "97  big nntp posting host university article write...\n",
              "98  info summary hard nntp posting host university...\n",
              "99  mark originator keywords nntp posting host rep...\n",
              "\n",
              "[100 rows x 1 columns]"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# re-erstellen von Dokumenten nach der Vorverarbeitungen. Die Dokumenten sind in Wörtern und werden für Word-Embedding Training benutzt\n",
        "docs_tr, docs_t, docs_v = textsloader.get_docs_in_words_for_each_set()\n",
        "train_docs_df = pd.DataFrame()\n",
        "train_docs_df['text-after-preprocessing'] = [' '.join(doc) for doc in docs_tr[:100]]\n",
        "train_docs_df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ds_KuUTQrK5P"
      },
      "source": [
        "# **Word-Embedding trainieren mit dem Traindatensatz**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KBexKIVf8Qs5",
        "outputId": "9ff25095-0127-4116-cdf6-984700601d4b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "word-embedding train begins\n",
            "word-embedding train finished\n",
            "length of vocabulary from word-embedding model 348\n",
            "length of the vocabulary of prepraring-dataset-vocabulary: 348\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 348/348 [00:00<00:00, 25088.40it/s]\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from src.embedding import WordEmbeddingCreator\n",
        "save_path = Path.joinpath(Path.cwd(), \"vocab_embedding.txt\")\n",
        "wb_creator = WordEmbeddingCreator(model_name=\"cbow\", documents = docs_tr, save_path= save_path)\n",
        "wb_creator.train(min_count=0, embedding_size= 10)\n",
        "vocab = list(word2id.keys())\n",
        "wb_creator.create_and_save_vocab_embedding(vocab, save_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f23xipx7MSV4",
        "outputId": "13bd0fd7-133f-4676-9990-b61a2dcd94c9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "word-embedding of the word-- washington: \n",
            "vector: [-0.0616175, 0.08143439, 0.055193506, -0.0573173, -0.007247365, -0.013431087, 0.07458643, -0.026739035, 0.0075050024, 0.11852459]\n",
            "dim of vector: 10\n"
          ]
        }
      ],
      "source": [
        "v = list(wb_creator.model.wv.vocab)[0]\n",
        "vec = list(wb_creator.model.wv.__getitem__(v))\n",
        "print(f'word-embedding of the word-- {v}: ')\n",
        "print(f'vector: {vec}')\n",
        "print(f'dim of vector: {len(vec)}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l53_jkUS-hl-"
      },
      "source": [
        "# **Word-Embeddings visualieren als Beispiel**\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "o96LsIWkNrZS"
      },
      "outputs": [],
      "source": [
        "# read word-embedding files\n",
        "with open(save_path) as f:\n",
        "  lines = f.readlines()\n",
        "embedding_data = []\n",
        "words_data = []\n",
        "for t in lines:\n",
        "  w = t.split(\"\\t\")[0]\n",
        "  v = [float(e) for e in t.split(\"\\t\")[1].split(\" \")]\n",
        "  words_data.append(w)\n",
        "  embedding_data.append(v)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "99hYOKPwB5aw",
        "outputId": "824a93e2-23f0-4dae-f64f-f75e2a03be9b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Cluster id labels for inputted data\n",
            "[0 6 9 1 9 1 7 0 6 6 6 6 5 6 7 8 5 2 5 8 5 5 3 5 9 1 5 3 4 3 1 7 0 7 9 8 7\n",
            " 1 4 9 5 3 7 1 1 4 6 4 9 6 1 5 0 0 4 2 5 5 5 9 2 6 3 0 1 9 6 3 8 5 7 1 5 3\n",
            " 3 9 7 1 0 2 6 5 1 2 3 7 8 5 8 6 2 4 7 8 2 4 1 2 8 7 7 9 3 5 7 4 5 0 6 0 7\n",
            " 8 6 4 1 0 8 0 8 1 2 8 0 2 2 2 4 4 1 3 0 3 1 2 5 2 5 4 5 6 3 4 4 8 0 0 5 3\n",
            " 5 3 7 4 2 8 3 2 1 8 1 1 5 5 5 5 4 2 8 4 2 2 3 1 6 1 3 7 5 1 8 5 7 2 8 1 8\n",
            " 5 7 4 0 3 1 0 4 8 8 1 7 8 3 6 1 2 3 3 7 2 2 0 4 3 2 7 4 1 3 1 4 7 1 2 3 7\n",
            " 1 6 1 2 1 3 4 6 1 0 7 8 2 0 2 2 4 6 7 8 1 0 1 6 5 0 2 4 6 0 2 2 2 2 4 2 2\n",
            " 1 8 0 9 6 1 6 9 1 4 7 7 4 6 3 7 2 1 6 6 4 3 8 0 7 8 2 2 2 8 3 6 0 4 6 1 2\n",
            " 4 5 4 4 1 1 6 2 2 0 4 6 8 3 2 8 2 7 7 4 4 7 0 2 2 2 2 8 8 4 4 2 8 6 2 6 7\n",
            " 2 2 8 0 0 0 5 2 7 3 3 1 7 2 2]\n",
            "Centroids data\n",
            "[[-0.0499181   0.07159634  0.00037833 -0.0186424   0.01913697 -0.03438601\n",
            "   0.06415873  0.00364077  0.0387983   0.12947281]\n",
            " [-0.05388258  0.13663567  0.05956406 -0.02224701  0.05255082 -0.06071362\n",
            "   0.06171536  0.0261201   0.07608133  0.25466873]\n",
            " [-0.02005033  0.03626464  0.00951518 -0.00351466  0.0160872  -0.01037013\n",
            "   0.01313288  0.00729842  0.02573019  0.06837327]\n",
            " [-0.01824662  0.05708713  0.051435   -0.0246985   0.02383532 -0.02308985\n",
            "   0.0305722   0.01424875  0.05994556  0.14644448]\n",
            " [-0.03588734  0.08717898 -0.00215366 -0.0105736   0.02597213 -0.03138298\n",
            "   0.00253092  0.00318411  0.06387041  0.12560094]\n",
            " [-0.07318392  0.10102182  0.0343192  -0.03012128  0.02927903 -0.03765215\n",
            "   0.05182248  0.03808959  0.07152507  0.19099526]\n",
            " [-0.0559486   0.1156518   0.01005565 -0.01044111  0.05546813 -0.06120478\n",
            "   0.02578901  0.0111661   0.07691755  0.21631199]\n",
            " [-0.02655098  0.1198536   0.04615365  0.00220087  0.03640989 -0.06409653\n",
            "   0.0595727   0.0300861   0.05802708  0.18118924]\n",
            " [-0.02624016  0.08043977  0.02948546 -0.01440057  0.03004285 -0.02749838\n",
            "   0.00733397  0.03562575  0.01214735  0.11072647]\n",
            " [-0.06017135  0.17174439  0.03612482 -0.00901944  0.08224985 -0.07525905\n",
            "   0.07324416  0.04072062  0.11850574  0.33868899]]\n"
          ]
        }
      ],
      "source": [
        "# clustering words with KMeans and Words-Vectors\n",
        "kmeans = cluster.KMeans(n_clusters=10)\n",
        "kmeans.fit(embedding_data)\n",
        " \n",
        "labels = kmeans.labels_\n",
        "centroids = kmeans.cluster_centers_\n",
        " \n",
        "print (\"Cluster id labels for inputted data\")\n",
        "print (labels)\n",
        "print (\"Centroids data\")\n",
        "print (centroids)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LAMgZ9aIE9A6",
        "outputId": "7a531806-142d-481e-f6e5-46613fec498d"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/numba/np/ufunc/parallel.py:363: NumbaWarning: The TBB threading layer requires TBB version 2019.5 or later i.e., TBB_INTERFACE_VERSION >= 11005. Found TBB_INTERFACE_VERSION = 9107. The TBB threading layer is disabled.\n",
            "  warnings.warn(problem)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Duration: 17.223621129989624 seconds\n"
          ]
        }
      ],
      "source": [
        "# dimension reduction with umap\n",
        "start = time.time()\n",
        "reducer = umap.UMAP(random_state=42,n_components=3)\n",
        "embedding = reducer.fit_transform(embedding_data)\n",
        "print('Duration: {} seconds'.format(time.time() - start))\n",
        "\n",
        "# show samples after dim-reduction in dataframe\n",
        "wb = pd.DataFrame(embedding, columns=['x', 'y', 'z'])\n",
        "wb['word'] = words_data\n",
        "wb['cluster'] = ['cluster ' + str(c) for c in labels]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 542
        },
        "id": "spomMOt_yy0W",
        "outputId": "5e762b64-348a-42fa-c93f-ddb21cea480b"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script src=\"https://cdn.plot.ly/plotly-2.11.1.min.js\"></script>                <div id=\"63476883-659e-4df8-bf8e-a909de01660b\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"63476883-659e-4df8-bf8e-a909de01660b\")) {                    Plotly.newPlot(                        \"63476883-659e-4df8-bf8e-a909de01660b\",                        [{\"hovertemplate\":\"cluster=cluster 0<br>x=%{x}<br>y=%{y}<br>z=%{z}<br>word=%{text}<extra></extra>\",\"legendgroup\":\"cluster 0\",\"marker\":{\"color\":\"#636efa\",\"symbol\":\"circle\"},\"mode\":\"markers+text\",\"name\":\"cluster 0\",\"scene\":\"scene\",\"showlegend\":true,\"text\":[\"washington\",\"figure\",\"simple\",\"clear\",\"support\",\"days\",\"cs\",\"lost\",\"bill\",\"wanted\",\"hold\",\"thought\",\"newsreader\",\"money\",\"making\",\"short\",\"send\",\"result\",\"called\",\"hope\",\"company\",\"california\",\"computing\",\"sort\",\"care\",\"key\",\"gun\",\"nice\",\"takes\",\"heard\",\"large\"],\"x\":[4.586956024169922,4.674012660980225,4.668649196624756,4.760767936706543,4.848241329193115,4.750986576080322,5.321506977081299,5.0400214195251465,5.564389705657959,4.471528053283691,4.6060051918029785,4.576556205749512,4.323995113372803,7.5501861572265625,5.958684921264648,4.66041898727417,4.473870277404785,4.685256004333496,7.113722324371338,5.039521217346191,6.005647659301758,4.073566913604736,4.066420078277588,6.145103931427002,4.6910624504089355,4.012448787689209,6.164378643035889,5.95898962020874,4.654075622558594,6.2425618171691895,4.787707805633545],\"y\":[4.710787773132324,5.8732829093933105,4.863770008087158,5.366110801696777,5.348331451416016,5.436799049377441,5.179896354675293,6.163722038269043,5.980121612548828,5.6329474449157715,5.467307090759277,5.46752405166626,5.138548374176025,4.803373336791992,6.316669940948486,6.214197635650635,4.87246036529541,4.788759708404541,5.412651062011719,5.253688812255859,6.23996114730835,6.078993797302246,5.695521831512451,4.890812397003174,4.716244220733643,5.9984540939331055,6.13375997543335,5.929169654846191,5.369492053985596,6.172304630279541,6.140993118286133],\"z\":[2.2264440059661865,1.6758378744125366,2.4612693786621094,1.6779457330703735,1.6391016244888306,1.6518123149871826,1.9885692596435547,2.110097885131836,3.8363354206085205,2.2619788646698,1.7779874801635742,1.8465821743011475,1.8766745328903198,3.2643532752990723,2.0735113620758057,2.258185863494873,2.0425736904144287,2.308631181716919,2.5298609733581543,1.8519642353057861,2.110280752182007,2.0813612937927246,1.8386303186416626,2.546025276184082,2.339770793914795,2.1565985679626465,2.0769925117492676,2.7895541191101074,1.7736010551452637,2.273469924926758,2.1223373413085938],\"type\":\"scatter3d\"},{\"hovertemplate\":\"cluster=cluster 6<br>x=%{x}<br>y=%{y}<br>z=%{z}<br>word=%{text}<extra></extra>\",\"legendgroup\":\"cluster 6\",\"marker\":{\"color\":\"#EF553B\",\"symbol\":\"circle\"},\"mode\":\"markers+text\",\"name\":\"cluster 6\",\"scene\":\"scene\",\"showlegend\":true,\"text\":[\"keywords\",\"things\",\"line\",\"case\",\"low\",\"based\",\"day\",\"jews\",\"computer\",\"gov\",\"mark\",\"fact\",\"live\",\"david\",\"phone\",\"run\",\"single\",\"months\",\"stuff\",\"understanding\",\"cost\",\"population\",\"au\",\"hear\",\"windows\",\"pc\",\"guy\",\"image\",\"software\",\"kind\",\"data\",\"problems\",\"ram\"],\"x\":[7.649211406707764,7.915447235107422,7.89447546005249,8.696931838989258,9.498880386352539,7.6226887702941895,8.795695304870605,9.09725570678711,7.8729472160339355,7.57787561416626,8.954364776611328,8.44348430633545,8.647195816040039,7.903147220611572,8.416961669921875,8.458744049072266,7.841064929962158,6.291560173034668,8.636608123779297,8.432573318481445,8.986083030700684,8.054254531860352,8.242085456848145,8.921795845031738,9.0588960647583,8.32665729522705,8.577330589294434,8.613019943237305,8.714700698852539,8.417482376098633,8.881572723388672,8.253230094909668,7.97169303894043],\"y\":[6.179211616516113,5.704257965087891,6.443931579589844,5.933316707611084,6.715803623199463,5.359947204589844,5.675543308258057,5.768647193908691,6.009004592895508,6.20384407043457,5.389590740203857,6.801419258117676,6.280206680297852,5.601014137268066,5.664003372192383,6.761168003082275,6.625865459442139,5.050694942474365,6.032814025878906,5.647290229797363,5.712724208831787,5.653162956237793,5.80453634262085,5.901871681213379,6.775669097900391,6.817137718200684,5.398523330688477,5.496868133544922,5.318353176116943,5.64778470993042,5.4991326332092285,6.722716331481934,6.385978698730469],\"z\":[3.1806676387786865,2.583616018295288,3.3102688789367676,3.1901357173919678,3.651444435119629,2.6838371753692627,3.075927495956421,3.396862030029297,3.0975422859191895,3.10675048828125,3.1307449340820312,3.354186534881592,3.8304409980773926,3.0792925357818604,3.1835172176361084,3.4176838397979736,2.9806931018829346,2.5172035694122314,3.0585429668426514,2.677993059158325,3.133629560470581,3.2487618923187256,2.827188491821289,3.2029786109924316,3.4454870223999023,3.2995243072509766,2.779142141342163,2.7184176445007324,4.226648807525635,2.685342788696289,2.954296827316284,3.202609062194824,2.8261523246765137],\"type\":\"scatter3d\"},{\"hovertemplate\":\"cluster=cluster 9<br>x=%{x}<br>y=%{y}<br>z=%{z}<br>word=%{text}<extra></extra>\",\"legendgroup\":\"cluster 9\",\"marker\":{\"color\":\"#00cc96\",\"symbol\":\"circle\"},\"mode\":\"markers+text\",\"name\":\"cluster 9\",\"scene\":\"scene\",\"showlegend\":true,\"text\":[\"article\",\"posting\",\"people\",\"university\",\"question\",\"god\",\"world\",\"nasa\",\"writes\",\"time\",\"john\",\"power\"],\"x\":[10.716984748840332,10.368475914001465,10.71334457397461,10.075472831726074,10.569089889526367,10.34656810760498,10.666661262512207,10.032997131347656,10.656292915344238,10.4246826171875,9.825265884399414,10.568605422973633],\"y\":[5.944976329803467,6.052108287811279,6.0431623458862305,5.794397354125977,5.942917823791504,5.906896591186523,6.0343337059021,6.08878231048584,5.98815393447876,5.964609146118164,6.138314723968506,5.924129962921143],\"z\":[4.317322254180908,4.456705570220947,4.34506893157959,3.978590726852417,4.287360191345215,4.183269023895264,4.401638507843018,4.170248508453369,4.375790119171143,4.2511701583862305,3.7958531379699707,4.275404453277588],\"type\":\"scatter3d\"},{\"hovertemplate\":\"cluster=cluster 1<br>x=%{x}<br>y=%{y}<br>z=%{z}<br>word=%{text}<extra></extra>\",\"legendgroup\":\"cluster 1\",\"marker\":{\"color\":\"#ab63fa\",\"symbol\":\"circle\"},\"mode\":\"markers+text\",\"name\":\"cluster 1\",\"scene\":\"scene\",\"showlegend\":true,\"text\":[\"nntp\",\"host\",\"drive\",\"open\",\"bible\",\"answer\",\"law\",\"make\",\"years\",\"reply\",\"news\",\"back\",\"work\",\"side\",\"call\",\"net\",\"version\",\"real\",\"put\",\"source\",\"access\",\"control\",\"file\",\"group\",\"thing\",\"year\",\"game\",\"important\",\"bit\",\"bad\",\"find\",\"book\",\"james\",\"program\",\"great\",\"number\",\"read\",\"board\",\"end\",\"give\",\"deleted\",\"life\",\"place\",\"memory\"],\"x\":[9.618029594421387,8.996538162231445,9.629722595214844,8.756590843200684,9.285593032836914,9.296574592590332,10.036518096923828,9.347539901733398,9.654101371765137,9.55797004699707,10.039484977722168,9.45068645477295,9.572307586669922,9.110062599182129,8.970897674560547,9.25687313079834,9.39826488494873,9.249049186706543,8.645119667053223,9.691751480102539,8.566502571105957,8.918960571289062,9.523580551147461,9.55334758758545,9.067543029785156,9.629794120788574,9.526226043701172,8.992992401123047,10.053746223449707,9.319066047668457,8.730348587036133,8.832968711853027,9.818401336669922,9.133233070373535,9.298991203308105,9.184951782226562,9.769981384277344,9.489100456237793,10.020105361938477,9.822677612304688,9.29851245880127,9.797828674316406,10.07468318939209,9.896138191223145],\"y\":[6.233372211456299,6.130650997161865,5.922245979309082,5.0414252281188965,5.553247928619385,5.57811164855957,6.173069000244141,6.012805461883545,5.791231155395508,6.713940620422363,6.063839912414551,5.706591606140137,6.238282203674316,5.296278476715088,6.097041606903076,5.669949531555176,6.125997066497803,5.82457971572876,6.302142143249512,6.551579475402832,5.188596725463867,6.121145725250244,5.841391086578369,6.243337631225586,5.329758644104004,6.373315811157227,5.895953178405762,5.654408931732178,5.892686367034912,5.652198791503906,5.2935333251953125,5.9180121421813965,6.6116042137146,5.381869316101074,5.651269912719727,5.6416168212890625,6.468541622161865,5.829320907592773,6.377968788146973,6.298284530639648,6.068679332733154,6.694731712341309,5.939042568206787,5.998048782348633],\"z\":[4.347155570983887,3.5831851959228516,4.128233909606934,4.275396347045898,4.551329612731934,4.668447494506836,4.006169319152832,4.042993068695068,4.683244705200195,3.694690465927124,4.566771030426025,4.649316310882568,4.161925315856934,4.531558036804199,3.8659911155700684,3.4284074306488037,4.466423988342285,3.814607858657837,4.066310405731201,3.912454843521118,4.308079719543457,4.238466262817383,3.5205955505371094,4.437642574310303,4.5677809715271,3.647736072540283,4.577189922332764,3.7955026626586914,4.401618957519531,4.524348258972168,4.242018222808838,4.521382808685303,3.932539701461792,4.0457611083984375,3.977323293685913,4.277286052703857,4.098463535308838,3.5748963356018066,4.007198810577393,3.935560703277588,4.370041370391846,3.904606580734253,4.3455328941345215,4.60361385345459],\"type\":\"scatter3d\"},{\"hovertemplate\":\"cluster=cluster 7<br>x=%{x}<br>y=%{y}<br>z=%{z}<br>word=%{text}<extra></extra>\",\"legendgroup\":\"cluster 7\",\"marker\":{\"color\":\"#FFA15A\",\"symbol\":\"circle\"},\"mode\":\"markers+text\",\"name\":\"cluster 7\",\"scene\":\"scene\",\"showlegend\":true,\"text\":[\"found\",\"speed\",\"small\",\"state\",\"christian\",\"lot\",\"usa\",\"sci\",\"made\",\"problem\",\"love\",\"long\",\"true\",\"post\",\"matter\",\"wrote\",\"dos\",\"person\",\"hand\",\"receive\",\"pretty\",\"man\",\"ago\",\"buy\",\"radio\",\"de\",\"guess\",\"today\",\"ibm\",\"cc\",\"code\",\"higher\",\"required\",\"mac\",\"coming\"],\"x\":[7.002748489379883,6.416642665863037,7.89125394821167,7.256211280822754,6.218045711517334,6.850764751434326,6.465915203094482,8.380040168762207,6.821518421173096,8.41420841217041,8.29686450958252,7.999732494354248,8.638100624084473,8.223392486572266,8.688153266906738,8.526939392089844,6.662250995635986,6.664849281311035,7.718489170074463,7.126220703125,6.338224411010742,8.269963264465332,7.687946319580078,7.296054840087891,6.653998374938965,6.9259538650512695,7.179506301879883,7.41674280166626,8.283632278442383,6.552734851837158,7.975488185882568,7.904568195343018,6.383233070373535,7.84626579284668,6.749850749969482],\"y\":[5.3861823081970215,6.408616065979004,6.317627429962158,5.717042922973633,5.166380405426025,5.279787063598633,5.628726005554199,5.385897159576416,6.148890495300293,6.127963542938232,4.8431501388549805,5.764495372772217,6.115306854248047,4.989899635314941,5.31876277923584,5.945664405822754,4.696775436401367,5.758768558502197,5.264472484588623,4.884069442749023,4.704390525817871,5.210878849029541,5.263553142547607,5.6057963371276855,5.674950122833252,5.892841339111328,5.860536575317383,4.956972122192383,5.287634372711182,5.189199924468994,5.456892967224121,4.84928560256958,4.851025104522705,4.9190449714660645,4.838273525238037],\"z\":[4.003540515899658,3.9834582805633545,3.677736759185791,2.7339839935302734,2.4038121700286865,3.6843161582946777,3.5725290775299072,3.625602960586548,4.024549961090088,3.700488328933716,3.8053317070007324,3.821352243423462,3.8320531845092773,3.9616520404815674,3.423269271850586,3.814366102218628,3.3713698387145996,3.3607490062713623,3.7923898696899414,3.28371262550354,3.2105894088745117,3.639983892440796,3.858085870742798,2.5697038173675537,3.537717819213867,3.6039745807647705,3.5104427337646484,3.1562535762786865,3.5757291316986084,3.669302463531494,3.658690929412842,3.8443825244903564,3.57832407951355,3.672135591506958,2.9794578552246094],\"type\":\"scatter3d\"},{\"hovertemplate\":\"cluster=cluster 5<br>x=%{x}<br>y=%{y}<br>z=%{z}<br>word=%{text}<extra></extra>\",\"legendgroup\":\"cluster 5\",\"marker\":{\"color\":\"#19d3f3\",\"symbol\":\"circle\"},\"mode\":\"markers+text\",\"name\":\"cluster 5\",\"scene\":\"scene\",\"showlegend\":true,\"text\":[\"part\",\"turn\",\"remember\",\"makes\",\"big\",\"times\",\"chip\",\"mind\",\"point\",\"uk\",\"free\",\"distribution\",\"center\",\"message\",\"robert\",\"add\",\"view\",\"considered\",\"email\",\"good\",\"system\",\"understand\",\"hard\",\"technology\",\"note\",\"information\",\"systems\",\"current\",\"talking\",\"couple\",\"sell\",\"list\",\"space\"],\"x\":[8.117042541503906,8.37641716003418,7.463292121887207,6.4998040199279785,8.303627967834473,8.42230224609375,8.230209350585938,8.308263778686523,8.774820327758789,6.686797618865967,6.670162200927734,6.96193790435791,8.629005432128906,8.069295883178711,6.283771514892578,6.823669910430908,6.260753631591797,8.426036834716797,8.173587799072266,8.328136444091797,8.55430793762207,5.344266414642334,8.427950859069824,8.2946195602417,6.47589111328125,7.536685943603516,8.398633003234863,7.34029483795166,7.535551071166992,6.855161666870117,7.62550163269043,8.541282653808594,8.606612205505371],\"y\":[6.3819966316223145,4.725055694580078,6.28229284286499,6.324836254119873,6.027865886688232,5.037822723388672,6.020334720611572,5.588868618011475,6.222014427185059,4.767740249633789,6.534722805023193,5.738794326782227,4.860184669494629,6.144043445587158,6.193421840667725,6.199210166931152,6.100371837615967,6.17274808883667,6.383697509765625,6.202856063842773,6.05421257019043,5.117882251739502,6.094862937927246,6.383326530456543,6.048512935638428,6.228228569030762,4.862963676452637,5.394757270812988,6.389965057373047,6.318115711212158,6.324106693267822,5.312236309051514,4.8902506828308105],\"z\":[4.027685165405273,3.5019826889038086,4.1130523681640625,4.211866855621338,3.3397302627563477,3.1454076766967773,3.0954132080078125,3.230461597442627,4.217538356781006,3.3516664505004883,3.662536859512329,2.468477725982666,4.098814964294434,4.038208484649658,4.19512939453125,4.04658842086792,4.011025428771973,3.3537728786468506,4.2619404792785645,3.902439594268799,4.367908477783203,2.1113250255584717,4.44084358215332,4.30216121673584,4.3264055252075195,4.093550682067871,3.35196852684021,2.589350461959839,2.935126543045044,4.046299457550049,4.172491550445557,3.092283010482788,4.136960983276367],\"type\":\"scatter3d\"},{\"hovertemplate\":\"cluster=cluster 8<br>x=%{x}<br>y=%{y}<br>z=%{z}<br>word=%{text}<extra></extra>\",\"legendgroup\":\"cluster 8\",\"marker\":{\"color\":\"#FF6692\",\"symbol\":\"circle\"},\"mode\":\"markers+text\",\"name\":\"cluster 8\",\"scene\":\"scene\",\"showlegend\":true,\"text\":[\"light\",\"idea\",\"religion\",\"research\",\"children\",\"show\",\"mine\",\"ca\",\"mike\",\"set\",\"possibly\",\"dod\",\"school\",\"reason\",\"late\",\"order\",\"posted\",\"toronto\",\"questions\",\"faster\",\"calls\",\"mentioned\",\"wondering\",\"left\",\"internet\",\"top\",\"laboratory\",\"full\",\"effect\",\"copy\",\"class\",\"design\",\"box\",\"form\"],\"x\":[3.7900965213775635,4.522529602050781,4.495676517486572,6.228309154510498,4.93345832824707,4.384852886199951,4.404632568359375,5.502904891967773,5.74366569519043,6.021503925323486,4.181812286376953,3.4783291816711426,4.906042098999023,6.213454246520996,4.105159282684326,4.390815734863281,4.423517227172852,6.103574752807617,4.643933296203613,4.825469493865967,4.428950309753418,4.3668928146362305,4.96864652633667,6.690893173217773,4.151376247406006,5.698331832885742,3.535637855529785,4.233379364013672,3.5842502117156982,4.724374771118164,5.067893981933594,3.7786002159118652,6.038924217224121,5.1955647468566895],\"y\":[5.470651149749756,4.844197750091553,5.0091447830200195,4.579545021057129,5.11790132522583,5.417087554931641,6.593792915344238,4.853204250335693,4.799356460571289,6.261504650115967,5.697834014892578,5.262725830078125,4.707299709320068,4.912585258483887,5.396571159362793,5.6461639404296875,5.103246688842773,4.829789638519287,5.3220930099487305,4.7493062019348145,5.460012435913086,5.369422435760498,4.747426986694336,5.6002655029296875,4.9034833908081055,4.880066871643066,5.226919174194336,4.988778591156006,5.609610080718994,5.07081937789917,4.84258508682251,5.322858810424805,4.7118611335754395,5.639153003692627],\"z\":[3.5545616149902344,3.6758692264556885,3.748250722885132,3.1372158527374268,3.7191696166992188,2.2014660835266113,3.190765857696533,2.807635545730591,2.7188775539398193,4.166348934173584,2.9814233779907227,3.4834980964660645,3.553091049194336,2.6180691719055176,2.363039016723633,3.0556061267852783,3.900500774383545,2.5718581676483154,3.954186201095581,3.538093328475952,3.6229465007781982,3.9695417881011963,3.4952714443206787,2.5271520614624023,3.6057510375976562,2.587920904159546,3.2370564937591553,3.610363006591797,3.583711624145508,3.0605251789093018,2.456509590148926,3.4364421367645264,3.416050434112549,4.1137871742248535],\"type\":\"scatter3d\"},{\"hovertemplate\":\"cluster=cluster 2<br>x=%{x}<br>y=%{y}<br>z=%{z}<br>word=%{text}<extra></extra>\",\"legendgroup\":\"cluster 2\",\"marker\":{\"color\":\"#B6E880\",\"symbol\":\"circle\"},\"mode\":\"markers+text\",\"name\":\"cluster 2\",\"scene\":\"scene\",\"showlegend\":true,\"text\":[\"gas\",\"ac\",\"department\",\"date\",\"interesting\",\"continue\",\"history\",\"home\",\"white\",\"engineering\",\"service\",\"dept\",\"ms\",\"east\",\"worse\",\"start\",\"technical\",\"hell\",\"disclaimer\",\"assuming\",\"opinion\",\"error\",\"fine\",\"canada\",\"reading\",\"job\",\"western\",\"agree\",\"religious\",\"institute\",\"easy\",\"advance\",\"tom\",\"corporation\",\"stop\",\"network\",\"texas\",\"division\",\"friend\",\"written\",\"told\",\"expressed\",\"exists\",\"display\",\"college\",\"sense\",\"originator\",\"claim\",\"application\",\"due\",\"project\",\"type\",\"simply\",\"taking\",\"miles\",\"minutes\"],\"x\":[3.6450576782226562,3.3961122035980225,3.5909712314605713,4.212096214294434,4.19785737991333,3.578289747238159,4.812832355499268,4.078929901123047,3.5859320163726807,3.7425127029418945,2.9745755195617676,3.5413761138916016,3.874873399734497,3.4350805282592773,3.0516366958618164,3.111732244491577,3.365344524383545,4.228030681610107,3.878228187561035,3.0748558044433594,3.411633253097534,3.3522162437438965,3.5840065479278564,3.114590644836426,3.212451457977295,3.2411932945251465,3.005178689956665,3.5612218379974365,3.348193407058716,3.129362106323242,2.985086679458618,3.4037652015686035,2.9632070064544678,4.040796756744385,4.141026020050049,3.3668084144592285,3.6936111450195312,3.092395782470703,4.022503852844238,4.427109718322754,4.451498508453369,3.23376727104187,3.804281711578369,3.1949574947357178,4.254202842712402,3.9131312370300293,3.1763265132904053,3.0497002601623535,3.4006426334381104,4.721757411956787,3.112720012664795,4.074722766876221,4.251302242279053,3.925508975982666,3.3027703762054443,3.1689891815185547],\"y\":[6.328731536865234,5.395105361938477,6.092319011688232,5.189760208129883,5.131245136260986,5.681857585906982,6.8003129959106445,5.130067825317383,6.042464733123779,5.510205268859863,5.992845058441162,5.894576549530029,5.1871337890625,5.5868940353393555,6.029910087585449,6.041492462158203,5.761684894561768,6.00549840927124,5.445581912994385,5.637621879577637,6.253718376159668,5.500871181488037,5.549237251281738,5.649913311004639,5.651256561279297,5.707014560699463,5.695175647735596,6.043103218078613,5.814175128936768,5.846930503845215,5.966063022613525,6.130832672119141,5.9358296394348145,6.545421600341797,5.727880001068115,6.03191614151001,5.630926609039307,6.2206244468688965,5.497551918029785,4.721715927124023,6.627304553985596,5.674488067626953,5.961924076080322,5.728449821472168,6.279622554779053,6.460261821746826,6.268497943878174,6.155250549316406,6.011626243591309,6.669579029083252,6.058948993682861,5.2199883460998535,5.383804798126221,6.169591903686523,5.663159370422363,6.230138778686523],\"z\":[2.1774306297302246,3.3892879486083984,3.6937644481658936,2.750485897064209,3.404794692993164,2.3266077041625977,3.425633192062378,3.0859851837158203,1.9335144758224487,3.907759666442871,3.0392982959747314,2.6621487140655518,2.1784565448760986,2.120701313018799,3.2216763496398926,3.420123338699341,2.8767096996307373,2.719177007675171,2.4032273292541504,2.762526273727417,3.479388475418091,2.4899864196777344,3.5301787853240967,3.197847366333008,2.6552884578704834,3.2977428436279297,2.7316553592681885,3.603475332260132,2.3774702548980713,2.5015926361083984,3.1692819595336914,3.6412010192871094,2.6729371547698975,2.610572576522827,3.392434597015381,2.3809869289398193,1.9604300260543823,2.703425645828247,2.325446367263794,2.3414292335510254,3.3422977924346924,2.8336570262908936,3.3976407051086426,3.3584516048431396,3.389526605606079,2.6247572898864746,2.775552272796631,2.7800889015197754,2.956148862838745,3.4614391326904297,3.364250898361206,2.828874349594116,3.9129903316497803,3.4574873447418213,3.0837783813476562,2.712453603744507],\"type\":\"scatter3d\"},{\"hovertemplate\":\"cluster=cluster 3<br>x=%{x}<br>y=%{y}<br>z=%{z}<br>word=%{text}<extra></extra>\",\"legendgroup\":\"cluster 3\",\"marker\":{\"color\":\"#FF97FF\",\"symbol\":\"circle\"},\"mode\":\"markers+text\",\"name\":\"cluster 3\",\"scene\":\"scene\",\"showlegend\":true,\"text\":[\"situation\",\"wrong\",\"high\",\"response\",\"science\",\"related\",\"apr\",\"steve\",\"results\",\"issue\",\"hp\",\"tin\",\"means\",\"price\",\"pay\",\"folks\",\"public\",\"opinions\",\"interested\",\"word\",\"disk\",\"card\",\"fax\",\"original\",\"sound\",\"rest\",\"international\",\"summary\",\"experience\",\"worth\",\"total\",\"truth\"],\"x\":[6.223259925842285,5.956744194030762,6.108024597167969,5.5288519859313965,7.288389682769775,6.031469821929932,6.133874893188477,6.102967262268066,5.779109001159668,6.017886161804199,6.306290626525879,5.301941871643066,6.304680347442627,4.899056911468506,5.434565544128418,5.090119361877441,6.018821716308594,6.784204483032227,4.7836833000183105,6.386542797088623,5.452445030212402,5.658559799194336,6.008791923522949,5.636415481567383,5.217965602874756,5.6110382080078125,5.3220415115356445,3.603663206100464,5.979495048522949,5.8015899658203125,3.943419933319092,5.541614055633545],\"y\":[4.974822044372559,6.043949604034424,6.029385089874268,6.34483003616333,5.329944133758545,5.752934455871582,5.936081886291504,6.388010501861572,4.831060886383057,5.840213298797607,4.644116401672363,4.97046422958374,5.93285608291626,6.123020648956299,5.136504173278809,6.22360897064209,5.867630481719971,6.274043083190918,6.325422286987305,4.643112659454346,6.589986801147461,5.156964302062988,5.63116455078125,6.2654619216918945,6.512611389160156,5.433122158050537,5.937086582183838,6.126614570617676,6.206516742706299,5.108808994293213,5.615711212158203,5.755679607391357],\"z\":[2.6264452934265137,4.0901288986206055,4.264888286590576,3.8532838821411133,3.1640987396240234,3.438061237335205,3.5659568309783936,3.9405014514923096,3.5888538360595703,3.6320295333862305,3.332651138305664,2.385645627975464,3.186210870742798,3.6641199588775635,3.472784996032715,3.8316826820373535,3.158106803894043,3.070401906967163,3.8026814460754395,3.1385858058929443,3.700587511062622,3.648498773574829,3.390080213546753,3.7744946479797363,3.6403682231903076,3.452528476715088,3.2102980613708496,2.7747247219085693,2.9355759620666504,3.552691698074341,1.9021152257919312,3.5718166828155518],\"type\":\"scatter3d\"},{\"hovertemplate\":\"cluster=cluster 4<br>x=%{x}<br>y=%{y}<br>z=%{z}<br>word=%{text}<extra></extra>\",\"legendgroup\":\"cluster 4\",\"marker\":{\"color\":\"#FECB52\",\"symbol\":\"circle\"},\"mode\":\"markers+text\",\"name\":\"cluster 4\",\"scene\":\"scene\",\"showlegend\":true,\"text\":[\"car\",\"interest\",\"parts\",\"references\",\"change\",\"major\",\"including\",\"sale\",\"bike\",\"info\",\"national\",\"rights\",\"jim\",\"sun\",\"numbers\",\"contact\",\"address\",\"city\",\"mail\",\"appreciated\",\"thinking\",\"strong\",\"feel\",\"front\",\"similar\",\"government\",\"asked\",\"common\",\"final\",\"org\",\"close\",\"write\",\"general\",\"early\",\"hardware\",\"week\",\"rate\",\"machine\"],\"x\":[5.731895923614502,5.583649635314941,3.736785411834717,5.527807712554932,5.591207027435303,5.432064056396484,4.875657558441162,5.555258750915527,6.323949337005615,5.301702976226807,4.906795024871826,5.567763328552246,5.753238677978516,4.930723190307617,4.767077922821045,5.2023396492004395,5.886946201324463,4.222316741943359,5.043562889099121,4.576394557952881,4.030163288116455,5.711654186248779,5.457942485809326,6.105857849121094,4.576572895050049,5.961281776428223,5.975913047790527,5.335541248321533,5.106429100036621,5.696157455444336,4.431183815002441,5.134068965911865,4.745650768280029,4.7278265953063965,5.849181175231934,4.660136699676514,4.263744831085205,5.75430154800415],\"y\":[6.46055269241333,6.634544372558594,6.254269123077393,6.662960052490234,6.449707508087158,6.181565761566162,6.833792209625244,6.2320404052734375,6.519163131713867,5.1081132888793945,6.8586273193359375,6.277658939361572,5.9442830085754395,6.46959114074707,6.387885570526123,6.765709400177002,6.440074443817139,6.4315924644470215,5.891732215881348,6.076080799102783,6.049755573272705,6.614531993865967,6.768389701843262,5.321822166442871,6.169588088989258,6.134120464324951,5.482616424560547,6.605262279510498,6.802794456481934,6.575100898742676,6.0529608726501465,6.833962440490723,6.859389781951904,6.8554511070251465,6.578019142150879,6.267324447631836,6.091526508331299,6.468846321105957],\"z\":[3.794100761413574,2.129340171813965,3.5307388305664062,2.481813907623291,2.0942904949188232,2.3840043544769287,2.7608752250671387,2.45780348777771,3.293346643447876,2.911536931991577,3.433090925216675,2.3500680923461914,2.6054978370666504,3.8381600379943848,2.359724998474121,2.216026544570923,2.1315882205963135,2.540503978729248,3.420685052871704,2.523545980453491,3.4043593406677246,2.6538326740264893,2.1745567321777344,2.3728387355804443,2.6185832023620605,2.3782663345336914,2.3782756328582764,2.0902669429779053,3.4054694175720215,2.3044512271881104,3.0792269706726074,3.3407697677612305,3.2277252674102783,2.938462018966675,2.2981984615325928,3.826430082321167,3.1700522899627686,2.319310188293457],\"type\":\"scatter3d\"}],                        {\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}},\"scene\":{\"domain\":{\"x\":[0.0,1.0],\"y\":[0.0,1.0]},\"xaxis\":{\"title\":{\"text\":\"x\"}},\"yaxis\":{\"title\":{\"text\":\"y\"}},\"zaxis\":{\"title\":{\"text\":\"z\"}}},\"legend\":{\"title\":{\"text\":\"cluster\"},\"tracegroupgap\":0},\"title\":{\"text\":\"word-embedding-samples\"}},                        {\"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('63476883-659e-4df8-bf8e-a909de01660b');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };                            </script>        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# visualization\n",
        "fig = px.scatter_3d(wb, \n",
        "                    text = wb['word'],\n",
        "                    x='x', y='y', z='z',\n",
        "                    color = wb['cluster'],\n",
        "                    title =\"word-embedding-samples\")\n",
        "fig.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P9jSI12r9zqu"
      },
      "source": [
        "# **ETM-Model trainieren**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fwiU9zWCIUh_",
        "outputId": "3e20f0b3-a90a-4fb4-c753-54ba01477fcd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "150\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 2., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 2., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 1., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1.,\n",
            "        1., 0., 0., 0., 0., 3., 0., 0., 2., 0., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 2., 0., 0., 0., 0.])\n"
          ]
        }
      ],
      "source": [
        "# using DocSet to use easier the modul DataSet from torch\n",
        "from src.train_etm import DocSet, ETMTrain\n",
        "from src.etm import ETM\n",
        "\n",
        "vocab_size = len(list(word2id.keys()))\n",
        "tr_set = DocSet(\"train\", vocab_size, train_set)\n",
        "print(len(tr_set))\n",
        "print(tr_set.__getitem__(0))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kbJIWLZpJRnG",
        "outputId": "c9e702ae-90dc-4b8f-aff2-ca24875336e5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "10\n",
            "Adam\n",
            "Defaulting to vanilla SGD\n",
            "Epoch 0/10:\n",
            "torch.Size([100])\n",
            "torch.Size([])\n",
            "total loss: 16049.3115234375\n",
            "Epoch 1/10:\n",
            "torch.Size([100])\n",
            "torch.Size([])\n",
            "total loss: 18193.31640625\n",
            "Epoch 2/10:\n",
            "torch.Size([100])\n",
            "torch.Size([])\n",
            "total loss: 18749.890625\n",
            "Epoch 3/10:\n",
            "torch.Size([100])\n",
            "torch.Size([])\n",
            "total loss: 18192.6796875\n",
            "Epoch 4/10:\n",
            "torch.Size([100])\n",
            "torch.Size([])\n",
            "total loss: 16852.69921875\n",
            "Epoch 5/10:\n",
            "torch.Size([100])\n",
            "torch.Size([])\n",
            "total loss: 18099.162109375\n",
            "Epoch 6/10:\n",
            "torch.Size([100])\n",
            "torch.Size([])\n",
            "total loss: 17802.39453125\n",
            "Epoch 7/10:\n",
            "torch.Size([100])\n",
            "torch.Size([])\n",
            "total loss: 16653.046875\n",
            "Epoch 8/10:\n",
            "torch.Size([100])\n",
            "torch.Size([])\n",
            "total loss: 17403.05859375\n",
            "Epoch 9/10:\n",
            "torch.Size([100])\n",
            "torch.Size([])\n",
            "total loss: 17507.982421875\n"
          ]
        }
      ],
      "source": [
        "num_topics = 5\n",
        "t_hidden_size = 100\n",
        "rho_size = len(embedding_data[0])\n",
        "emb_size = len(embedding_data[0])\n",
        "theta_act = \"relu\"\n",
        "\n",
        "class TrainArguments:\n",
        "      def __init__(self, epochs, batch_size, log_interval):\n",
        "          self.epochs = epochs\n",
        "          self.batch_size = batch_size\n",
        "          self.log_interval = log_interval\n",
        "\n",
        "class OptimizerArguments:\n",
        "      def __init__(self, optimizer_name, lr, wdecay):\n",
        "            self.optimizer = optimizer_name\n",
        "            self.lr = lr\n",
        "            self.wdecay = wdecay\n",
        "            \n",
        "train_args = TrainArguments(epochs=10, batch_size=100, log_interval=None)\n",
        "optimizer_args = OptimizerArguments(optimizer_name=\"Adam\", lr=0.005, wdecay=0.1)\n",
        "\n",
        "print(train_args.epochs)\n",
        "print(optimizer_args.optimizer)\n",
        "\n",
        "training_set = train_set\n",
        "\n",
        "# define the ETM-model with setting-parameters\n",
        "etm_model = ETM(\n",
        "      num_topics, \n",
        "      vocab_size, \n",
        "      t_hidden_size, rho_size, emb_size, theta_act, \n",
        "      embedding_data, enc_drop=0.5)\n",
        "\n",
        "# start training\n",
        "train_class = ETMTrain().train(\n",
        "    etm_model,\n",
        "    num_topics, \n",
        "    vocab_size, \n",
        "    train_args, optimizer_args, training_set, \n",
        "    t_hidden_size, rho_size, emb_size, theta_act, embedding_data, 0.5)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "include_colab_link": true,
      "name": "notebook_replication.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
