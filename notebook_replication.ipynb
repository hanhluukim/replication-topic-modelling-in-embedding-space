{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hanhluukim/replication-topic-modelling-in-embedding-space/blob/main/notebook_replication.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PJ7P852F7yzU"
      },
      "source": [
        "# **Das Projekt aus dem Github klonen und in den Projektsordner**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "riOxinNHJcIB",
        "outputId": "86af55bd-7fc6-44a1-c98b-cc1c6f3b8239"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'replication-topic-modelling-in-embedding-space'...\n",
            "remote: Enumerating objects: 400, done.\u001b[K\n",
            "remote: Counting objects: 100% (175/175), done.\u001b[K\n",
            "remote: Compressing objects: 100% (122/122), done.\u001b[K\n",
            "remote: Total 400 (delta 113), reused 108 (delta 51), pack-reused 225\u001b[K\n",
            "Receiving objects: 100% (400/400), 4.75 MiB | 5.81 MiB/s, done.\n",
            "Resolving deltas: 100% (223/223), done.\n"
          ]
        }
      ],
      "source": [
        "#wenn die Ordner noch nicht geklont ist, soll dieser Fehler zuerst durchgeführt werden.\n",
        "!git clone https://github.com/hanhluukim/replication-topic-modelling-in-embedding-space.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B_6em-5qJg5e",
        "outputId": "a05dc661-3347-4144-b4eb-c572d7423fad"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/replication-topic-modelling-in-embedding-space\n"
          ]
        }
      ],
      "source": [
        "cd /content/replication-topic-modelling-in-embedding-space"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6AAG98vV1JCg"
      },
      "source": [
        "#**Die benötige Paketen für das Projekt mittels requirements.txt installieren**\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YcBay625sD5D",
        "outputId": "24fa31d3-7d74-419f-e1d5-d32df099d618"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: gensim in /usr/local/lib/python3.7/dist-packages (from -r /content/replication-topic-modelling-in-embedding-space/requirements.txt (line 1)) (3.6.0)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.7/dist-packages (from -r /content/replication-topic-modelling-in-embedding-space/requirements.txt (line 2)) (3.2.5)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from -r /content/replication-topic-modelling-in-embedding-space/requirements.txt (line 3)) (1.21.6)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from -r /content/replication-topic-modelling-in-embedding-space/requirements.txt (line 4)) (1.0.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from -r /content/replication-topic-modelling-in-embedding-space/requirements.txt (line 5)) (1.4.1)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.7/dist-packages (from -r /content/replication-topic-modelling-in-embedding-space/requirements.txt (line 6)) (1.11.0+cu113)\n",
            "Collecting transformers\n",
            "  Downloading transformers-4.18.0-py3-none-any.whl (4.0 MB)\n",
            "\u001b[K     |████████████████████████████████| 4.0 MB 6.6 MB/s \n",
            "\u001b[?25hCollecting umap-learn\n",
            "  Downloading umap-learn-0.5.3.tar.gz (88 kB)\n",
            "\u001b[K     |████████████████████████████████| 88 kB 3.4 MB/s \n",
            "\u001b[?25hCollecting plotly==5.7.0\n",
            "  Downloading plotly-5.7.0-py2.py3-none-any.whl (28.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 28.8 MB 2.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: pathlib in /usr/local/lib/python3.7/dist-packages (from -r /content/replication-topic-modelling-in-embedding-space/requirements.txt (line 10)) (1.0.1)\n",
            "Collecting pyyaml==5.4.1\n",
            "  Downloading PyYAML-5.4.1-cp37-cp37m-manylinux1_x86_64.whl (636 kB)\n",
            "\u001b[K     |████████████████████████████████| 636 kB 42.5 MB/s \n",
            "\u001b[?25hCollecting kaleido\n",
            "  Downloading kaleido-0.2.1-py2.py3-none-manylinux1_x86_64.whl (79.9 MB)\n",
            "\u001b[K     |████████████████████████████████| 79.9 MB 85 kB/s \n",
            "\u001b[?25hRequirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from plotly==5.7.0->-r /content/replication-topic-modelling-in-embedding-space/requirements.txt (line 9)) (1.15.0)\n",
            "Requirement already satisfied: tenacity>=6.2.0 in /usr/local/lib/python3.7/dist-packages (from plotly==5.7.0->-r /content/replication-topic-modelling-in-embedding-space/requirements.txt (line 9)) (8.0.1)\n",
            "Requirement already satisfied: smart-open>=1.2.1 in /usr/local/lib/python3.7/dist-packages (from gensim->-r /content/replication-topic-modelling-in-embedding-space/requirements.txt (line 1)) (6.0.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->-r /content/replication-topic-modelling-in-embedding-space/requirements.txt (line 4)) (3.1.0)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->-r /content/replication-topic-modelling-in-embedding-space/requirements.txt (line 4)) (1.1.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch->-r /content/replication-topic-modelling-in-embedding-space/requirements.txt (line 6)) (4.2.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers->-r /content/replication-topic-modelling-in-embedding-space/requirements.txt (line 7)) (3.6.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers->-r /content/replication-topic-modelling-in-embedding-space/requirements.txt (line 7)) (2.23.0)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers->-r /content/replication-topic-modelling-in-embedding-space/requirements.txt (line 7)) (4.64.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers->-r /content/replication-topic-modelling-in-embedding-space/requirements.txt (line 7)) (21.3)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers->-r /content/replication-topic-modelling-in-embedding-space/requirements.txt (line 7)) (2019.12.20)\n",
            "Collecting sacremoses\n",
            "  Downloading sacremoses-0.0.53.tar.gz (880 kB)\n",
            "\u001b[K     |████████████████████████████████| 880 kB 44.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers->-r /content/replication-topic-modelling-in-embedding-space/requirements.txt (line 7)) (4.11.3)\n",
            "Collecting huggingface-hub<1.0,>=0.1.0\n",
            "  Downloading huggingface_hub-0.5.1-py3-none-any.whl (77 kB)\n",
            "\u001b[K     |████████████████████████████████| 77 kB 2.9 MB/s \n",
            "\u001b[?25hCollecting tokenizers!=0.11.3,<0.13,>=0.11.1\n",
            "  Downloading tokenizers-0.12.1-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (6.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 6.6 MB 42.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers->-r /content/replication-topic-modelling-in-embedding-space/requirements.txt (line 7)) (3.0.8)\n",
            "Requirement already satisfied: numba>=0.49 in /usr/local/lib/python3.7/dist-packages (from umap-learn->-r /content/replication-topic-modelling-in-embedding-space/requirements.txt (line 8)) (0.51.2)\n",
            "Collecting pynndescent>=0.5\n",
            "  Downloading pynndescent-0.5.6.tar.gz (1.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.1 MB 44.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from numba>=0.49->umap-learn->-r /content/replication-topic-modelling-in-embedding-space/requirements.txt (line 8)) (57.4.0)\n",
            "Requirement already satisfied: llvmlite<0.35,>=0.34.0.dev0 in /usr/local/lib/python3.7/dist-packages (from numba>=0.49->umap-learn->-r /content/replication-topic-modelling-in-embedding-space/requirements.txt (line 8)) (0.34.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers->-r /content/replication-topic-modelling-in-embedding-space/requirements.txt (line 7)) (3.8.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers->-r /content/replication-topic-modelling-in-embedding-space/requirements.txt (line 7)) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers->-r /content/replication-topic-modelling-in-embedding-space/requirements.txt (line 7)) (2021.10.8)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers->-r /content/replication-topic-modelling-in-embedding-space/requirements.txt (line 7)) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers->-r /content/replication-topic-modelling-in-embedding-space/requirements.txt (line 7)) (3.0.4)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers->-r /content/replication-topic-modelling-in-embedding-space/requirements.txt (line 7)) (7.1.2)\n",
            "Building wheels for collected packages: umap-learn, pynndescent, sacremoses\n",
            "  Building wheel for umap-learn (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for umap-learn: filename=umap_learn-0.5.3-py3-none-any.whl size=82829 sha256=17ec48d5998d153b551bf2ca078ad7b894a1e34b3723fb791ace7410c5f0ef52\n",
            "  Stored in directory: /root/.cache/pip/wheels/b3/52/a5/1fd9e3e76a7ab34f134c07469cd6f16e27ef3a37aeff1fe821\n",
            "  Building wheel for pynndescent (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pynndescent: filename=pynndescent-0.5.6-py3-none-any.whl size=53943 sha256=3ec949f00ac263342c82047517601ccd94ec9fc8444c353bd50d608466919a99\n",
            "  Stored in directory: /root/.cache/pip/wheels/03/f1/56/f80d72741e400345b5a5b50ec3d929aca581bf45e0225d5c50\n",
            "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sacremoses: filename=sacremoses-0.0.53-py3-none-any.whl size=895260 sha256=adc4ddf1ddb8fb187caac2e528e5ff6eb473d3854f8fa30d800cf2e53acfd833\n",
            "  Stored in directory: /root/.cache/pip/wheels/87/39/dd/a83eeef36d0bf98e7a4d1933a4ad2d660295a40613079bafc9\n",
            "Successfully built umap-learn pynndescent sacremoses\n",
            "Installing collected packages: pyyaml, tokenizers, sacremoses, pynndescent, huggingface-hub, umap-learn, transformers, plotly, kaleido\n",
            "  Attempting uninstall: pyyaml\n",
            "    Found existing installation: PyYAML 3.13\n",
            "    Uninstalling PyYAML-3.13:\n",
            "      Successfully uninstalled PyYAML-3.13\n",
            "  Attempting uninstall: plotly\n",
            "    Found existing installation: plotly 5.5.0\n",
            "    Uninstalling plotly-5.5.0:\n",
            "      Successfully uninstalled plotly-5.5.0\n",
            "Successfully installed huggingface-hub-0.5.1 kaleido-0.2.1 plotly-5.7.0 pynndescent-0.5.6 pyyaml-5.4.1 sacremoses-0.0.53 tokenizers-0.12.1 transformers-4.18.0 umap-learn-0.5.3\n"
          ]
        }
      ],
      "source": [
        "# Falls die Packages noch nicht installiert wurden, \n",
        "!pip install -r \"/content/replication-topic-modelling-in-embedding-space/requirements.txt\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k7xiPgja8eZe"
      },
      "source": [
        "# **Gebrauchte Paketen importieren**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uV7KZhGq1P7g",
        "outputId": "d2bf178c-a730-4ea9-a148-2e2efd1a3843"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/distributed/config.py:20: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.\n",
            "  defaults = yaml.load(f)\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "from pathlib import Path\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "import umap.umap_ as umap\n",
        "import time\n",
        "import plotly.express as px\n",
        "from sklearn import cluster\n",
        "from sklearn import metrics"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QzWqQhPQdJWV"
      },
      "source": [
        "# **Vorverarbeitung und BOW-Repräsentationen für Textdaten durchführen**\n",
        "1. Vocabular erstellen\n",
        "2. BOW-Repräsentationen für allen Teildatensätzen"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "1OCULr82pfgk"
      },
      "outputs": [],
      "source": [
        "from src.preprare_dataset import TextDataLoader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cy0PpjxEpbrR",
        "outputId": "1162e16a-2a4b-43e1-daa0-8c0276b7b958"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loading texts: ...\n",
            "finished load!\n",
            "check some sample texts of the dataset\n",
            "['From', ':', 'lerxst', '@', 'wam', '.', 'umd', '.', 'edu', '(', \"where's\", 'my', 'thing', ')', 'Subject', ':', 'WHAT', 'car', 'is', 'this', '!', '?', 'Nntp', 'Posting', 'Host', ':', 'rac3', '.', 'wam', '.', 'umd', '.', 'edu', 'Organization', ':', 'University', 'of', 'Maryland', ',', 'College', 'Park', 'Lines', ':', '15', 'I', 'was', 'wondering', 'if', 'anyone', 'out', 'there', 'could', 'enlighten', 'me', 'on', 'this', 'car', 'I', 'saw', 'the', 'other', 'day', '.', 'It', 'was', 'a', '2', 'door', 'sports', 'car', ',', 'looked', 'to', 'be', 'from', 'the', 'late', '60s', '/', 'early', '70s', '.', 'It', 'was', 'called', 'a', 'Bricklin', '.', 'The', 'doors', 'were', 'really', 'small', '.', 'In', 'addition', ',', 'the', 'front', 'bumper', 'was', 'separate', 'from', 'the', 'rest', 'of', 'the', 'body', '.', 'This', 'is', 'all', 'I', 'know', '.', 'If', 'anyone', 'can', 'tellme', 'a', 'model', 'name', ',', 'engine', 'specs', ',', 'years', 'of', 'production', ',', 'where', 'this', 'car', 'is', 'made', ',', 'history', ',', 'or', 'whatever', 'info', 'you', 'have', 'on', 'this', 'funky', 'looking', 'car', ',', 'please', 'e', 'mail', '.', 'Thanks', ',', 'IL', 'brought', 'to', 'you', 'by', 'your', 'neighborhood', 'Lerxst']\n",
            "====================================================================================================\n",
            "['From', ':', 'guykuo', '@', 'carson', '.', 'u', '.', 'washington', '.', 'edu', '(', 'Guy', 'Kuo', ')', 'Subject', ':', 'SI', 'Clock', 'Poll', 'Final', 'Call', 'Summary', ':', 'Final', 'call', 'for', 'SI', 'clock', 'reports', 'Keywords', ':', 'SI', ',', 'acceleration', ',', 'clock', ',', 'upgrade', 'Article', 'I', '.', 'D', '.', ':', 'shelley', '.', '1qvfo9INNc3s', 'Organization', ':', 'University', 'of', 'Washington', 'Lines', ':', '11', 'NNTP', 'Posting', 'Host', ':', 'carson', '.', 'u', '.', 'washington', '.', 'edu', 'A', 'fair', 'number', 'of', 'brave', 'souls', 'who', 'upgraded', 'their', 'SI', 'clock', 'oscillator', 'have', 'shared', 'their', 'experiences', 'for', 'this', 'poll', '.', 'Please', 'send', 'a', 'brief', 'message', 'detailing', 'your', 'experiences', 'with', 'the', 'procedure', '.', 'Top', 'speed', 'attained', ',', 'CPU', 'rated', 'speed', ',', 'add', 'on', 'cards', 'and', 'adapters', ',', 'heat', 'sinks', ',', 'hour', 'of', 'usage', 'per', 'day', ',', 'floppy', 'disk', 'functionality', 'with', '800', 'and', '1', '.', '4', 'm', 'floppies', 'are', 'especially', 'requested', '.', 'I', 'will', 'be', 'summarizing', 'in', 'the', 'next', 'two', 'days', ',', 'so', 'please', 'add', 'to', 'the', 'network', 'knowledge', 'base', 'if', 'you', 'have', 'done', 'the', 'clock', 'upgrade', 'and', \"haven't\", 'answered', 'this', 'poll', '.', 'Thanks', '.', 'Guy', 'Kuo', '<', 'guykuo', '@', 'u', '.', 'washington', '.', 'edu', '>']\n",
            "====================================================================================================\n"
          ]
        }
      ],
      "source": [
        "# init TextDataLoader für die Datenquelle 20 News Groups\n",
        "# Daten abrufen vom Sklearn, tokenisieren und besondere Charaktern entfernen\n",
        "textsloader = TextDataLoader(source=\"20newsgroups\", train_size=None, test_size=None)\n",
        "textsloader.load_tokenize_texts(\"20newsgroups\")\n",
        "# Beispiel von Textdaten\n",
        "textsloader.show_example_raw_texts(n_docs=2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5odpQDJ7qPTt",
        "outputId": "fe819fe5-97c9-4fd1-87fc-bb6deb1a4f3b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "start: preprocessing: ...\n",
            "finised: preprocessing!\n"
          ]
        }
      ],
      "source": [
        "# Vorverarbeitung von Daten mit folgenden Schritten:\n",
        "textsloader.preprocess_texts(length_one_remove=True, punctuation_lower = True, stopwords_filter = True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PRRCNPa9qXfq",
        "outputId": "c83749d6-5399-444e-c9db-fae565e7a61d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "test-document-frequency: \n",
            "[[ 18  17  11  13  18  10  13  20  17  22  15  19  19  10 162  18  10  15\n",
            "   43  17  10  23  10  12  25  14  13  38  11  12  14  17  22  61  12  33\n",
            "   27  11  11  17  16  14  34  11  31  20  14  11  13  16  11  11  10  11\n",
            "   12  12  18  13  10  19  10  17  12  14  10  63  12  14  13  11  28  14\n",
            "   14  11  22  20  51  18  10  10  22  13  25  24  19  18  11  11  10  13\n",
            "   21  21  14  10  16  13  12  74  13  13  10  10  11  19  13  11  11  15\n",
            "   11  31  26  16  14  10  10  11  13  36  10  20  20  13  14  11  43  13\n",
            "   14  12  22  20  13  15  14  16  10  11  13  16  22  22  54  17  17  11\n",
            "   31  10  27  18  10  20  20  10  16  27  14  11  11  24  13  20  10  14\n",
            "   12  17  15 158  12  16  13  20  10  12  14  18  10  11  23  26  12  10\n",
            "   15  12  14  21  12  21  12  12  15  10  25  14  32  21  13  14  18  11\n",
            "   17  10  21  10  24  12  24  12  15  12  32  11  12  11  25  15  15  11\n",
            "   14  15  30  36  21  60  15  11  14  20  16  24  10  18  12  24  11  12\n",
            "   10  19  17  11  10  19  20  10  12  17  25  10  21  15  35  23  16  10\n",
            "  157  14  32  15  11  15  14  26  13  16  13  10  27  14  10  11  13  75\n",
            "   11  11  11  23  25  10  13  10  38  10  10  29  18 163  22  13  18  48\n",
            "   27  23  13  16  27  48  10  10  15  10  10  10  30  11  33  18  10  12\n",
            "   10  10  12  10  17  10  24  76  12  21  15  12  14  13  11  10  16  27\n",
            "   11  11  10  18  27  11  16  14  14  19  12  13  16  11  17  12  17  12\n",
            "   17  26  13  11  15  19  10  21  12  16  11  41  20  12  11  14  12  20\n",
            "   22  18  15  10  37  21  12  14  15  11  11  24  13  35  31  12  27  76\n",
            "   22  19  23  13  13  12  18  12  30  11  18  11  11  11  22  18  12 150\n",
            "   55  33  18  12  10  13  13  16  10  14  14  11  23  14  17  11  35  57\n",
            "   11  11  16 175  12  21  28  10  28  37]]\n",
            "vocab-size in df: 424\n",
            "start creating vocabulary ...\n",
            "length of the vocabulary: 422\n",
            "sample ten words of the vocabulary: ['cmu', 'support', 'greater', 'asked', 'good', 'program', 'host', 'pretty', 'calls', 'interested']\n",
            "length word2id list: 422\n",
            "length id2word list: 422\n",
            "finished: creating vocabulary\n"
          ]
        }
      ],
      "source": [
        "# Daten zerlegen für Train, Test und Validation. Erstellen Vocabular aus dem Trainset\n",
        "textsloader.split_and_create_voca_from_trainset(max_df=0.7, min_df=10, stopwords_remove_from_voca=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "etzyjh_nqi19",
        "outputId": "c2e0600d-1708-431e-9e48-f2dbb774b1d3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "length train-documents-indices : 4142\n",
            "length of the vocabulary: 422\n",
            "\n",
            "\n",
            "start: creating bow representation...\n",
            "top 10 - word-id of the doc: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
            "max word-id: 421\n",
            "min word-id: 0\n",
            "max doc-id: 143\n",
            "min doc-id: 0\n",
            "all docs: 4142\n",
            "all words: 4142\n",
            "docidx unique 144\n",
            "words unique: 422\n",
            "ndocs: 144\n",
            "vocab-size: 422\n",
            "finised creating bow input!\n",
            "\n",
            "need normalized bows\n",
            "start: creating bow representation...\n",
            "top 10 - word-id of the doc: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
            "max word-id: 421\n",
            "min word-id: 0\n",
            "max doc-id: 104\n",
            "min doc-id: 0\n",
            "all docs: 3659\n",
            "all words: 3659\n",
            "docidx unique 105\n",
            "words unique: 420\n",
            "ndocs: 105\n",
            "vocab-size: 422\n",
            "finised creating bow input!\n",
            "\n",
            "need normalized bows\n",
            "start: creating bow representation...\n",
            "top 10 - word-id of the doc: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
            "max word-id: 421\n",
            "min word-id: 0\n",
            "max doc-id: 51\n",
            "min doc-id: 0\n",
            "all docs: 1884\n",
            "all words: 1884\n",
            "docidx unique 52\n",
            "words unique: 399\n",
            "ndocs: 52\n",
            "vocab-size: 422\n",
            "finised creating bow input!\n",
            "\n",
            "need normalized bows\n",
            "start: creating bow representation...\n",
            "top 10 - word-id of the doc: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
            "max word-id: 421\n",
            "min word-id: 0\n",
            "max doc-id: 52\n",
            "min doc-id: 0\n",
            "all docs: 1775\n",
            "all words: 1775\n",
            "docidx unique 53\n",
            "words unique: 374\n",
            "ndocs: 53\n",
            "vocab-size: 422\n",
            "finised creating bow input!\n",
            "\n",
            "need normalized bows\n",
            "start: creating bow representation...\n",
            "top 10 - word-id of the doc: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
            "max word-id: 421\n",
            "min word-id: 0\n",
            "max doc-id: 100\n",
            "min doc-id: 0\n",
            "all docs: 3555\n",
            "all words: 3555\n",
            "docidx unique 101\n",
            "words unique: 417\n",
            "ndocs: 101\n",
            "vocab-size: 422\n",
            "finised creating bow input!\n",
            "\n",
            "need normalized bows\n"
          ]
        }
      ],
      "source": [
        "# Erstellen BOW-Repräsentation für ETM Modell\n",
        "for_lda_model = False \n",
        "word2id, id2word, train_set, test_set, val_set = textsloader.create_bow_and_savebow_for_each_set(for_lda_model=for_lda_model)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r-DXUMguC8zM"
      },
      "source": [
        "# **Vocabular und IDs anzeigen als Beispiel**\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "6RBJYhLHCfwy",
        "outputId": "8a5b23ff-cc2f-4af8-d1ab-03cad3076b38"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "         word  id\n",
              "0         cmu   0\n",
              "1     support   1\n",
              "2     greater   2\n",
              "3       asked   3\n",
              "4        good   4\n",
              "..        ...  ..\n",
              "95        top  95\n",
              "96  technical  96\n",
              "97        bbs  97\n",
              "98      claim  98\n",
              "99       turn  99\n",
              "\n",
              "[100 rows x 2 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-3ae62c25-8642-4708-b230-4ecc9c72d2bf\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>word</th>\n",
              "      <th>id</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>cmu</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>support</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>greater</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>asked</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>good</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>95</th>\n",
              "      <td>top</td>\n",
              "      <td>95</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>96</th>\n",
              "      <td>technical</td>\n",
              "      <td>96</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>97</th>\n",
              "      <td>bbs</td>\n",
              "      <td>97</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>98</th>\n",
              "      <td>claim</td>\n",
              "      <td>98</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>99</th>\n",
              "      <td>turn</td>\n",
              "      <td>99</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>100 rows × 2 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-3ae62c25-8642-4708-b230-4ecc9c72d2bf')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-3ae62c25-8642-4708-b230-4ecc9c72d2bf button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-3ae62c25-8642-4708-b230-4ecc9c72d2bf');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "# show for samples: 100 word2id and id2 word\n",
        "word2id_df_100 = pd.DataFrame()\n",
        "word2id_df_100['word'] = list(word2id.keys())[:100]\n",
        "word2id_df_100['id'] = list(word2id.values())[:100]\n",
        "word2id_df_100"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tupeI6Pw85_L"
      },
      "source": [
        "# **Die Größe von Datensätzen kontrollieren**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n1d-5ji3qwE8",
        "outputId": "7298a345-2ba7-430b-e440-3ba942a4dd88"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Size of the vocabulary after prprocessing ist: 422\n",
            "Size of train set: 144\n",
            "Size of val set: 101\n",
            "Size of test set: 105\n"
          ]
        }
      ],
      "source": [
        "# Kontrollieren die Größen von verschiedenen Datensätzen\n",
        "print(f'Size of the vocabulary after prprocessing ist: {len(textsloader.vocabulary)}')\n",
        "print(f'Size of train set: {len(train_set[\"tokens\"])}')\n",
        "print(f'Size of val set: {len(val_set[\"tokens\"])}')\n",
        "print(f'Size of test set: {len(test_set[\"test\"][\"tokens\"])}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bxQL5jQtDb1c"
      },
      "source": [
        "# **Dokumenten wiederstellen für Word2Vec Embedding**\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "PDXEEBHfq3Cy",
        "outputId": "d6920625-aa31-4a3e-969c-5aebcb05fe3d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                             text-after-preprocessing\n",
              "0   steve article west nntp posting host writes ro...\n",
              "1   article free writes high speed mind hardware n...\n",
              "2   system reply uk canada back months posted time...\n",
              "3   nntp posting host article access net access wr...\n",
              "4   cs disclaimer public access system run univers...\n",
              "..                                                ...\n",
              "95  reply win net win net line mail program called...\n",
              "96  state university nntp posting host keywords di...\n",
              "97  microsoft distribution usa article news cs de ...\n",
              "98  pay graphics view ca dan writes remember posti...\n",
              "99  ca john wanted pc newsreader tin version unive...\n",
              "\n",
              "[100 rows x 1 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-2894a9f6-5a4a-4079-afc9-75fc7a2c649a\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text-after-preprocessing</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>steve article west nntp posting host writes ro...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>article free writes high speed mind hardware n...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>system reply uk canada back months posted time...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>nntp posting host article access net access wr...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>cs disclaimer public access system run univers...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>95</th>\n",
              "      <td>reply win net win net line mail program called...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>96</th>\n",
              "      <td>state university nntp posting host keywords di...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>97</th>\n",
              "      <td>microsoft distribution usa article news cs de ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>98</th>\n",
              "      <td>pay graphics view ca dan writes remember posti...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>99</th>\n",
              "      <td>ca john wanted pc newsreader tin version unive...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>100 rows × 1 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-2894a9f6-5a4a-4079-afc9-75fc7a2c649a')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-2894a9f6-5a4a-4079-afc9-75fc7a2c649a button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-2894a9f6-5a4a-4079-afc9-75fc7a2c649a');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ],
      "source": [
        "# re-erstellen von Dokumenten nach der Vorverarbeitungen. Die Dokumenten sind in Wörtern und werden für Word-Embedding Training benutzt\n",
        "docs_tr, docs_t, docs_v = textsloader.get_docs_in_words_for_each_set()\n",
        "train_docs_df = pd.DataFrame()\n",
        "train_docs_df['text-after-preprocessing'] = [' '.join(doc) for doc in docs_tr[:100]]\n",
        "train_docs_df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ds_KuUTQrK5P"
      },
      "source": [
        "# **Word-Embedding trainieren mit dem Traindatensatz**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "KBexKIVf8Qs5",
        "outputId": "f14d30fc-fc4a-4455-cda1-fdee048a1de3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "word-embedding train begins\n",
            "word-embedding train finished\n",
            "length of vocabulary from word-embedding model 422\n",
            "length of the vocabulary of prepraring-dataset-vocabulary: 422\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 422/422 [00:00<00:00, 35035.56it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cluster id labels for inputted data\n",
            "[9 3 3 9 9 9 9 8 6 3 8 6 8 2 2 1 1 4 1 2 4 8 3 6 7 4 1 1 1 3 4 3 7 1 6 6 3\n",
            " 2 3 4 3 9 7 1 9 7 2 6 3 5 4 9 2 3 9 4 9 7 9 2 1 7 2 9 2 9 2 3 9 4 7 6 7 7\n",
            " 8 9 7 2 3 4 1 8 3 3 5 1 6 1 1 9 2 7 5 1 8 5 8 4 3 2 7 8 3 7 9 3 1 7 7 7 8\n",
            " 3 4 2 9 3 8 8 3 6 6 2 3 0 0 9 4 8 6 2 1 1 1 0 9 2 6 2 6 0 8 9 4 7 9 2 1 0\n",
            " 2 7 6 7 3 3 1 5 1 3 0 1 4 9 1 7 5 7 0 4 2 9 7 5 5 6 6 8 8 7 0 0 2 2 2 5 9\n",
            " 0 7 8 2 2 7 0 2 1 1 4 6 4 2 9 5 0 9 7 5 5 1 3 0 0 4 1 6 3 5 6 9 1 6 6 4 3\n",
            " 8 3 8 5 9 2 7 8 0 4 4 7 3 2 0 2 4 1 7 4 1 7 8 0 7 2 3 6 1 1 4 8 3 4 6 6 6\n",
            " 9 1 6 8 0 6 8 7 7 4 9 9 2 7 0 7 1 5 6 2 4 0 6 7 7 8 8 2 6 1 2 3 2 7 8 7 5\n",
            " 1 3 3 7 3 6 9 4 8 7 9 4 3 8 7 1 4 1 5 7 7 8 2 8 5 0 6 4 0 8 7 7 2 4 9 7 6\n",
            " 0 0 8 3 4 7 7 8 6 4 1 6 2 7 7 8 7 7 9 9 7 1 1 4 3 0 0 0 1 4 2 2 2 8 4 2 5\n",
            " 2 8 7 6 4 5 3 8 4 5 0 7 4 6 9 6 6 4 8 6 5 2 7 1 6 1 7 5 0 0 4 8 1 7 1 6 5\n",
            " 6 2 0 6 8 0 0 5 1 6 5 7 6 4 8]\n",
            "Centroids data\n",
            "[[ 0.00186341  0.00090625 -0.00414835 -0.00456915  0.01119775 -0.00805125\n",
            "   0.0068034  -0.02625954 -0.01627562  0.01399306]\n",
            " [-0.02887674  0.05530724 -0.02116448  0.00619171 -0.01986829  0.05199963\n",
            "  -0.07242515 -0.03381212 -0.03059618  0.02221138]\n",
            " [ 0.00851132  0.07079646 -0.00118927  0.02707525  0.01154836  0.05205386\n",
            "  -0.0368168  -0.00831288 -0.02951769  0.045052  ]\n",
            " [ 0.02337305  0.07099158 -0.02616324  0.01334894 -0.01822668  0.04312435\n",
            "  -0.07456007 -0.05756378 -0.02557968  0.05824202]\n",
            " [-0.01562225  0.05349741 -0.01233148 -0.00678105 -0.01850669  0.00999186\n",
            "  -0.01996036 -0.03718503 -0.00983177  0.04515807]\n",
            " [-0.02729632  0.05814417  0.00186104  0.0126606   0.00658041  0.02095409\n",
            "  -0.01557283 -0.00611212  0.00518401 -0.00681016]\n",
            " [ 0.01192418  0.02102868 -0.02142355  0.01784952 -0.01825777  0.01571388\n",
            "  -0.03638977  0.00304181 -0.028984   -0.00137995]\n",
            " [ 0.01994597  0.06641082  0.00517138 -0.01222615  0.00096761  0.03707351\n",
            "  -0.04659147 -0.03423081 -0.00697518  0.00018403]\n",
            " [-0.00159303  0.01446568  0.01953752 -0.01059503  0.00355787  0.03427406\n",
            "  -0.04307091  0.00164173 -0.00136861  0.04064573]\n",
            " [-0.01787686  0.11162532  0.00434633  0.01812165 -0.02122727  0.07016956\n",
            "  -0.08584219 -0.03717069 -0.03454505  0.05611726]]\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script src=\"https://cdn.plot.ly/plotly-2.11.1.min.js\"></script>                <div id=\"1e792152-3e8b-4c89-b09c-84b8c3e2e9b0\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"1e792152-3e8b-4c89-b09c-84b8c3e2e9b0\")) {                    Plotly.newPlot(                        \"1e792152-3e8b-4c89-b09c-84b8c3e2e9b0\",                        [{\"hovertemplate\":\"cluster=cluster 9<br>x=%{x}<br>y=%{y}<br>word=%{text}<extra></extra>\",\"legendgroup\":\"cluster 9\",\"marker\":{\"color\":\"#636efa\",\"symbol\":\"circle\"},\"mode\":\"markers+text\",\"name\":\"cluster 9\",\"orientation\":\"v\",\"showlegend\":true,\"text\":[\"steve\",\"nntp\",\"posting\",\"host\",\"writes\",\"system\",\"back\",\"systems\",\"net\",\"people\",\"cs\",\"opinions\",\"wrote\",\"point\",\"version\",\"bike\",\"distribution\",\"result\",\"year\",\"nasa\",\"power\",\"ca\",\"usa\",\"religion\",\"work\",\"win\",\"technology\",\"reason\",\"day\",\"called\",\"line\",\"read\",\"things\",\"house\",\"sun\",\"religious\",\"lot\",\"man\"],\"x\":[6.848155498504639,6.711545467376709,7.714081764221191,7.552985191345215,7.498396396636963,7.435273170471191,7.19260311126709,6.975968360900879,7.223485946655273,7.834136486053467,7.311434268951416,7.074234962463379,6.767092704772949,6.8349785804748535,7.550395488739014,7.620357036590576,7.89045524597168,7.01724100112915,7.09640645980835,6.711386203765869,6.975743293762207,7.7683186531066895,6.578280925750732,7.197490692138672,7.031274318695068,6.886556148529053,6.993619918823242,6.896475315093994,7.204061985015869,6.843991756439209,7.576157569885254,7.660384654998779,7.7321391105651855,6.851500988006592,7.660487174987793,6.963433265686035,6.65950345993042,7.2907395362854],\"xaxis\":\"x\",\"y\":[6.463565826416016,5.101733684539795,6.866362571716309,6.34041166305542,6.3754730224609375,6.479185104370117,6.487734794616699,7.332294464111328,7.030138969421387,7.404895305633545,7.377237319946289,7.2253947257995605,7.111230373382568,6.688718795776367,6.454052448272705,7.115274429321289,7.211668014526367,7.2882890701293945,7.1742377281188965,7.265774250030518,5.836757659912109,7.256776332855225,6.9520263671875,7.11660099029541,5.76860237121582,5.734054088592529,6.274108409881592,6.941222190856934,5.970703125,5.92793607711792,6.924853324890137,7.134876251220703,7.158995628356934,7.227233409881592,7.036333084106445,7.509485721588135,4.925858497619629,6.727254390716553],\"yaxis\":\"y\",\"type\":\"scatter\"},{\"hovertemplate\":\"cluster=cluster 3<br>x=%{x}<br>y=%{y}<br>word=%{text}<extra></extra>\",\"legendgroup\":\"cluster 3\",\"marker\":{\"color\":\"#EF553B\",\"symbol\":\"circle\"},\"mode\":\"markers+text\",\"name\":\"cluster 3\",\"orientation\":\"v\",\"showlegend\":true,\"text\":[\"article\",\"west\",\"time\",\"speed\",\"data\",\"turn\",\"question\",\"long\",\"de\",\"email\",\"access\",\"current\",\"correct\",\"bill\",\"ac\",\"years\",\"computer\",\"keywords\",\"made\",\"big\",\"close\",\"gun\",\"view\",\"based\",\"major\",\"internet\",\"find\",\"stuff\",\"mail\",\"book\",\"folks\",\"hard\",\"design\",\"guess\",\"mark\",\"chip\",\"making\",\"card\",\"understand\",\"agree\"],\"x\":[7.150502681732178,4.86367130279541,5.8608927726745605,6.9941792488098145,6.476007461547852,6.828632354736328,6.389069080352783,4.304852485656738,6.184668064117432,6.780209541320801,4.547893524169922,5.331695556640625,4.51304292678833,5.706100940704346,5.237607955932617,6.330855369567871,6.238592147827148,6.69844913482666,5.792459011077881,6.143590927124023,5.17722225189209,5.008372783660889,5.078408241271973,6.62575626373291,4.440371036529541,6.470879554748535,6.958991050720215,6.014260292053223,6.612884044647217,5.965975761413574,4.3467302322387695,6.807170867919922,5.802670001983643,6.608175277709961,5.394174575805664,6.460782051086426,6.655187606811523,5.679055690765381,6.339990615844727,6.502797603607178],\"xaxis\":\"x\",\"y\":[6.378304481506348,6.018160820007324,6.017571449279785,5.235132217407227,5.344491958618164,6.574224472045898,5.149120807647705,6.799997329711914,6.01271915435791,5.640915393829346,6.335781097412109,5.850963115692139,5.994168281555176,5.724412441253662,6.339651584625244,5.775262355804443,6.079819679260254,5.884306907653809,6.380918502807617,4.930996894836426,5.934614181518555,6.777838706970215,6.493178844451904,6.863999366760254,6.609804153442383,5.915865421295166,5.591937065124512,5.867988109588623,5.360912322998047,5.788086891174316,6.3921637535095215,6.322181224822998,6.137919902801514,5.217480659484863,6.517148017883301,6.194807529449463,5.813908100128174,6.828409194946289,5.178090572357178,5.3968024253845215],\"yaxis\":\"y\",\"type\":\"scatter\"},{\"hovertemplate\":\"cluster=cluster 8<br>x=%{x}<br>y=%{y}<br>word=%{text}<extra></extra>\",\"legendgroup\":\"cluster 8\",\"marker\":{\"color\":\"#00cc96\",\"symbol\":\"circle\"},\"mode\":\"markers+text\",\"name\":\"cluster 8\",\"orientation\":\"v\",\"showlegend\":true,\"text\":[\"robert\",\"jim\",\"job\",\"high\",\"dos\",\"mr\",\"hold\",\"road\",\"dod\",\"wondering\",\"parts\",\"open\",\"related\",\"low\",\"source\",\"written\",\"single\",\"contact\",\"engineering\",\"friend\",\"response\",\"check\",\"il\",\"ohio\",\"quote\",\"apr\",\"members\",\"claim\",\"head\",\"playing\",\"originator\",\"jews\",\"specific\",\"advance\",\"kind\",\"higher\",\"tin\",\"truth\",\"deleted\",\"christian\",\"application\",\"total\"],\"x\":[5.4056925773620605,3.235541820526123,3.2860584259033203,3.04508900642395,3.0383810997009277,5.541524887084961,3.544565200805664,3.582737684249878,2.8132081031799316,3.2767560482025146,5.244847297668457,4.044875144958496,3.188551664352417,3.02797532081604,4.4346232414245605,3.7395379543304443,4.4107794761657715,3.0213234424591064,3.7767488956451416,2.8029470443725586,2.8286590576171875,3.8167126178741455,4.53305196762085,1.6900588274002075,3.3568155765533447,4.226803302764893,3.3739004135131836,4.98654317855835,3.2507567405700684,3.097740650177002,3.1266491413116455,3.8101394176483154,1.7487661838531494,5.414636611938477,4.069272041320801,3.620598077774048,3.354074001312256,3.0732109546661377,3.269735336303711,1.8705931901931763,2.9529755115509033,3.88519024848938],\"xaxis\":\"x\",\"y\":[4.072858810424805,4.701324939727783,7.207845211029053,5.905683517456055,4.919122695922852,4.079617500305176,5.351954936981201,4.9454426765441895,5.413489818572998,6.2211503982543945,6.0693488121032715,5.403755187988281,4.927591323852539,5.309863567352295,4.117345809936523,3.9706103801727295,6.167906761169434,4.622995853424072,4.550761699676514,4.868197441101074,7.577701091766357,6.631735801696777,4.170772552490234,5.626669406890869,5.726168632507324,6.170405864715576,6.729547500610352,5.723128795623779,6.803342819213867,5.257625102996826,5.309837818145752,4.654370307922363,5.75612211227417,4.0001397132873535,5.572145938873291,4.975700855255127,4.919321537017822,7.083544731140137,4.887218475341797,6.334290981292725,5.793663024902344,5.738337993621826],\"yaxis\":\"y\",\"type\":\"scatter\"},{\"hovertemplate\":\"cluster=cluster 6<br>x=%{x}<br>y=%{y}<br>word=%{text}<extra></extra>\",\"legendgroup\":\"cluster 6\",\"marker\":{\"color\":\"#ab63fa\",\"symbol\":\"circle\"},\"mode\":\"markers+text\",\"name\":\"cluster 6\",\"orientation\":\"v\",\"showlegend\":true,\"text\":[\"wrong\",\"fine\",\"mind\",\"hands\",\"copy\",\"original\",\"drive\",\"remember\",\"center\",\"final\",\"death\",\"laboratory\",\"james\",\"issue\",\"history\",\"rights\",\"required\",\"address\",\"radio\",\"dangerous\",\"sale\",\"start\",\"college\",\"looked\",\"early\",\"rest\",\"western\",\"add\",\"caused\",\"live\",\"standard\",\"numbers\",\"matter\",\"support\",\"show\",\"recently\",\"bitnet\",\"simply\",\"takes\",\"joe\",\"complete\",\"display\",\"hope\",\"disk\",\"calls\",\"buy\"],\"x\":[2.0269577503204346,3.2509307861328125,3.0116310119628906,1.5865193605422974,1.889058232307434,2.6740293502807617,1.8290408849716187,2.63854718208313,4.389465808868408,3.6671032905578613,4.704169273376465,1.860138177871704,1.7673567533493042,2.0341286659240723,2.6537282466888428,2.9867775440216064,4.579256534576416,5.945729732513428,3.671035051345825,1.9515767097473145,4.330638408660889,1.6986006498336792,1.7113512754440308,1.609778642654419,1.5546900033950806,2.110448122024536,3.82188081741333,4.579334259033203,2.5452089309692383,1.7401005029678345,2.996680736541748,2.369500160217285,1.7640573978424072,4.696913242340088,3.2558488845825195,3.978646755218506,1.80067777633667,2.1876556873321533,1.7078897953033447,3.943652391433716,1.4522088766098022,3.811645030975342,4.827274799346924,1.684695839881897,1.9646474123001099,2.572723865509033],\"xaxis\":\"x\",\"y\":[4.182353496551514,5.307624816894531,3.741340160369873,4.968703746795654,3.99776029586792,4.207762241363525,4.164708137512207,5.317390441894531,5.237067699432373,6.038365364074707,7.059900760650635,5.679313659667969,4.134562969207764,4.861421585083008,4.0754876136779785,3.817894697189331,6.8702168464660645,7.529472351074219,5.853488445281982,5.15519905090332,5.9708147048950195,3.933795213699341,3.91754412651062,4.003767967224121,4.2959394454956055,4.730064392089844,5.132883548736572,4.869592189788818,3.9725680351257324,4.84409236907959,4.198993682861328,4.093177318572998,5.039165496826172,5.463212490081787,5.245056629180908,5.785776138305664,3.922614336013794,4.7521185874938965,4.367774963378906,4.850520133972168,5.186636447906494,5.932146072387695,6.997831344604492,4.104268550872803,3.9797475337982178,3.752035140991211],\"yaxis\":\"y\",\"type\":\"scatter\"},{\"hovertemplate\":\"cluster=cluster 2<br>x=%{x}<br>y=%{y}<br>word=%{text}<extra></extra>\",\"legendgroup\":\"cluster 2\",\"marker\":{\"color\":\"#FFA15A\",\"symbol\":\"circle\"},\"mode\":\"markers+text\",\"name\":\"cluster 2\",\"orientation\":\"v\",\"showlegend\":true,\"text\":[\"record\",\"baseball\",\"world\",\"code\",\"posted\",\"place\",\"disclaimer\",\"control\",\"dept\",\"places\",\"assuming\",\"side\",\"call\",\"type\",\"times\",\"means\",\"gov\",\"software\",\"part\",\"love\",\"government\",\"late\",\"night\",\"city\",\"info\",\"toronto\",\"windows\",\"mit\",\"thing\",\"ago\",\"washington\",\"bad\",\"clear\",\"pretty\",\"deal\",\"summary\",\"space\",\"paul\",\"feel\",\"sell\",\"give\",\"faster\",\"important\",\"pay\",\"couple\",\"list\",\"local\"],\"x\":[3.6455392837524414,5.027105808258057,6.487545967102051,5.33446741104126,3.4302024841308594,6.3221869468688965,6.342290878295898,4.1508026123046875,6.8713059425354,3.7818877696990967,3.4558544158935547,4.143315315246582,6.964527606964111,5.129317283630371,3.6707398891448975,5.064335346221924,4.2914719581604,5.274468421936035,5.151585102081299,5.968417644500732,6.575570583343506,5.398046016693115,3.5878219604492188,5.192862033843994,6.48005485534668,6.136493682861328,5.406593322753906,5.196922302246094,4.468691825866699,4.749305725097656,5.389362812042236,4.0420613288879395,4.801881790161133,4.9475297927856445,4.73020601272583,4.537195205688477,4.659834384918213,4.074286460876465,3.3186256885528564,4.318980693817139,3.4152932167053223,3.7203805446624756,6.555017471313477,4.020292282104492,4.407621383666992,4.737699508666992,5.960503101348877],\"xaxis\":\"x\",\"y\":[4.500098705291748,4.763646602630615,5.437568664550781,4.888141632080078,5.729199409484863,5.739400863647461,5.160581111907959,4.48271369934082,5.478195667266846,5.8104248046875,4.259398937225342,7.170600414276123,5.193966388702393,4.890268802642822,4.573073863983154,4.876119613647461,7.347764492034912,5.960808277130127,5.822473526000977,5.554740905761719,4.87886905670166,6.1239848136901855,7.210653305053711,4.828160762786865,5.555181503295898,4.978837966918945,6.082217693328857,4.50252628326416,8.03299331665039,4.865113735198975,5.475948333740234,6.229702472686768,6.596744060516357,5.385731220245361,5.190093040466309,8.160260200500488,5.433654308319092,6.033505439758301,7.266999244689941,6.2987847328186035,7.573193550109863,5.690561771392822,4.784203052520752,7.416337013244629,8.078283309936523,5.089528560638428,5.003425598144531],\"yaxis\":\"y\",\"type\":\"scatter\"},{\"hovertemplate\":\"cluster=cluster 1<br>x=%{x}<br>y=%{y}<br>word=%{text}<extra></extra>\",\"legendgroup\":\"cluster 1\",\"marker\":{\"color\":\"#19d3f3\",\"symbol\":\"circle\"},\"mode\":\"markers+text\",\"name\":\"cluster 1\",\"orientation\":\"v\",\"showlegend\":true,\"text\":[\"problem\",\"post\",\"reply\",\"run\",\"heard\",\"bit\",\"effect\",\"canada\",\"public\",\"good\",\"david\",\"fact\",\"make\",\"set\",\"cc\",\"great\",\"children\",\"real\",\"ii\",\"state\",\"problems\",\"group\",\"ms\",\"graphics\",\"easy\",\"car\",\"put\",\"sort\",\"interested\",\"mine\",\"left\",\"life\",\"small\",\"cost\",\"order\",\"performance\",\"cmu\",\"understanding\",\"ibm\",\"general\",\"uiuc\",\"opinion\",\"board\",\"price\",\"class\",\"miles\",\"days\"],\"x\":[6.398341655731201,6.576688289642334,5.629660129547119,5.781427383422852,5.157320499420166,6.350236892700195,4.447009563446045,5.663595199584961,4.608160972595215,5.659825325012207,7.009377956390381,5.781185150146484,4.084079265594482,5.940744876861572,5.939414024353027,6.084901809692383,5.572432518005371,6.710546970367432,5.347536087036133,6.460082530975342,6.127683639526367,7.049155235290527,5.305486679077148,6.373589515686035,6.764377593994141,6.450857639312744,5.647109508514404,5.242908000946045,5.899453163146973,6.52164363861084,6.601830005645752,5.312438011169434,5.98905611038208,6.145802974700928,5.91532039642334,6.195507049560547,6.1915764808654785,6.85284948348999,6.293761730194092,6.003526210784912,6.190292835235596,5.6705827713012695,4.563648700714111,5.505520820617676,6.56496524810791,5.309241771697998,6.108422756195068],\"xaxis\":\"x\",\"y\":[6.855467319488525,7.552585124969482,7.018330097198486,7.386496543884277,8.00969123840332,6.512194633483887,4.696218967437744,6.870370864868164,8.101973533630371,7.130571365356445,6.178425312042236,6.072491645812988,4.28349494934082,6.885239601135254,7.406304836273193,6.835816383361816,7.407872200012207,7.716335296630859,7.703024864196777,6.316414833068848,6.892265796661377,6.610795021057129,7.780309200286865,7.240277290344238,7.526632308959961,6.825253963470459,6.631033420562744,5.236323833465576,7.411246299743652,7.557155609130859,6.885014057159424,7.772937297821045,7.483750343322754,6.2499308586120605,6.431796550750732,6.484846591949463,6.472785472869873,7.039833068847656,7.047348499298096,7.0503249168396,7.516676902770996,7.108274936676025,8.110352516174316,6.5645318031311035,7.410233497619629,7.178094387054443,6.610226154327393],\"yaxis\":\"y\",\"type\":\"scatter\"},{\"hovertemplate\":\"cluster=cluster 4<br>x=%{x}<br>y=%{y}<br>word=%{text}<extra></extra>\",\"legendgroup\":\"cluster 4\",\"marker\":{\"color\":\"#FF6692\",\"symbol\":\"circle\"},\"mode\":\"markers+text\",\"name\":\"cluster 4\",\"orientation\":\"v\",\"showlegend\":true,\"text\":[\"error\",\"free\",\"needed\",\"rate\",\"hand\",\"computing\",\"news\",\"file\",\"god\",\"possibly\",\"write\",\"population\",\"technical\",\"today\",\"change\",\"simple\",\"word\",\"box\",\"corporation\",\"strong\",\"phone\",\"mentioned\",\"research\",\"decided\",\"similar\",\"situation\",\"experience\",\"release\",\"key\",\"memory\",\"games\",\"east\",\"message\",\"coming\",\"machine\",\"john\",\"figure\",\"including\",\"results\",\"information\",\"views\",\"interesting\",\"argument\"],\"x\":[3.7555015087127686,3.856456995010376,3.839594841003418,2.9236388206481934,2.4612622261047363,2.724975109100342,3.8973686695098877,2.792263984680176,4.387801647186279,4.516814231872559,2.419518232345581,4.858826637268066,3.2573513984680176,2.9973902702331543,2.933403730392456,2.934093713760376,3.959317684173584,2.9548892974853516,3.981381893157959,3.1898601055145264,2.4392714500427246,5.071648597717285,4.195561408996582,2.6493964195251465,3.7465410232543945,2.5635299682617188,3.347485065460205,1.9638203382492065,2.3811283111572266,4.155237197875977,3.101233720779419,3.6847174167633057,3.671053886413574,3.4238123893737793,4.442332744598389,4.06871223449707,4.027556896209717,3.6465044021606445,3.0799107551574707,3.4407129287719727,4.037073612213135,3.290314197540283,3.9244544506073],\"xaxis\":\"x\",\"y\":[6.411665916442871,7.143907070159912,5.363163471221924,6.65091609954834,7.3050689697265625,6.54718017578125,5.224187850952148,7.641006946563721,7.411029815673828,6.688645362854004,6.412168979644775,6.032688617706299,6.88239049911499,7.812107563018799,6.437711715698242,6.384955883026123,7.404895782470703,7.725264549255371,6.8045973777771,7.823757171630859,7.085033416748047,6.865533828735352,5.473598957061768,6.633424758911133,7.596310615539551,7.385258197784424,6.201093673706055,6.352391242980957,7.025508403778076,7.804372310638428,7.736026763916016,7.345647811889648,7.611839771270752,6.156233787536621,5.947147846221924,6.896921157836914,6.426326751708984,6.766650676727295,6.423099994659424,4.778489112854004,7.513860702514648,6.020745277404785,6.314306259155273],\"yaxis\":\"y\",\"type\":\"scatter\"},{\"hovertemplate\":\"cluster=cluster 7<br>x=%{x}<br>y=%{y}<br>word=%{text}<extra></extra>\",\"legendgroup\":\"cluster 7\",\"marker\":{\"color\":\"#B6E880\",\"symbol\":\"circle\"},\"mode\":\"markers+text\",\"name\":\"cluster 7\",\"orientation\":\"v\",\"showlegend\":true,\"text\":[\"hardware\",\"form\",\"uk\",\"months\",\"sense\",\"university\",\"found\",\"thought\",\"talking\",\"admit\",\"wanted\",\"white\",\"science\",\"au\",\"ray\",\"image\",\"lab\",\"bible\",\"case\",\"ma\",\"end\",\"national\",\"happened\",\"exists\",\"thinking\",\"org\",\"taking\",\"company\",\"hear\",\"division\",\"sci\",\"care\",\"number\",\"fax\",\"asked\",\"common\",\"bbs\",\"dan\",\"reading\",\"project\",\"program\",\"tom\",\"answer\",\"team\",\"worse\",\"lead\",\"supposed\",\"newsreader\",\"send\",\"international\",\"guy\",\"idea\",\"week\",\"money\",\"references\",\"play\",\"considered\",\"service\",\"makes\",\"events\"],\"x\":[2.2535789012908936,4.769036769866943,5.3197550773620605,4.71269416809082,5.070950508117676,4.4322285652160645,4.3148064613342285,6.225822925567627,5.6735944747924805,3.718475580215454,3.921811580657959,5.876654148101807,4.827358722686768,4.599395751953125,2.621000051498413,4.9765944480896,3.763747215270996,2.983985662460327,4.352333068847656,5.5505475997924805,3.8313989639282227,5.231379508972168,4.911108016967773,4.668023109436035,4.93765926361084,4.257043838500977,3.232335329055786,4.399387836456299,5.901159763336182,3.7552099227905273,5.372682094573975,4.213810920715332,4.702188014984131,2.459855318069458,3.588311195373535,3.9818360805511475,5.1574015617370605,4.085360527038574,4.604832649230957,4.925670146942139,4.356627941131592,3.744804859161377,5.28694486618042,4.354928970336914,4.4697065353393555,4.038259983062744,3.1586053371429443,4.024447441101074,5.70096492767334,3.8834946155548096,4.8677873611450195,3.8455650806427,4.03287410736084,4.129916667938232,7.375721454620361,3.115302085876465,4.124282360076904,3.3364908695220947,5.264925479888916,2.257671594619751],\"xaxis\":\"x\",\"y\":[4.211660385131836,3.8050994873046875,5.356781482696533,4.186702728271484,5.252837181091309,5.313070774078369,4.730760097503662,4.4757080078125,4.6239237785339355,3.6824676990509033,5.041041851043701,4.6737961769104,4.4731597900390625,8.317177772521973,5.202522277832031,3.564654588699341,3.534581184387207,3.7469215393066406,3.7645952701568604,4.827242374420166,3.4663655757904053,5.277268409729004,3.8809359073638916,5.690859794616699,4.403207778930664,4.621016502380371,3.99576997756958,3.6491591930389404,4.428407192230225,3.6420042514801025,3.8884737491607666,3.5061793327331543,8.229598045349121,5.304050445556641,4.139261245727539,3.7422068119049072,3.7264087200164795,4.125475883483887,4.462728023529053,3.716855525970459,4.943943023681641,3.510664701461792,3.909975528717041,3.957319736480713,4.707043170928955,3.502699136734009,3.606931447982788,4.094453811645508,5.174794673919678,3.4032628536224365,4.23475456237793,3.42610502243042,5.251114845275879,4.673469066619873,6.980884552001953,3.6330618858337402,4.17166805267334,4.052217483520508,3.893502950668335,5.524537086486816],\"yaxis\":\"y\",\"type\":\"scatter\"},{\"hovertemplate\":\"cluster=cluster 5<br>x=%{x}<br>y=%{y}<br>word=%{text}<extra></extra>\",\"legendgroup\":\"cluster 5\",\"marker\":{\"color\":\"#FF97FF\",\"symbol\":\"circle\"},\"mode\":\"markers+text\",\"name\":\"cluster 5\",\"orientation\":\"v\",\"showlegend\":true,\"text\":[\"lost\",\"mike\",\"true\",\"gas\",\"gave\",\"hp\",\"short\",\"continue\",\"person\",\"home\",\"yeah\",\"sound\",\"include\",\"nice\",\"department\",\"receive\",\"mac\",\"game\",\"microsoft\",\"due\",\"expressed\",\"top\",\"level\",\"doubt\",\"church\",\"school\"],\"x\":[3.635786533355713,4.649705410003662,3.831369161605835,2.3927996158599854,2.2715859413146973,2.6636085510253906,2.391700506210327,2.1117641925811768,3.0205237865448,3.360058307647705,1.9872874021530151,2.537553310394287,4.430541515350342,2.587235450744629,3.401374101638794,2.5706522464752197,2.2588818073272705,3.9668819904327393,2.8707334995269775,3.6448090076446533,2.2871668338775635,4.019594192504883,2.086822509765625,3.3729653358459473,4.5906782150268555,3.234912633895874],\"xaxis\":\"x\",\"y\":[7.4175238609313965,7.659019947052002,7.292710781097412,3.6135857105255127,4.850658893585205,4.7288079261779785,5.194026947021484,4.902801513671875,4.13754415512085,4.338308811187744,4.306995868682861,3.687100887298584,7.8760175704956055,4.781678676605225,4.45670747756958,5.306829929351807,4.751302719116211,7.069772243499756,4.599656581878662,6.848969459533691,3.6428775787353516,7.908508777618408,5.432007312774658,7.212340831756592,8.266743659973145,7.914886474609375],\"yaxis\":\"y\",\"type\":\"scatter\"},{\"hovertemplate\":\"cluster=cluster 0<br>x=%{x}<br>y=%{y}<br>word=%{text}<extra></extra>\",\"legendgroup\":\"cluster 0\",\"marker\":{\"color\":\"#FECB52\",\"symbol\":\"circle\"},\"mode\":\"markers+text\",\"name\":\"cluster 0\",\"orientation\":\"v\",\"showlegend\":true,\"text\":[\"hell\",\"tv\",\"law\",\"told\",\"peter\",\"questions\",\"columbia\",\"started\",\"front\",\"longer\",\"network\",\"institute\",\"greater\",\"street\",\"stop\",\"voice\",\"note\",\"dr\",\"light\",\"study\",\"california\",\"appreciated\",\"interest\",\"full\",\"worth\",\"large\",\"rutgers\",\"pc\",\"texas\",\"difference\",\"ram\",\"date\",\"words\"],\"x\":[1.8820533752441406,2.296480894088745,4.455893516540527,1.1513341665267944,1.4609824419021606,1.092453956604004,2.3405704498291016,1.1961368322372437,1.8402529954910278,2.604433059692383,1.9555386304855347,2.121342182159424,2.0989768505096436,1.497878074645996,1.8346480131149292,2.9274613857269287,1.6883211135864258,1.5805044174194336,2.9378538131713867,1.2998573780059814,1.189867615699768,2.142791509628296,1.5081994533538818,2.5602481365203857,1.1611061096191406,2.11501407623291,1.299870252609253,2.175961971282959,1.6055967807769775,1.3345582485198975,1.2490968704223633,1.3140183687210083,2.4917712211608887],\"xaxis\":\"x\",\"y\":[6.319764137268066,6.724842548370361,7.115991592407227,5.694540977478027,6.089807510375977,5.310650825500488,5.312067985534668,5.955394744873047,4.581671714782715,7.422524452209473,5.9894843101501465,5.703110694885254,6.088522434234619,5.5189642906188965,5.9479193687438965,6.112935543060303,5.912437915802002,6.198490142822266,7.210379123687744,5.172789096832275,5.092269420623779,5.3923115730285645,5.955677509307861,6.627671241760254,5.819347381591797,5.456461429595947,4.856595993041992,6.033141613006592,4.417582988739014,4.637750625610352,5.70199728012085,6.014005184173584,6.559048652648926],\"yaxis\":\"y\",\"type\":\"scatter\"}],                        {\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}},\"xaxis\":{\"anchor\":\"y\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"x\"}},\"yaxis\":{\"anchor\":\"x\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"y\"}},\"legend\":{\"title\":{\"text\":\"cluster\"},\"tracegroupgap\":0},\"title\":{\"text\":\"word embedding samples\"}},                        {\"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('1e792152-3e8b-4c89-b09c-84b8c3e2e9b0');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };                            </script>        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ],
      "source": [
        "from src.embedding import WordEmbeddingCreator\n",
        "from pathlib import Path\n",
        "save_path = Path.joinpath(Path.cwd(), \"vocab_embedding.txt\")\n",
        "wb_creator = WordEmbeddingCreator(model_name=\"cbow\", documents = docs_tr, save_path= save_path)\n",
        "wb_creator.train(min_count=0, embedding_size= 10)\n",
        "vocab = list(word2id.keys())\n",
        "wb_creator.create_and_save_vocab_embedding(vocab, save_path)\n",
        "wb_creator.cluster_words(embedding_save_path = save_path, fig_path = Path('figures'), n_components=2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f23xipx7MSV4",
        "outputId": "0803ef9b-ee8d-4af4-b786-41e23b1373fd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "word-embedding of the word-- steve: \n",
            "vector: [-0.03008843, 0.08728182, -0.017987255, 0.034843035, 0.013637893, 0.08920556, -0.06917789, -0.018850897, -0.063429914, 0.054515846]\n",
            "dim of vector: 10\n"
          ]
        }
      ],
      "source": [
        "v = list(wb_creator.model.wv.vocab)[0]\n",
        "vec = list(wb_creator.model.wv.__getitem__(v))\n",
        "print(f'word-embedding of the word-- {v}: ')\n",
        "print(f'vector: {vec}')\n",
        "print(f'dim of vector: {len(vec)}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l53_jkUS-hl-"
      },
      "source": [
        "# **Word-Embeddings visualieren als Beispiel**\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "o96LsIWkNrZS"
      },
      "outputs": [],
      "source": [
        "# read word-embedding files\n",
        "with open(save_path) as f:\n",
        "  lines = f.readlines()\n",
        "embedding_data = []\n",
        "words_data = []\n",
        "for t in lines:\n",
        "  w = t.split(\"\\t\")[0]\n",
        "  v = [float(e) for e in t.split(\"\\t\")[1].split(\" \")]\n",
        "  words_data.append(w)\n",
        "  embedding_data.append(v)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "99hYOKPwB5aw",
        "outputId": "5f044131-1725-444a-f36e-e4b747e92650"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cluster id labels for inputted data\n",
            "[4 0 0 4 4 4 4 3 3 0 3 5 2 8 6 9 4 1 0 8 2 1 8 5 6 3 9 2 9 0 1 0 6 6 5 5 0\n",
            " 8 0 1 0 4 0 9 4 6 1 5 8 2 1 4 8 0 4 3 4 0 4 8 2 0 6 4 8 4 5 0 4 1 6 5 6 8\n",
            " 3 4 6 5 0 2 9 3 0 0 2 9 5 9 6 4 2 6 2 9 3 2 3 3 8 8 6 3 0 6 4 8 9 2 5 6 7\n",
            " 0 1 2 4 0 9 3 0 0 5 8 0 7 1 4 0 3 5 2 9 9 9 9 4 2 7 9 5 7 3 8 1 6 4 8 9 7\n",
            " 8 6 5 6 0 9 9 5 9 0 7 4 1 9 2 6 3 6 1 1 8 4 0 2 3 5 5 6 3 8 7 1 9 2 2 2 8\n",
            " 1 0 0 8 8 6 7 9 9 4 1 7 2 5 8 3 1 4 6 5 5 9 0 7 7 2 6 5 8 2 5 4 9 5 5 1 0\n",
            " 3 8 3 3 4 2 6 3 7 2 1 6 0 6 1 8 9 9 6 0 9 6 1 7 6 0 0 5 9 2 1 3 9 2 5 5 5\n",
            " 8 9 5 6 7 3 7 6 6 1 4 4 9 6 1 6 4 3 5 9 1 7 5 6 6 1 1 6 5 9 2 0 0 6 3 6 1\n",
            " 6 8 8 6 0 5 4 1 3 0 4 1 8 2 6 9 2 9 5 6 6 3 2 3 2 7 5 2 1 3 6 6 2 2 4 6 5\n",
            " 7 1 7 0 2 6 6 3 5 1 9 3 2 6 6 3 6 3 4 8 6 9 9 0 8 7 1 7 9 0 2 8 8 6 1 2 3\n",
            " 2 3 0 5 2 2 8 2 1 5 1 6 3 5 4 5 5 2 3 5 2 0 6 2 5 6 6 7 5 7 1 1 9 3 9 7 2\n",
            " 5 8 7 5 1 7 1 2 9 5 2 6 5 1 3]\n",
            "Centroids data\n",
            "[[ 0.02654559  0.07123066 -0.01534187  0.01808528 -0.03019339  0.03397408\n",
            "  -0.06502702 -0.04475694 -0.00647219  0.04823434]\n",
            " [-0.00549886  0.03139058 -0.01704844 -0.01911119 -0.01285411  0.01208502\n",
            "  -0.00664367 -0.03465889 -0.01506089  0.03683323]\n",
            " [-0.02136109  0.05802353  0.00055924  0.02990114  0.00192246  0.03513212\n",
            "  -0.01937828 -0.02890809  0.00690236  0.03068104]\n",
            " [-0.01405942  0.03519679  0.0203448  -0.01648285  0.00152366  0.02037317\n",
            "  -0.05090346  0.01134945 -0.00954176  0.02339982]\n",
            " [-0.02464581  0.10834297  0.00107883  0.01534085 -0.02376414  0.07267448\n",
            "  -0.08698903 -0.03339568 -0.02910133  0.05131949]\n",
            " [ 0.0080719   0.02375568 -0.02733964  0.01724813 -0.01188754  0.02142357\n",
            "  -0.03115991 -0.00028018 -0.027539   -0.00392378]\n",
            " [ 0.01296162  0.0606678   0.0069091  -0.01573174  0.00228767  0.04365691\n",
            "  -0.04855813 -0.03220132 -0.00812533 -0.00132876]\n",
            " [ 0.01727989 -0.00742762  0.01480538  0.00722138  0.0107396  -0.00960315\n",
            "   0.00692236 -0.01429755 -0.01163233  0.01479802]\n",
            " [ 0.01714818  0.08794287 -0.00499736  0.00827005  0.01563716  0.04907437\n",
            "  -0.06401572 -0.02877847 -0.04760027  0.06189814]\n",
            " [-0.02360455  0.05199203 -0.02725131  0.01395271 -0.01447971  0.05032654\n",
            "  -0.06989287 -0.03048601 -0.04611606  0.0302021 ]]\n"
          ]
        }
      ],
      "source": [
        "# clustering words with KMeans and Words-Vectors\n",
        "kmeans = cluster.KMeans(n_clusters=10)\n",
        "kmeans.fit(embedding_data)\n",
        " \n",
        "labels = kmeans.labels_\n",
        "centroids = kmeans.cluster_centers_\n",
        " \n",
        "print (\"Cluster id labels for inputted data\")\n",
        "print (labels)\n",
        "print (\"Centroids data\")\n",
        "print (centroids)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LAMgZ9aIE9A6",
        "outputId": "877a7a2e-24ca-4833-dd0b-ca6c27b7d37e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/numba/np/ufunc/parallel.py:363: NumbaWarning: The TBB threading layer requires TBB version 2019.5 or later i.e., TBB_INTERFACE_VERSION >= 11005. Found TBB_INTERFACE_VERSION = 9107. The TBB threading layer is disabled.\n",
            "  warnings.warn(problem)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Duration: 16.986818075180054 seconds\n"
          ]
        }
      ],
      "source": [
        "# dimension reduction with umap\n",
        "start = time.time()\n",
        "reducer = umap.UMAP(random_state=42,n_components=3)\n",
        "embedding = reducer.fit_transform(embedding_data)\n",
        "print('Duration: {} seconds'.format(time.time() - start))\n",
        "\n",
        "# show samples after dim-reduction in dataframe\n",
        "wb = pd.DataFrame(embedding, columns=['x', 'y', 'z'])\n",
        "wb['word'] = words_data\n",
        "wb['cluster'] = ['cluster ' + str(c) for c in labels]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 542
        },
        "id": "spomMOt_yy0W",
        "outputId": "83d8a6ae-81a6-46e6-9522-d9032dca2826"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script src=\"https://cdn.plot.ly/plotly-2.11.1.min.js\"></script>                <div id=\"4e517d99-7a72-45b2-bf80-175e0b6df1a5\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"4e517d99-7a72-45b2-bf80-175e0b6df1a5\")) {                    Plotly.newPlot(                        \"4e517d99-7a72-45b2-bf80-175e0b6df1a5\",                        [{\"hovertemplate\":\"cluster=cluster 4<br>x=%{x}<br>y=%{y}<br>z=%{z}<br>word=%{text}<extra></extra>\",\"legendgroup\":\"cluster 4\",\"marker\":{\"color\":\"#636efa\",\"symbol\":\"circle\"},\"mode\":\"markers+text\",\"name\":\"cluster 4\",\"scene\":\"scene\",\"showlegend\":true,\"text\":[\"steve\",\"nntp\",\"posting\",\"host\",\"writes\",\"post\",\"system\",\"back\",\"systems\",\"net\",\"people\",\"cs\",\"opinions\",\"wrote\",\"point\",\"version\",\"bike\",\"distribution\",\"result\",\"year\",\"nasa\",\"ca\",\"group\",\"religion\",\"easy\",\"technology\",\"reason\",\"day\",\"line\",\"read\",\"cost\",\"things\",\"house\",\"sun\",\"religious\",\"man\"],\"x\":[10.433961868286133,10.359746932983398,10.492362976074219,10.63855266571045,10.72378158569336,9.818361282348633,10.693358421325684,10.482288360595703,10.181217193603516,9.953760147094727,9.95409870147705,9.826387405395508,9.838910102844238,10.330399513244629,9.384495735168457,10.62300968170166,10.262046813964844,10.106950759887695,9.80697250366211,10.152447700500488,9.297986030578613,10.080805778503418,9.892191886901855,9.884048461914062,9.8795747756958,10.624526977539062,10.245201110839844,10.468072891235352,10.216763496398926,10.052545547485352,8.954652786254883,10.177241325378418,10.250761985778809,10.20225715637207,10.08343505859375,10.063374519348145],\"y\":[6.537059783935547,7.432307720184326,5.913644790649414,6.128487586975098,6.184178829193115,6.154604911804199,6.252264976501465,6.542379379272461,6.127398490905762,5.903504371643066,5.5875420570373535,5.677692890167236,6.056158065795898,6.325974464416504,6.258224010467529,6.112067222595215,5.874788761138916,5.4527153968811035,5.927145481109619,6.115678310394287,6.0720906257629395,5.510655403137207,6.483520030975342,6.024785995483398,6.135401248931885,6.757464408874512,6.422113418579102,6.60512113571167,5.860355377197266,5.587793350219727,6.536754131317139,5.7041730880737305,6.3790388107299805,5.770358562469482,5.9648613929748535,6.191017150878906],\"z\":[6.410951614379883,6.416678428649902,5.891659736633301,5.676678657531738,5.944063663482666,5.9959940910339355,5.997635841369629,6.105921745300293,6.61328649520874,6.730325698852539,5.7014055252075195,6.222686290740967,6.655165672302246,6.410739898681641,6.721620082855225,5.761628150939941,5.883129119873047,5.83162260055542,6.490238666534424,6.4398064613342285,6.461625099182129,5.753961086273193,6.494245529174805,6.698874473571777,6.116734504699707,6.3095245361328125,6.2383246421813965,6.074168682098389,5.514582633972168,6.083430767059326,6.803825855255127,5.794225215911865,6.5531110763549805,5.513664722442627,6.239379405975342,6.416632652282715],\"type\":\"scatter3d\"},{\"hovertemplate\":\"cluster=cluster 0<br>x=%{x}<br>y=%{y}<br>z=%{z}<br>word=%{text}<extra></extra>\",\"legendgroup\":\"cluster 0\",\"marker\":{\"color\":\"#EF553B\",\"symbol\":\"circle\"},\"mode\":\"markers+text\",\"name\":\"cluster 0\",\"scene\":\"scene\",\"showlegend\":true,\"text\":[\"article\",\"west\",\"time\",\"reply\",\"data\",\"turn\",\"question\",\"long\",\"de\",\"uk\",\"access\",\"sense\",\"university\",\"current\",\"correct\",\"bill\",\"ac\",\"computer\",\"made\",\"big\",\"close\",\"center\",\"gun\",\"population\",\"view\",\"major\",\"national\",\"exists\",\"single\",\"internet\",\"stuff\",\"book\",\"research\",\"bad\",\"folks\",\"design\",\"space\",\"chip\",\"program\",\"card\",\"machine\",\"john\",\"references\",\"list\"],\"x\":[10.674407958984375,9.303403854370117,10.049630165100098,9.023665428161621,10.192122459411621,10.636260986328125,10.118617057800293,9.114533424377441,10.318946838378906,9.305261611938477,9.0325927734375,9.122065544128418,8.675355911254883,9.799895286560059,9.046137809753418,10.024225234985352,9.299447059631348,10.144109725952148,9.764634132385254,9.987939834594727,9.474272727966309,8.49872875213623,9.250391006469727,9.023368835449219,9.362106323242188,9.239230155944824,9.171167373657227,9.256546974182129,8.795649528503418,10.412266731262207,9.9306058883667,9.93559741973877,8.126558303833008,8.444613456726074,9.008947372436523,9.888031005859375,8.900110244750977,10.302155494689941,8.341286659240723,9.583230972290039,8.428485870361328,8.714875221252441,9.931351661682129,8.554180145263672],\"y\":[6.491494655609131,8.074235916137695,6.6901164054870605,6.6446099281311035,7.283610820770264,6.657888889312744,7.345327854156494,7.437850475311279,6.826662063598633,7.765363693237305,7.925605297088623,8.049129486083984,8.099437713623047,7.284236431121826,8.310211181640625,7.33057165145874,7.140073776245117,6.805779933929443,6.537778854370117,7.402040958404541,7.419415473937988,8.39815616607666,8.363424301147461,7.367626190185547,6.846117973327637,7.372528553009033,7.857457160949707,7.645707607269287,7.664142608642578,7.143824100494385,7.053440570831299,7.035854816436768,7.454507827758789,7.4570136070251465,7.742962837219238,6.77868127822876,8.077646255493164,6.586875915527344,7.872087001800537,6.268845081329346,7.256649971008301,7.290213584899902,5.927351951599121,8.509008407592773],\"z\":[5.587803363800049,5.025496482849121,4.965901851654053,5.727248191833496,5.3848161697387695,5.4583587646484375,5.236466407775879,4.028549671173096,4.948319911956787,5.639448642730713,4.544277667999268,5.932058811187744,5.563952922821045,4.700862407684326,4.634777545928955,4.864334583282471,5.000156879425049,4.997987270355225,5.020400524139404,5.553622722625732,4.660301208496094,5.73587703704834,4.625654697418213,4.821342945098877,4.672738075256348,4.215959072113037,5.716726303100586,4.6773762702941895,4.710305690765381,5.294397354125977,5.15966272354126,5.1220173835754395,5.3177995681762695,4.608689308166504,4.314807415008545,5.08957052230835,5.391388416290283,5.0393452644348145,5.744219779968262,5.029276371002197,5.429516315460205,3.854935884475708,5.297337532043457,5.837258338928223],\"type\":\"scatter3d\"},{\"hovertemplate\":\"cluster=cluster 3<br>x=%{x}<br>y=%{y}<br>z=%{z}<br>word=%{text}<extra></extra>\",\"legendgroup\":\"cluster 3\",\"marker\":{\"color\":\"#00cc96\",\"symbol\":\"circle\"},\"mode\":\"markers+text\",\"name\":\"cluster 3\",\"scene\":\"scene\",\"showlegend\":true,\"text\":[\"robert\",\"wrong\",\"jim\",\"needed\",\"news\",\"dos\",\"mr\",\"hold\",\"road\",\"possibly\",\"dod\",\"open\",\"related\",\"low\",\"hp\",\"continue\",\"written\",\"home\",\"contact\",\"engineering\",\"nice\",\"friend\",\"check\",\"western\",\"department\",\"members\",\"claim\",\"playing\",\"originator\",\"jews\",\"advance\",\"show\",\"kind\",\"week\",\"microsoft\",\"tin\",\"information\",\"deleted\",\"makes\",\"total\"],\"x\":[7.3719916343688965,6.630678176879883,6.551178932189941,7.815169334411621,7.935067653656006,6.786288738250732,7.442028522491455,7.077744960784912,6.690303802490234,8.677330017089844,7.340668201446533,7.736880779266357,6.633626937866211,7.422257900238037,7.117065906524658,7.358880519866943,7.062946319580078,6.923834323883057,6.639899253845215,6.787047863006592,7.236689567565918,7.108902931213379,8.299478530883789,7.78760290145874,7.000598907470703,7.507064342498779,9.277029991149902,6.9915361404418945,7.057845592498779,7.034605979919434,7.486539363861084,7.516656875610352,7.904369831085205,7.870555400848389,6.711299896240234,6.675660133361816,7.161259651184082,6.665006160736084,7.615807056427002,7.866652011871338],\"y\":[6.955434322357178,9.088098526000977,7.4428863525390625,7.252022743225098,7.232993125915527,7.522035598754883,6.890955924987793,7.326845169067383,7.204592227935791,6.955354690551758,8.775064468383789,7.504622936248779,7.487213134765625,8.597031593322754,8.164040565490723,9.100876808166504,7.56559944152832,7.635838508605957,7.691794395446777,6.943274021148682,7.907359600067139,8.274025917053223,7.181229114532471,7.84267520904541,7.611105442047119,7.2336249351501465,8.131877899169922,7.653456211090088,7.60628080368042,7.071778774261475,6.889071464538574,8.255949020385742,7.1025614738464355,7.456356048583984,7.8968505859375,7.338308334350586,7.596147060394287,7.60443115234375,6.9184041023254395,7.405053615570068],\"z\":[6.050114154815674,6.074522495269775,5.767690658569336,5.708420753479004,5.898568630218506,5.645265579223633,6.163045406341553,5.374401569366455,5.769310474395752,5.140269756317139,4.798973083496094,5.334194660186768,5.667294979095459,5.127030372619629,5.810216903686523,4.963785171508789,6.49083137512207,6.3551025390625,6.016032695770264,5.996944427490234,5.814526081085205,5.704059600830078,4.895844459533691,5.902095317840576,6.289666175842285,4.930782318115234,5.360775947570801,5.441725254058838,5.4237141609191895,6.012546539306641,6.2719807624816895,5.5284013748168945,5.60142183303833,5.80387020111084,6.087069511413574,5.702376842498779,6.16463041305542,5.899958610534668,6.1395344734191895,5.154604911804199],\"type\":\"scatter3d\"},{\"hovertemplate\":\"cluster=cluster 5<br>x=%{x}<br>y=%{y}<br>z=%{z}<br>word=%{text}<extra></extra>\",\"legendgroup\":\"cluster 5\",\"marker\":{\"color\":\"#ab63fa\",\"symbol\":\"circle\"},\"mode\":\"markers+text\",\"name\":\"cluster 5\",\"scene\":\"scene\",\"showlegend\":true,\"text\":[\"fine\",\"mind\",\"hands\",\"copy\",\"original\",\"places\",\"drive\",\"assuming\",\"remember\",\"ray\",\"final\",\"death\",\"james\",\"issue\",\"gave\",\"history\",\"rights\",\"mit\",\"yeah\",\"sound\",\"address\",\"radio\",\"dangerous\",\"sale\",\"start\",\"college\",\"looked\",\"early\",\"rest\",\"add\",\"caused\",\"live\",\"standard\",\"mac\",\"numbers\",\"matter\",\"support\",\"recently\",\"expressed\",\"bitnet\",\"simply\",\"takes\",\"joe\",\"complete\",\"texas\",\"hope\",\"disk\",\"calls\",\"buy\"],\"x\":[7.562036991119385,7.736560821533203,7.386017322540283,7.1744704246521,7.876303195953369,8.656131744384766,6.62621545791626,8.493220329284668,7.376086235046387,7.57258939743042,8.389383316040039,8.77888011932373,6.800185203552246,7.366830825805664,7.60650634765625,7.868579387664795,7.517472743988037,8.528100967407227,6.85009241104126,6.867485046386719,9.007770538330078,8.330002784729004,7.0644378662109375,8.677997589111328,7.151589393615723,7.254283905029297,7.077371597290039,6.849160194396973,7.432580947875977,8.193161010742188,7.756447792053223,7.119143009185791,8.296334266662598,7.04215669631958,7.672942638397217,7.198450565338135,8.753118515014648,8.24855899810791,6.837674617767334,7.152266025543213,7.666242599487305,6.886332988739014,8.6770658493042,7.098353385925293,6.647514343261719,8.899602890014648,6.920596599578857,6.9566802978515625,7.373279094696045],\"y\":[8.677057266235352,8.912113189697266,9.490959167480469,9.752931594848633,9.328974723815918,8.520849227905273,9.390082359313965,9.0538911819458,8.65458869934082,8.644966125488281,8.70871639251709,8.862395286560059,9.468389511108398,9.1773042678833,9.080018043518066,9.529847145080566,9.121607780456543,8.694130897521973,8.953264236450195,8.714089393615723,6.183021545410156,8.840070724487305,8.922636985778809,8.082643508911133,9.643987655639648,9.86267375946045,9.749217987060547,9.415793418884277,9.102052688598633,8.42744255065918,9.534374237060547,9.326066970825195,9.115577697753906,8.795147895812988,9.604255676269531,9.23636531829834,8.842301368713379,8.198284149169922,8.941692352294922,9.68687629699707,9.196698188781738,9.346056938171387,8.971612930297852,9.287160873413086,9.431751251220703,8.7531099319458,9.608519554138184,9.423398971557617,9.232601165771484],\"z\":[5.255508899688721,6.347486972808838,4.957833290100098,5.839285373687744,5.303585529327393,4.7958903312683105,5.957034111022949,5.25433874130249,5.626834869384766,5.760959625244141,4.683609485626221,4.474812984466553,6.008240222930908,5.075043201446533,5.296114444732666,5.461286544799805,6.162668228149414,6.47525691986084,5.815350532531738,6.3713483810424805,5.920608043670654,4.968591690063477,5.089635848999023,4.6791181564331055,5.945745468139648,6.04990291595459,5.902159690856934,5.935705184936523,5.554726600646973,5.9944000244140625,5.564866065979004,5.057936668395996,5.143411159515381,5.450168132781982,5.511297225952148,4.797696590423584,5.463634490966797,5.182681083679199,6.230005741119385,6.141258239746094,5.125267028808594,5.904317378997803,5.2248382568359375,4.771282196044922,5.836225986480713,4.620283603668213,6.015430927276611,6.076560020446777,6.305024147033691],\"type\":\"scatter3d\"},{\"hovertemplate\":\"cluster=cluster 2<br>x=%{x}<br>y=%{y}<br>z=%{z}<br>word=%{text}<extra></extra>\",\"legendgroup\":\"cluster 2\",\"marker\":{\"color\":\"#FFA15A\",\"symbol\":\"circle\"},\"mode\":\"markers+text\",\"name\":\"cluster 2\",\"scene\":\"scene\",\"showlegend\":true,\"text\":[\"job\",\"free\",\"heard\",\"lost\",\"public\",\"god\",\"mike\",\"side\",\"true\",\"gas\",\"au\",\"type\",\"means\",\"gov\",\"ms\",\"short\",\"night\",\"city\",\"person\",\"word\",\"box\",\"include\",\"thing\",\"strong\",\"life\",\"similar\",\"summary\",\"head\",\"memory\",\"paul\",\"game\",\"games\",\"feel\",\"east\",\"message\",\"sell\",\"give\",\"pay\",\"couple\",\"including\",\"due\",\"truth\",\"views\",\"top\",\"board\",\"doubt\",\"church\",\"school\"],\"x\":[7.4849090576171875,8.628085136413574,8.436724662780762,7.745760440826416,8.379398345947266,8.470656394958496,8.238446235656738,8.54388427734375,8.140570640563965,6.790122985839844,8.178205490112305,9.015955924987793,8.97678279876709,8.5383939743042,8.72853946685791,6.856950283050537,7.857818603515625,8.989344596862793,6.673128604888916,8.509029388427734,7.381223678588867,8.174097061157227,8.517788887023926,7.436194896697998,8.804831504821777,7.919389724731445,8.316740036010742,7.0805463790893555,8.170814514160156,8.415811538696289,8.166105270385742,7.563864231109619,7.324877738952637,8.199825286865234,7.834691047668457,8.794824600219727,7.7281107902526855,8.399988174438477,8.320221900939941,8.104161262512207,7.998710632324219,7.227591514587402,8.333314895629883,7.9049763679504395,8.427046775817871,7.656854629516602,8.113122940063477,7.50773286819458],\"y\":[7.06960391998291,7.32170295715332,5.734788417816162,6.825196266174316,6.042469024658203,6.739473342895508,6.405651092529297,7.125895023345947,6.904518127441406,8.603979110717773,5.926478862762451,8.488351821899414,8.456947326660156,6.9275994300842285,5.785720348358154,8.243205070495605,7.063169479370117,8.583674430847168,8.518402099609375,7.126700401306152,6.4345622062683105,6.2136383056640625,6.14263391494751,6.417196273803711,5.8157548904418945,6.742109298706055,5.974422454833984,7.149469375610352,6.448307514190674,7.841966152191162,7.023283958435059,6.581516742706299,6.816477298736572,7.129168510437012,6.641814708709717,8.053248405456543,6.732959747314453,6.81038236618042,6.058367729187012,7.659934043884277,7.1760478019714355,7.199910640716553,6.789754390716553,6.319064617156982,6.0087761878967285,7.035568714141846,5.922092914581299,6.33317232131958],\"z\":[4.421601295471191,3.770400047302246,5.217996120452881,4.082197666168213,4.86930513381958,4.743229389190674,5.368319988250732,4.221785068511963,4.174682140350342,6.351200580596924,4.845917701721191,6.10418176651001,6.103646278381348,4.060090065002441,5.2488861083984375,5.515568256378174,4.2214226722717285,6.153349876403809,5.6736063957214355,3.9672861099243164,4.494660377502441,4.969901084899902,4.521389484405518,4.781965255737305,5.278615951538086,4.023746013641357,4.7019524574279785,4.62979793548584,4.551909446716309,4.937324523925781,4.479211330413818,4.269383907318115,4.464195251464844,4.090988636016846,4.33606481552124,4.512404918670654,4.082988739013672,4.202414035797119,4.544760704040527,4.3548712730407715,4.380256175994873,4.57066011428833,4.173857688903809,4.621771335601807,4.785077095031738,4.205348491668701,4.771684169769287,4.68326997756958],\"type\":\"scatter3d\"},{\"hovertemplate\":\"cluster=cluster 8<br>x=%{x}<br>y=%{y}<br>z=%{z}<br>word=%{text}<extra></extra>\",\"legendgroup\":\"cluster 8\",\"marker\":{\"color\":\"#19d3f3\",\"symbol\":\"circle\"},\"mode\":\"markers+text\",\"name\":\"cluster 8\",\"scene\":\"scene\",\"showlegend\":true,\"text\":[\"record\",\"world\",\"speed\",\"code\",\"email\",\"place\",\"disclaimer\",\"dept\",\"talking\",\"years\",\"call\",\"keywords\",\"times\",\"power\",\"part\",\"love\",\"government\",\"happened\",\"work\",\"info\",\"toronto\",\"win\",\"find\",\"mail\",\"washington\",\"called\",\"guess\",\"mark\",\"making\",\"lot\",\"understand\",\"faster\",\"important\",\"agree\",\"local\"],\"x\":[8.469792366027832,10.224977493286133,10.508692741394043,9.203567504882812,10.533337593078613,9.978901863098145,9.929405212402344,10.510016441345215,9.217711448669434,10.058834075927734,10.484929084777832,10.419492721557617,7.551929473876953,10.771496772766113,9.508160591125488,9.862298011779785,10.167916297912598,8.447905540466309,10.723428726196289,9.960834503173828,9.817553520202637,10.697317123413086,10.621525764465332,10.188483238220215,9.4686861038208,10.354742050170898,10.321368217468262,9.25831413269043,10.612319946289062,10.277567863464355,9.9533052444458,8.405364990234375,10.202032089233398,10.2396821975708,9.586343765258789],\"y\":[8.3125638961792,7.7442708015441895,7.295417785644531,8.461630821228027,7.143557548522949,7.530890464782715,7.543367385864258,7.430656909942627,7.979691028594971,6.925175666809082,7.402778625488281,7.176355361938477,7.616620063781738,7.018249988555908,8.128737449645996,7.995702743530273,7.726907730102539,7.4743971824646,7.007084846496582,7.243497848510742,8.08746337890625,7.022957801818848,7.117053031921387,7.3398308753967285,8.305384635925293,6.901725769042969,7.37495231628418,7.046651363372803,7.066562175750732,7.6828765869140625,7.337880611419678,8.173873901367188,7.69602108001709,7.304121494293213,7.752763271331787],\"z\":[5.433358192443848,6.218090057373047,6.464274883270264,6.144659996032715,5.804537296295166,6.134449481964111,6.407997131347656,6.1340012550354,6.576630592346191,5.168301105499268,6.549059867858887,5.610960960388184,6.369582653045654,5.717806339263916,5.382976531982422,5.9767680168151855,6.533065319061279,6.391073226928711,5.7187275886535645,6.187604904174805,6.242708683013916,5.634855270385742,6.352067947387695,6.034292697906494,5.883393287658691,5.910557746887207,5.813986301422119,5.431449890136719,5.493923187255859,6.420424938201904,6.371352195739746,4.861530780792236,6.477969646453857,5.6456193923950195,6.428292751312256],\"type\":\"scatter3d\"},{\"hovertemplate\":\"cluster=cluster 6<br>x=%{x}<br>y=%{y}<br>z=%{z}<br>word=%{text}<extra></extra>\",\"legendgroup\":\"cluster 6\",\"marker\":{\"color\":\"#FF6692\",\"symbol\":\"circle\"},\"mode\":\"markers+text\",\"name\":\"cluster 6\",\"scene\":\"scene\",\"showlegend\":true,\"text\":[\"baseball\",\"hardware\",\"form\",\"effect\",\"months\",\"control\",\"found\",\"thought\",\"admit\",\"make\",\"wanted\",\"white\",\"science\",\"image\",\"lab\",\"bible\",\"case\",\"ma\",\"end\",\"source\",\"thinking\",\"org\",\"put\",\"taking\",\"company\",\"ago\",\"hear\",\"division\",\"sci\",\"il\",\"care\",\"number\",\"fax\",\"asked\",\"common\",\"bbs\",\"deal\",\"dan\",\"reading\",\"performance\",\"project\",\"tom\",\"answer\",\"team\",\"worse\",\"lead\",\"supposed\",\"newsreader\",\"send\",\"international\",\"guy\",\"idea\",\"money\",\"higher\",\"play\",\"considered\",\"price\",\"service\",\"events\"],\"x\":[8.872013092041016,8.682868957519531,8.303772926330566,8.144148826599121,8.868733406066895,6.9442548751831055,8.022867202758789,9.336715698242188,7.771351337432861,6.9648895263671875,7.83242130279541,8.76597785949707,8.272196769714355,8.07221508026123,7.335276126861572,7.543787002563477,8.05409049987793,8.973566055297852,7.5288238525390625,6.930675029754639,8.379438400268555,8.004520416259766,8.406291961669922,7.617221832275391,7.7842888832092285,8.739142417907715,8.52849292755127,7.440405368804932,7.551077842712402,7.0590500831604,7.912553787231445,8.291193008422852,7.03213357925415,7.931676387786865,7.583485126495361,7.624936103820801,8.909602165222168,7.013252258300781,8.08917236328125,8.87485122680664,8.321301460266113,7.597501277923584,7.559925079345703,8.4196138381958,8.046350479125977,7.849411964416504,7.5978240966796875,7.986761093139648,9.072495460510254,7.486905574798584,8.6671724319458,7.5022149085998535,8.023292541503906,7.19644021987915,7.586694717407227,7.812380790710449,8.392789840698242,7.618401527404785,6.58717155456543],\"y\":[8.110440254211426,7.283566951751709,7.285618305206299,8.028116226196289,8.22781753540039,6.87445592880249,8.185420036315918,8.030312538146973,8.428991317749023,6.814307689666748,7.4830241203308105,6.774834156036377,8.571922302246094,7.195590972900391,7.767956256866455,8.846882820129395,7.822510242462158,7.640483856201172,8.350886344909668,6.811410903930664,8.277342796325684,8.294633865356445,6.6539082527160645,8.469438552856445,7.494113922119141,8.179864883422852,7.2382683753967285,7.86818265914917,6.8817667961120605,6.871227264404297,7.321397304534912,5.857157230377197,8.450434684753418,6.754788875579834,7.695613384246826,7.029338359832764,8.281219482421875,6.764700412750244,8.672416687011719,6.67854118347168,7.264012813568115,8.27278995513916,6.9707441329956055,8.047920227050781,8.208025932312012,8.153560638427734,9.058279991149902,8.054240226745605,7.128006458282471,8.020697593688965,7.7606024742126465,8.080945014953613,8.166106224060059,7.564628601074219,8.781378746032715,7.8631205558776855,6.689507484436035,8.433911323547363,8.335915565490723],\"z\":[6.38100528717041,6.271031856536865,6.602474689483643,6.285609722137451,6.847320079803467,6.197643756866455,6.162347793579102,6.789670467376709,6.897746562957764,6.342083930969238,6.137247562408447,6.801741123199463,6.447664260864258,6.867660045623779,6.8034820556640625,6.4653401374816895,6.893327713012695,6.523749828338623,6.91733980178833,5.902677059173584,6.323862075805664,6.142820358276367,6.24596643447876,6.243783473968506,6.862683296203613,6.208568572998047,6.881884574890137,6.920865058898926,6.284998416900635,6.107621669769287,6.79461669921875,4.987117290496826,5.346711158752441,5.665864944458008,6.750202655792236,6.474288463592529,5.8967061042785645,6.1864705085754395,6.363893508911133,6.612913608551025,6.712865829467773,6.988646030426025,6.27086067199707,6.794183731079102,6.254341125488281,6.933737277984619,6.460633277893066,6.6259765625,6.16757345199585,6.977133274078369,6.873545169830322,7.015171527862549,6.01683235168457,5.6019368171691895,6.539945125579834,6.542209148406982,6.219604969024658,6.276258945465088,5.301663875579834],\"type\":\"scatter3d\"},{\"hovertemplate\":\"cluster=cluster 9<br>x=%{x}<br>y=%{y}<br>z=%{z}<br>word=%{text}<extra></extra>\",\"legendgroup\":\"cluster 9\",\"marker\":{\"color\":\"#B6E880\",\"symbol\":\"circle\"},\"mode\":\"markers+text\",\"name\":\"cluster 9\",\"scene\":\"scene\",\"showlegend\":true,\"text\":[\"problem\",\"run\",\"bit\",\"canada\",\"good\",\"david\",\"fact\",\"set\",\"cc\",\"parts\",\"great\",\"children\",\"real\",\"law\",\"software\",\"ii\",\"based\",\"state\",\"problems\",\"usa\",\"late\",\"windows\",\"graphics\",\"car\",\"sort\",\"mentioned\",\"interested\",\"mine\",\"left\",\"hard\",\"small\",\"clear\",\"pretty\",\"order\",\"cmu\",\"understanding\",\"ibm\",\"general\",\"uiuc\",\"opinion\",\"class\",\"miles\",\"days\"],\"x\":[10.461698532104492,9.223932266235352,9.373973846435547,9.41198444366455,9.374465942382812,10.505499839782715,9.63454818725586,9.576253890991211,9.023765563964844,9.333296775817871,9.358860969543457,9.181916236877441,9.194271087646484,8.397981643676758,9.33292007446289,8.981568336486816,10.477535247802734,9.518978118896484,9.723421096801758,10.377934455871582,9.40793514251709,9.515692710876465,9.592001914978027,10.339011192321777,8.93250560760498,9.026117324829102,9.115490913391113,9.159440040588379,10.14706802368164,10.588224411010742,8.948726654052734,8.999579429626465,9.307320594787598,9.719486236572266,9.078180313110352,9.766511917114258,9.720423698425293,9.123763084411621,8.999906539916992,9.222999572753906,9.540878295898438,9.175199508666992,9.059094429016113],\"y\":[6.724254608154297,6.0517659187316895,6.801993370056152,6.47133207321167,6.21848201751709,6.889671802520752,7.873570442199707,6.603054523468018,6.448366641998291,8.7587308883667,6.691555500030518,6.035808563232422,5.790714740753174,7.755295276641846,8.777299880981445,5.866650581359863,6.536950588226318,6.768836975097656,6.741024017333984,6.5873003005981445,8.69242000579834,8.604077339172363,6.3434977531433105,6.668953895568848,7.147702217102051,6.915770530700684,6.2419114112854,5.931529998779297,6.585175514221191,6.789461135864258,6.274487018585205,8.570054054260254,8.35546875,6.462265968322754,6.561472415924072,6.480271339416504,6.4196014404296875,6.621189594268799,6.153707504272461,6.331087112426758,6.00350284576416,6.2369914054870605,6.599616050720215],\"z\":[6.573774337768555,5.488225936889648,6.238638401031494,5.219686985015869,5.229661464691162,6.412357330322266,5.739665508270264,5.937748908996582,6.139739990234375,5.211956977844238,6.21934700012207,5.324219703674316,6.167264938354492,4.108630180358887,5.320476055145264,5.25316047668457,5.660860538482666,6.115544319152832,6.02449369430542,6.676656723022461,5.226691246032715,5.313559532165527,5.911534309387207,6.673222064971924,6.308394908905029,5.114861488342285,5.743692874908447,6.319681167602539,6.747382640838623,6.0800461769104,6.168197154998779,4.858168601989746,5.737763404846191,5.178492546081543,6.703499794006348,6.670621871948242,5.934593677520752,6.449036121368408,6.251402378082275,5.465114116668701,6.0845746994018555,5.178446292877197,6.3857598304748535],\"type\":\"scatter3d\"},{\"hovertemplate\":\"cluster=cluster 1<br>x=%{x}<br>y=%{y}<br>z=%{z}<br>word=%{text}<extra></extra>\",\"legendgroup\":\"cluster 1\",\"marker\":{\"color\":\"#FF97FF\",\"symbol\":\"circle\"},\"mode\":\"markers+text\",\"name\":\"cluster 1\",\"scene\":\"scene\",\"showlegend\":true,\"text\":[\"error\",\"high\",\"rate\",\"hand\",\"posted\",\"computing\",\"file\",\"write\",\"tv\",\"technical\",\"today\",\"columbia\",\"change\",\"front\",\"longer\",\"simple\",\"institute\",\"corporation\",\"phone\",\"voice\",\"response\",\"decided\",\"situation\",\"light\",\"experience\",\"quote\",\"apr\",\"receive\",\"release\",\"key\",\"appreciated\",\"full\",\"coming\",\"large\",\"figure\",\"results\",\"pc\",\"interesting\",\"christian\",\"application\",\"words\",\"argument\"],\"x\":[8.175383567810059,7.802644729614258,8.114995002746582,7.13454532623291,8.279343605041504,7.650055885314941,7.169122219085693,7.841623306274414,7.148902893066406,7.66253137588501,7.434555530548096,7.3771491050720215,7.628483772277832,6.656703472137451,6.966081142425537,8.206974029541016,6.41029691696167,8.862387657165527,7.30600643157959,7.709895133972168,7.05014705657959,7.6232194900512695,6.870762348175049,7.168421745300293,8.154166221618652,8.111897468566895,8.632841110229492,7.358951091766357,6.348126411437988,7.2245354652404785,7.172424793243408,7.319675922393799,8.143109321594238,7.235908031463623,8.748453140258789,7.787578105926514,6.443578243255615,8.084466934204102,6.2997517585754395,7.677235126495361,7.40210485458374,8.369540214538574],\"y\":[7.613790512084961,8.362797737121582,8.075582504272461,7.247065544128418,8.543392181396484,8.231578826904297,6.681156635284424,8.249783515930176,8.132990837097168,7.384383201599121,6.397186279296875,8.938570976257324,8.049494743347168,8.980752944946289,7.0343146324157715,8.004120826721191,8.244476318359375,7.549843788146973,7.5459184646606445,8.299055099487305,6.7689971923828125,8.127840995788574,7.102940559387207,7.373254776000977,8.307245254516602,8.343683242797852,8.015812873840332,8.556302070617676,8.023823738098145,7.5365447998046875,9.254854202270508,8.171623229980469,8.106013298034668,9.48469352722168,7.6898674964904785,7.931907653808594,7.848724365234375,8.579143524169922,8.197198867797852,8.402082443237305,8.307707786560059,7.502184867858887],\"z\":[4.568780899047852,4.590202808380127,3.6976428031921387,3.8799729347229004,4.891039848327637,4.195763111114502,4.251835823059082,3.7960219383239746,4.035867214202881,4.3060688972473145,4.413905620574951,5.594791412353516,4.212545871734619,5.886754035949707,4.220762252807617,3.812849998474121,5.11319637298584,3.930192232131958,3.869697093963623,4.51632022857666,4.398165225982666,3.9172556400299072,4.395120620727539,4.287947654724121,4.464946269989014,4.771245002746582,4.628818988800049,5.626071929931641,4.685089588165283,3.9108777046203613,5.547999858856201,4.002121448516846,4.729034423828125,5.495708465576172,4.2487711906433105,4.394841194152832,5.2027740478515625,4.692304611206055,4.4931111335754395,4.7348551750183105,4.0685648918151855,4.828839302062988],\"type\":\"scatter3d\"},{\"hovertemplate\":\"cluster=cluster 7<br>x=%{x}<br>y=%{y}<br>z=%{z}<br>word=%{text}<extra></extra>\",\"legendgroup\":\"cluster 7\",\"marker\":{\"color\":\"#FECB52\",\"symbol\":\"circle\"},\"mode\":\"markers+text\",\"name\":\"cluster 7\",\"scene\":\"scene\",\"showlegend\":true,\"text\":[\"wondering\",\"hell\",\"laboratory\",\"told\",\"peter\",\"questions\",\"started\",\"network\",\"required\",\"greater\",\"street\",\"stop\",\"note\",\"dr\",\"ohio\",\"study\",\"california\",\"interest\",\"specific\",\"worth\",\"rutgers\",\"level\",\"difference\",\"display\",\"ram\",\"date\"],\"x\":[7.133745193481445,6.353618621826172,6.651534557342529,6.360973358154297,6.629055500030518,6.234039306640625,6.366165637969971,6.380984306335449,8.750645637512207,6.289431095123291,6.8287353515625,6.3281965255737305,6.348872184753418,6.305891990661621,6.618757724761963,6.356050968170166,6.279191017150879,6.5758771896362305,6.56169319152832,6.365293979644775,6.4220871925354,6.684696197509766,6.494814395904541,8.66394329071045,6.5720744132995605,6.516958236694336],\"y\":[7.461421489715576,8.088338851928711,8.57700252532959,8.984323501586914,8.547181129455566,9.0609130859375,8.85826301574707,7.9972968101501465,8.821907997131348,8.147886276245117,9.027423858642578,8.362950325012207,8.4629545211792,8.423333168029785,8.642715454101562,9.017257690429688,9.054682731628418,8.67848014831543,8.575151443481445,8.90450668334961,9.064335823059082,8.365822792053223,9.321292877197266,8.749654769897461,8.996583938598633,8.733818054199219],\"z\":[4.855985641479492,4.667299270629883,5.041164875030518,4.5172014236450195,4.246937274932861,5.019306182861328,4.349450588226318,5.07318639755249,4.487358570098877,4.8888044357299805,4.505455493927002,4.765201091766357,4.716926574707031,4.5020036697387695,4.794980525970459,5.153118133544922,5.253686428070068,4.3845977783203125,4.852960109710693,4.398663520812988,5.517833709716797,5.401080131530762,5.733638286590576,4.660116195678711,4.4304656982421875,4.368431568145752],\"type\":\"scatter3d\"}],                        {\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}},\"scene\":{\"domain\":{\"x\":[0.0,1.0],\"y\":[0.0,1.0]},\"xaxis\":{\"title\":{\"text\":\"x\"}},\"yaxis\":{\"title\":{\"text\":\"y\"}},\"zaxis\":{\"title\":{\"text\":\"z\"}}},\"legend\":{\"title\":{\"text\":\"cluster\"},\"tracegroupgap\":0},\"title\":{\"text\":\"word-embedding-samples\"}},                        {\"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('4e517d99-7a72-45b2-bf80-175e0b6df1a5');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };                            </script>        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "# visualization\n",
        "fig = px.scatter_3d(wb, \n",
        "                    text = wb['word'],\n",
        "                    x='x', y='y', z='z',\n",
        "                    color = wb['cluster'],\n",
        "                    title =\"word-embedding-samples\")\n",
        "fig.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P9jSI12r9zqu"
      },
      "source": [
        "# **ETM-Model trainieren**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fwiU9zWCIUh_",
        "outputId": "36f808af-983b-4761-cd45-a1e4494c8ff8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "144\n",
            "tensor([0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
            "        0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 2., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 2., 1., 0., 1., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0.])\n"
          ]
        }
      ],
      "source": [
        "# using DocSet to use easier the modul DataSet from torch\n",
        "from src.train_etm import DocSet, TrainETM\n",
        "from src.etm import ETM\n",
        "\n",
        "vocab_size = len(list(word2id.keys()))\n",
        "tr_set = DocSet(\"train\", vocab_size, train_set)\n",
        "print(len(tr_set))\n",
        "print(tr_set.__getitem__(0))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "kbJIWLZpJRnG",
        "outputId": "86e4337a-9ef9-4c3b-be2d-86311988c028"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1000\n",
            "adam\n",
            "number of batches: 24\n",
            "Epoch: 0/1000  -  Loss: 173.89637756347656\n",
            "Epoch: 1/1000  -  Loss: 173.88658142089844\n",
            "Epoch: 2/1000  -  Loss: 173.8802947998047\n",
            "Epoch: 3/1000  -  Loss: 173.8724822998047\n",
            "Epoch: 4/1000  -  Loss: 173.8698272705078\n",
            "Epoch: 5/1000  -  Loss: 173.86524963378906\n",
            "Epoch: 6/1000  -  Loss: 173.86151123046875\n",
            "Epoch: 7/1000  -  Loss: 173.8585662841797\n",
            "Epoch: 8/1000  -  Loss: 173.8630828857422\n",
            "Epoch: 9/1000  -  Loss: 173.8540496826172\n",
            "Epoch: 10/1000  -  Loss: 173.8553466796875\n",
            "Epoch: 11/1000  -  Loss: 173.85289001464844\n",
            "Epoch: 12/1000  -  Loss: 173.84881591796875\n",
            "Epoch: 13/1000  -  Loss: 173.84461975097656\n",
            "Epoch: 14/1000  -  Loss: 173.8428497314453\n",
            "Epoch: 15/1000  -  Loss: 173.84361267089844\n",
            "Epoch: 16/1000  -  Loss: 173.83802795410156\n",
            "Epoch: 17/1000  -  Loss: 173.8377685546875\n",
            "Epoch: 18/1000  -  Loss: 173.83689880371094\n",
            "Epoch: 19/1000  -  Loss: 173.83631896972656\n",
            "Epoch: 20/1000  -  Loss: 173.8359832763672\n",
            "Epoch: 21/1000  -  Loss: 173.8358612060547\n",
            "Epoch: 22/1000  -  Loss: 173.83392333984375\n",
            "Epoch: 23/1000  -  Loss: 173.83294677734375\n",
            "Epoch: 24/1000  -  Loss: 173.8306427001953\n",
            "Epoch: 25/1000  -  Loss: 173.8317108154297\n",
            "Epoch: 26/1000  -  Loss: 173.83079528808594\n",
            "Epoch: 27/1000  -  Loss: 173.83042907714844\n",
            "Epoch: 28/1000  -  Loss: 173.8278350830078\n",
            "Epoch: 29/1000  -  Loss: 173.82740783691406\n",
            "Epoch: 30/1000  -  Loss: 173.82740783691406\n",
            "Epoch: 31/1000  -  Loss: 173.82810974121094\n",
            "Epoch: 32/1000  -  Loss: 173.82708740234375\n",
            "Epoch: 33/1000  -  Loss: 173.82643127441406\n",
            "Epoch: 34/1000  -  Loss: 173.8265380859375\n",
            "Epoch: 35/1000  -  Loss: 173.82591247558594\n",
            "Epoch: 36/1000  -  Loss: 173.82521057128906\n",
            "Epoch: 37/1000  -  Loss: 173.8253936767578\n",
            "Epoch: 38/1000  -  Loss: 173.8252716064453\n",
            "Epoch: 39/1000  -  Loss: 173.82508850097656\n",
            "Epoch: 40/1000  -  Loss: 173.8245391845703\n",
            "Epoch: 41/1000  -  Loss: 173.82481384277344\n",
            "Epoch: 42/1000  -  Loss: 173.82452392578125\n",
            "Epoch: 43/1000  -  Loss: 173.8240966796875\n",
            "Epoch: 44/1000  -  Loss: 173.82408142089844\n",
            "Epoch: 45/1000  -  Loss: 173.82403564453125\n",
            "Epoch: 46/1000  -  Loss: 173.82411193847656\n",
            "Epoch: 47/1000  -  Loss: 173.8236083984375\n",
            "Epoch: 48/1000  -  Loss: 173.8236846923828\n",
            "Epoch: 49/1000  -  Loss: 173.82337951660156\n",
            "Epoch: 50/1000  -  Loss: 173.8232421875\n",
            "Epoch: 51/1000  -  Loss: 173.8231964111328\n",
            "Epoch: 52/1000  -  Loss: 173.8232421875\n",
            "Epoch: 53/1000  -  Loss: 173.8236083984375\n",
            "Epoch: 54/1000  -  Loss: 173.82301330566406\n",
            "Epoch: 55/1000  -  Loss: 173.823486328125\n",
            "Epoch: 56/1000  -  Loss: 173.8230743408203\n",
            "Epoch: 57/1000  -  Loss: 173.82298278808594\n",
            "Epoch: 58/1000  -  Loss: 173.82293701171875\n",
            "Epoch: 59/1000  -  Loss: 173.8227996826172\n",
            "Epoch: 60/1000  -  Loss: 173.8228302001953\n",
            "Epoch: 61/1000  -  Loss: 173.82313537597656\n",
            "Epoch: 62/1000  -  Loss: 173.82252502441406\n",
            "Epoch: 63/1000  -  Loss: 173.82305908203125\n",
            "Epoch: 64/1000  -  Loss: 173.8226318359375\n",
            "Epoch: 65/1000  -  Loss: 173.8230743408203\n",
            "Epoch: 66/1000  -  Loss: 173.82261657714844\n",
            "Epoch: 67/1000  -  Loss: 173.82264709472656\n",
            "Epoch: 68/1000  -  Loss: 173.82293701171875\n",
            "Epoch: 69/1000  -  Loss: 173.82310485839844\n",
            "Epoch: 70/1000  -  Loss: 173.8227996826172\n",
            "Epoch: 71/1000  -  Loss: 173.8227081298828\n",
            "Epoch: 72/1000  -  Loss: 173.82322692871094\n",
            "Epoch: 73/1000  -  Loss: 173.8227081298828\n",
            "Epoch: 74/1000  -  Loss: 173.8227996826172\n",
            "Epoch: 75/1000  -  Loss: 173.8229217529297\n",
            "Epoch: 76/1000  -  Loss: 173.82275390625\n",
            "Epoch: 77/1000  -  Loss: 173.82269287109375\n",
            "Epoch: 78/1000  -  Loss: 173.8228302001953\n",
            "Epoch: 79/1000  -  Loss: 173.82257080078125\n",
            "Epoch: 80/1000  -  Loss: 173.8225555419922\n",
            "Epoch: 81/1000  -  Loss: 173.82208251953125\n",
            "Epoch: 82/1000  -  Loss: 173.82269287109375\n",
            "Epoch: 83/1000  -  Loss: 173.82275390625\n",
            "Epoch: 84/1000  -  Loss: 173.8226776123047\n",
            "Epoch: 85/1000  -  Loss: 173.82220458984375\n",
            "Epoch: 86/1000  -  Loss: 173.8231658935547\n",
            "Epoch: 87/1000  -  Loss: 173.82301330566406\n",
            "Epoch: 88/1000  -  Loss: 173.82261657714844\n",
            "Epoch: 89/1000  -  Loss: 173.8226318359375\n",
            "Epoch: 90/1000  -  Loss: 173.8225860595703\n",
            "Epoch: 91/1000  -  Loss: 173.8226776123047\n",
            "Epoch: 92/1000  -  Loss: 173.82286071777344\n",
            "Epoch: 93/1000  -  Loss: 173.8228759765625\n",
            "Epoch: 94/1000  -  Loss: 173.82249450683594\n",
            "Epoch: 95/1000  -  Loss: 173.82244873046875\n",
            "Epoch: 96/1000  -  Loss: 173.8224639892578\n",
            "Epoch: 97/1000  -  Loss: 173.8227081298828\n",
            "Epoch: 98/1000  -  Loss: 173.82310485839844\n",
            "Epoch: 99/1000  -  Loss: 173.82269287109375\n",
            "Epoch: 100/1000  -  Loss: 173.8226776123047\n",
            "Epoch: 101/1000  -  Loss: 173.82273864746094\n",
            "Epoch: 102/1000  -  Loss: 173.8226318359375\n",
            "Epoch: 103/1000  -  Loss: 173.8230743408203\n",
            "Epoch: 104/1000  -  Loss: 173.8225555419922\n",
            "Epoch: 105/1000  -  Loss: 173.82281494140625\n",
            "Epoch: 106/1000  -  Loss: 173.822998046875\n",
            "Epoch: 107/1000  -  Loss: 173.82286071777344\n",
            "Epoch: 108/1000  -  Loss: 173.8228302001953\n",
            "Epoch: 109/1000  -  Loss: 173.8227081298828\n",
            "Epoch: 110/1000  -  Loss: 173.8224334716797\n",
            "Epoch: 111/1000  -  Loss: 173.82249450683594\n",
            "Epoch: 112/1000  -  Loss: 173.82264709472656\n",
            "Epoch: 113/1000  -  Loss: 173.82264709472656\n",
            "Epoch: 114/1000  -  Loss: 173.82298278808594\n",
            "Epoch: 115/1000  -  Loss: 173.8226318359375\n",
            "Epoch: 116/1000  -  Loss: 173.82261657714844\n",
            "Epoch: 117/1000  -  Loss: 173.8225860595703\n",
            "Epoch: 118/1000  -  Loss: 173.82257080078125\n",
            "Epoch: 119/1000  -  Loss: 173.82264709472656\n",
            "Epoch: 120/1000  -  Loss: 173.82264709472656\n",
            "Epoch: 121/1000  -  Loss: 173.82293701171875\n",
            "Epoch: 122/1000  -  Loss: 173.8231201171875\n",
            "Epoch: 123/1000  -  Loss: 173.82264709472656\n",
            "Epoch: 124/1000  -  Loss: 173.82286071777344\n",
            "Epoch: 125/1000  -  Loss: 173.8228302001953\n",
            "Epoch: 126/1000  -  Loss: 173.8227081298828\n",
            "Epoch: 127/1000  -  Loss: 173.82275390625\n",
            "Epoch: 128/1000  -  Loss: 173.8230743408203\n",
            "Epoch: 129/1000  -  Loss: 173.8227081298828\n",
            "Epoch: 130/1000  -  Loss: 173.82249450683594\n",
            "Epoch: 131/1000  -  Loss: 173.82286071777344\n",
            "Epoch: 132/1000  -  Loss: 173.82289123535156\n",
            "Epoch: 133/1000  -  Loss: 173.82240295410156\n",
            "Epoch: 134/1000  -  Loss: 173.82264709472656\n",
            "Epoch: 135/1000  -  Loss: 173.82261657714844\n",
            "Epoch: 136/1000  -  Loss: 173.82232666015625\n",
            "Epoch: 137/1000  -  Loss: 173.82275390625\n",
            "Epoch: 138/1000  -  Loss: 173.822509765625\n",
            "Epoch: 139/1000  -  Loss: 173.82276916503906\n",
            "Epoch: 140/1000  -  Loss: 173.8227996826172\n",
            "Epoch: 141/1000  -  Loss: 173.82264709472656\n",
            "Epoch: 142/1000  -  Loss: 173.82220458984375\n",
            "Epoch: 143/1000  -  Loss: 173.8225555419922\n",
            "Epoch: 144/1000  -  Loss: 173.82275390625\n",
            "Epoch: 145/1000  -  Loss: 173.82275390625\n",
            "Epoch: 146/1000  -  Loss: 173.8225860595703\n",
            "Epoch: 147/1000  -  Loss: 173.8226776123047\n",
            "Epoch: 148/1000  -  Loss: 173.82191467285156\n",
            "Epoch: 149/1000  -  Loss: 173.8229522705078\n",
            "Epoch: 150/1000  -  Loss: 173.8224334716797\n",
            "Epoch: 151/1000  -  Loss: 173.8232879638672\n",
            "Epoch: 152/1000  -  Loss: 173.8225555419922\n",
            "Epoch: 153/1000  -  Loss: 173.8224639892578\n",
            "Epoch: 154/1000  -  Loss: 173.82313537597656\n",
            "Epoch: 155/1000  -  Loss: 173.82264709472656\n",
            "Epoch: 156/1000  -  Loss: 173.82273864746094\n",
            "Epoch: 157/1000  -  Loss: 173.82298278808594\n",
            "Epoch: 158/1000  -  Loss: 173.82276916503906\n",
            "Epoch: 159/1000  -  Loss: 173.8226776123047\n",
            "Epoch: 160/1000  -  Loss: 173.82252502441406\n",
            "Epoch: 161/1000  -  Loss: 173.82264709472656\n",
            "Epoch: 162/1000  -  Loss: 173.82264709472656\n",
            "Epoch: 163/1000  -  Loss: 173.82257080078125\n",
            "Epoch: 164/1000  -  Loss: 173.8226776123047\n",
            "Epoch: 165/1000  -  Loss: 173.8226776123047\n",
            "Epoch: 166/1000  -  Loss: 173.82232666015625\n",
            "Epoch: 167/1000  -  Loss: 173.82275390625\n",
            "Epoch: 168/1000  -  Loss: 173.82252502441406\n",
            "Epoch: 169/1000  -  Loss: 173.822021484375\n",
            "Epoch: 170/1000  -  Loss: 173.8225555419922\n",
            "Epoch: 171/1000  -  Loss: 173.8230438232422\n",
            "Epoch: 172/1000  -  Loss: 173.8224639892578\n",
            "Epoch: 173/1000  -  Loss: 173.822998046875\n",
            "Epoch: 174/1000  -  Loss: 173.8225555419922\n",
            "Epoch: 175/1000  -  Loss: 173.8225860595703\n",
            "Epoch: 176/1000  -  Loss: 173.822509765625\n",
            "Epoch: 177/1000  -  Loss: 173.82298278808594\n",
            "Epoch: 178/1000  -  Loss: 173.8225555419922\n",
            "Epoch: 179/1000  -  Loss: 173.8229217529297\n",
            "Epoch: 180/1000  -  Loss: 173.8223114013672\n",
            "Epoch: 181/1000  -  Loss: 173.82240295410156\n",
            "Epoch: 182/1000  -  Loss: 173.8224334716797\n",
            "Epoch: 183/1000  -  Loss: 173.822509765625\n",
            "Epoch: 184/1000  -  Loss: 173.82228088378906\n",
            "Epoch: 185/1000  -  Loss: 173.8228759765625\n",
            "Epoch: 186/1000  -  Loss: 173.82257080078125\n",
            "Epoch: 187/1000  -  Loss: 173.8224639892578\n",
            "Epoch: 188/1000  -  Loss: 173.8227081298828\n",
            "Epoch: 189/1000  -  Loss: 173.82281494140625\n",
            "Epoch: 190/1000  -  Loss: 173.8232421875\n",
            "Epoch: 191/1000  -  Loss: 173.8226776123047\n",
            "Epoch: 192/1000  -  Loss: 173.82261657714844\n",
            "Epoch: 193/1000  -  Loss: 173.82275390625\n",
            "Epoch: 194/1000  -  Loss: 173.82261657714844\n",
            "Epoch: 195/1000  -  Loss: 173.8224639892578\n",
            "Epoch: 196/1000  -  Loss: 173.8224639892578\n",
            "Epoch: 197/1000  -  Loss: 173.8229522705078\n",
            "Epoch: 198/1000  -  Loss: 173.82276916503906\n",
            "Epoch: 199/1000  -  Loss: 173.822509765625\n",
            "Epoch: 200/1000  -  Loss: 173.8228302001953\n",
            "Epoch: 201/1000  -  Loss: 173.82286071777344\n",
            "Epoch: 202/1000  -  Loss: 173.8225555419922\n",
            "Epoch: 203/1000  -  Loss: 173.8229217529297\n",
            "Epoch: 204/1000  -  Loss: 173.8230743408203\n",
            "Epoch: 205/1000  -  Loss: 173.8228302001953\n",
            "Epoch: 206/1000  -  Loss: 173.82240295410156\n",
            "Epoch: 207/1000  -  Loss: 173.82281494140625\n",
            "Epoch: 208/1000  -  Loss: 173.8225555419922\n",
            "Epoch: 209/1000  -  Loss: 173.8226318359375\n",
            "Epoch: 210/1000  -  Loss: 173.82264709472656\n",
            "Epoch: 211/1000  -  Loss: 173.8225860595703\n",
            "Epoch: 212/1000  -  Loss: 173.8225555419922\n",
            "Epoch: 213/1000  -  Loss: 173.82276916503906\n",
            "Epoch: 214/1000  -  Loss: 173.82298278808594\n",
            "Epoch: 215/1000  -  Loss: 173.8227996826172\n",
            "Epoch: 216/1000  -  Loss: 173.82269287109375\n",
            "Epoch: 217/1000  -  Loss: 173.82330322265625\n",
            "Epoch: 218/1000  -  Loss: 173.822998046875\n",
            "Epoch: 219/1000  -  Loss: 173.82276916503906\n",
            "Epoch: 220/1000  -  Loss: 173.82273864746094\n",
            "Epoch: 221/1000  -  Loss: 173.82240295410156\n",
            "Epoch: 222/1000  -  Loss: 173.82273864746094\n",
            "Epoch: 223/1000  -  Loss: 173.82252502441406\n",
            "Epoch: 224/1000  -  Loss: 173.82322692871094\n",
            "Epoch: 225/1000  -  Loss: 173.82276916503906\n",
            "Epoch: 226/1000  -  Loss: 173.8226318359375\n",
            "Epoch: 227/1000  -  Loss: 173.8229217529297\n",
            "Epoch: 228/1000  -  Loss: 173.82276916503906\n",
            "Epoch: 229/1000  -  Loss: 173.82252502441406\n",
            "Epoch: 230/1000  -  Loss: 173.82261657714844\n",
            "Epoch: 231/1000  -  Loss: 173.82301330566406\n",
            "Epoch: 232/1000  -  Loss: 173.82276916503906\n",
            "Epoch: 233/1000  -  Loss: 173.82264709472656\n",
            "Epoch: 234/1000  -  Loss: 173.82249450683594\n",
            "Epoch: 235/1000  -  Loss: 173.82244873046875\n",
            "Epoch: 236/1000  -  Loss: 173.8224639892578\n",
            "Epoch: 237/1000  -  Loss: 173.82322692871094\n",
            "Epoch: 238/1000  -  Loss: 173.82252502441406\n",
            "Epoch: 239/1000  -  Loss: 173.8231201171875\n",
            "Epoch: 240/1000  -  Loss: 173.82275390625\n",
            "Epoch: 241/1000  -  Loss: 173.82313537597656\n",
            "Epoch: 242/1000  -  Loss: 173.822509765625\n",
            "Epoch: 243/1000  -  Loss: 173.82305908203125\n",
            "Epoch: 244/1000  -  Loss: 173.8225860595703\n",
            "Epoch: 245/1000  -  Loss: 173.82240295410156\n",
            "Epoch: 246/1000  -  Loss: 173.822265625\n",
            "Epoch: 247/1000  -  Loss: 173.82276916503906\n",
            "Epoch: 248/1000  -  Loss: 173.822998046875\n",
            "Epoch: 249/1000  -  Loss: 173.82249450683594\n",
            "Epoch: 250/1000  -  Loss: 173.8227081298828\n",
            "Epoch: 251/1000  -  Loss: 173.8228302001953\n",
            "Epoch: 252/1000  -  Loss: 173.8231201171875\n",
            "Epoch: 253/1000  -  Loss: 173.82289123535156\n",
            "Epoch: 254/1000  -  Loss: 173.8223419189453\n",
            "Epoch: 255/1000  -  Loss: 173.8221893310547\n",
            "Epoch: 256/1000  -  Loss: 173.8228759765625\n",
            "Epoch: 257/1000  -  Loss: 173.82322692871094\n",
            "Epoch: 258/1000  -  Loss: 173.82318115234375\n",
            "Epoch: 259/1000  -  Loss: 173.82228088378906\n",
            "Epoch: 260/1000  -  Loss: 173.8225860595703\n",
            "Epoch: 261/1000  -  Loss: 173.82273864746094\n",
            "Epoch: 262/1000  -  Loss: 173.8228302001953\n",
            "Epoch: 263/1000  -  Loss: 173.8226776123047\n",
            "Epoch: 264/1000  -  Loss: 173.82286071777344\n",
            "Epoch: 265/1000  -  Loss: 173.82318115234375\n",
            "Epoch: 266/1000  -  Loss: 173.82281494140625\n",
            "Epoch: 267/1000  -  Loss: 173.82249450683594\n",
            "Epoch: 268/1000  -  Loss: 173.8225555419922\n",
            "Epoch: 269/1000  -  Loss: 173.82264709472656\n",
            "Epoch: 270/1000  -  Loss: 173.82286071777344\n",
            "Epoch: 271/1000  -  Loss: 173.82257080078125\n",
            "Epoch: 272/1000  -  Loss: 173.82289123535156\n",
            "Epoch: 273/1000  -  Loss: 173.82261657714844\n",
            "Epoch: 274/1000  -  Loss: 173.82257080078125\n",
            "Epoch: 275/1000  -  Loss: 173.8224334716797\n",
            "Epoch: 276/1000  -  Loss: 173.82273864746094\n",
            "Epoch: 277/1000  -  Loss: 173.82275390625\n",
            "Epoch: 278/1000  -  Loss: 173.82264709472656\n",
            "Epoch: 279/1000  -  Loss: 173.82273864746094\n",
            "Epoch: 280/1000  -  Loss: 173.82289123535156\n",
            "Epoch: 281/1000  -  Loss: 173.822998046875\n",
            "Epoch: 282/1000  -  Loss: 173.8230438232422\n",
            "Epoch: 283/1000  -  Loss: 173.8223876953125\n",
            "Epoch: 284/1000  -  Loss: 173.8229522705078\n",
            "Epoch: 285/1000  -  Loss: 173.82269287109375\n",
            "Epoch: 286/1000  -  Loss: 173.8224334716797\n",
            "Epoch: 287/1000  -  Loss: 173.82264709472656\n",
            "Epoch: 288/1000  -  Loss: 173.82273864746094\n",
            "Epoch: 289/1000  -  Loss: 173.82286071777344\n",
            "Epoch: 290/1000  -  Loss: 173.8223876953125\n",
            "Epoch: 291/1000  -  Loss: 173.82228088378906\n",
            "Epoch: 292/1000  -  Loss: 173.8230438232422\n",
            "Epoch: 293/1000  -  Loss: 173.8230438232422\n",
            "Epoch: 294/1000  -  Loss: 173.8225555419922\n",
            "Epoch: 295/1000  -  Loss: 173.8224639892578\n",
            "Epoch: 296/1000  -  Loss: 173.82257080078125\n",
            "Epoch: 297/1000  -  Loss: 173.82275390625\n",
            "Epoch: 298/1000  -  Loss: 173.8227996826172\n",
            "Epoch: 299/1000  -  Loss: 173.8224334716797\n",
            "Epoch: 300/1000  -  Loss: 173.82257080078125\n",
            "Epoch: 301/1000  -  Loss: 173.822998046875\n",
            "Epoch: 302/1000  -  Loss: 173.82232666015625\n",
            "Epoch: 303/1000  -  Loss: 173.82257080078125\n",
            "Epoch: 304/1000  -  Loss: 173.8225860595703\n",
            "Epoch: 305/1000  -  Loss: 173.82286071777344\n",
            "Epoch: 306/1000  -  Loss: 173.82286071777344\n",
            "Epoch: 307/1000  -  Loss: 173.82286071777344\n",
            "Epoch: 308/1000  -  Loss: 173.82252502441406\n",
            "Epoch: 309/1000  -  Loss: 173.82252502441406\n",
            "Epoch: 310/1000  -  Loss: 173.8230438232422\n",
            "Epoch: 311/1000  -  Loss: 173.82305908203125\n",
            "Epoch: 312/1000  -  Loss: 173.82244873046875\n",
            "Epoch: 313/1000  -  Loss: 173.8223876953125\n",
            "Epoch: 314/1000  -  Loss: 173.8231201171875\n",
            "Epoch: 315/1000  -  Loss: 173.8228759765625\n",
            "Epoch: 316/1000  -  Loss: 173.8227996826172\n",
            "Epoch: 317/1000  -  Loss: 173.82298278808594\n",
            "Epoch: 318/1000  -  Loss: 173.82301330566406\n",
            "Epoch: 319/1000  -  Loss: 173.82286071777344\n",
            "Epoch: 320/1000  -  Loss: 173.82257080078125\n",
            "Epoch: 321/1000  -  Loss: 173.8232421875\n",
            "Epoch: 322/1000  -  Loss: 173.8227996826172\n",
            "Epoch: 323/1000  -  Loss: 173.822509765625\n",
            "Epoch: 324/1000  -  Loss: 173.8228759765625\n",
            "Epoch: 325/1000  -  Loss: 173.8226318359375\n",
            "Epoch: 326/1000  -  Loss: 173.8229522705078\n",
            "Epoch: 327/1000  -  Loss: 173.82275390625\n",
            "Epoch: 328/1000  -  Loss: 173.8227081298828\n",
            "Epoch: 329/1000  -  Loss: 173.8229522705078\n",
            "Epoch: 330/1000  -  Loss: 173.8227996826172\n",
            "Epoch: 331/1000  -  Loss: 173.8231201171875\n",
            "Epoch: 332/1000  -  Loss: 173.8226776123047\n",
            "Epoch: 333/1000  -  Loss: 173.8225555419922\n",
            "Epoch: 334/1000  -  Loss: 173.82269287109375\n",
            "Epoch: 335/1000  -  Loss: 173.8227081298828\n",
            "Epoch: 336/1000  -  Loss: 173.8227081298828\n",
            "Epoch: 337/1000  -  Loss: 173.8228759765625\n",
            "Epoch: 338/1000  -  Loss: 173.82273864746094\n",
            "Epoch: 339/1000  -  Loss: 173.8231201171875\n",
            "Epoch: 340/1000  -  Loss: 173.8225555419922\n",
            "Epoch: 341/1000  -  Loss: 173.8226776123047\n",
            "Epoch: 342/1000  -  Loss: 173.82212829589844\n",
            "Epoch: 343/1000  -  Loss: 173.82281494140625\n",
            "Epoch: 344/1000  -  Loss: 173.82273864746094\n",
            "Epoch: 345/1000  -  Loss: 173.822265625\n",
            "Epoch: 346/1000  -  Loss: 173.8229522705078\n",
            "Epoch: 347/1000  -  Loss: 173.82237243652344\n",
            "Epoch: 348/1000  -  Loss: 173.8224334716797\n",
            "Epoch: 349/1000  -  Loss: 173.8228759765625\n",
            "Epoch: 350/1000  -  Loss: 173.82276916503906\n",
            "Epoch: 351/1000  -  Loss: 173.8227081298828\n",
            "Epoch: 352/1000  -  Loss: 173.8223114013672\n",
            "Epoch: 353/1000  -  Loss: 173.82261657714844\n",
            "Epoch: 354/1000  -  Loss: 173.82220458984375\n",
            "Epoch: 355/1000  -  Loss: 173.82208251953125\n",
            "Epoch: 356/1000  -  Loss: 173.8230438232422\n",
            "Epoch: 357/1000  -  Loss: 173.82273864746094\n",
            "Epoch: 358/1000  -  Loss: 173.8229522705078\n",
            "Epoch: 359/1000  -  Loss: 173.82342529296875\n",
            "Epoch: 360/1000  -  Loss: 173.82289123535156\n",
            "Epoch: 361/1000  -  Loss: 173.82249450683594\n",
            "Epoch: 362/1000  -  Loss: 173.82289123535156\n",
            "Epoch: 363/1000  -  Loss: 173.8228302001953\n",
            "Epoch: 364/1000  -  Loss: 173.82264709472656\n",
            "Epoch: 365/1000  -  Loss: 173.8229217529297\n",
            "Epoch: 366/1000  -  Loss: 173.8226318359375\n",
            "Epoch: 367/1000  -  Loss: 173.82261657714844\n",
            "Epoch: 368/1000  -  Loss: 173.8225860595703\n",
            "Epoch: 369/1000  -  Loss: 173.82275390625\n",
            "Epoch: 370/1000  -  Loss: 173.82269287109375\n",
            "Epoch: 371/1000  -  Loss: 173.82281494140625\n",
            "Epoch: 372/1000  -  Loss: 173.8229217529297\n",
            "Epoch: 373/1000  -  Loss: 173.8225860595703\n",
            "Epoch: 374/1000  -  Loss: 173.8232421875\n",
            "Epoch: 375/1000  -  Loss: 173.822998046875\n",
            "Epoch: 376/1000  -  Loss: 173.8227996826172\n",
            "Epoch: 377/1000  -  Loss: 173.82228088378906\n",
            "Epoch: 378/1000  -  Loss: 173.8227996826172\n",
            "Epoch: 379/1000  -  Loss: 173.8228759765625\n",
            "Epoch: 380/1000  -  Loss: 173.82289123535156\n",
            "Epoch: 381/1000  -  Loss: 173.82264709472656\n",
            "Epoch: 382/1000  -  Loss: 173.82276916503906\n",
            "Epoch: 383/1000  -  Loss: 173.82269287109375\n",
            "Epoch: 384/1000  -  Loss: 173.82252502441406\n",
            "Epoch: 385/1000  -  Loss: 173.8227081298828\n",
            "Epoch: 386/1000  -  Loss: 173.8231201171875\n",
            "Epoch: 387/1000  -  Loss: 173.8224334716797\n",
            "Epoch: 388/1000  -  Loss: 173.8225860595703\n",
            "Epoch: 389/1000  -  Loss: 173.8226776123047\n",
            "Epoch: 390/1000  -  Loss: 173.8227996826172\n",
            "Epoch: 391/1000  -  Loss: 173.82293701171875\n",
            "Epoch: 392/1000  -  Loss: 173.822509765625\n",
            "Epoch: 393/1000  -  Loss: 173.8226318359375\n",
            "Epoch: 394/1000  -  Loss: 173.8227996826172\n",
            "Epoch: 395/1000  -  Loss: 173.8225860595703\n",
            "Epoch: 396/1000  -  Loss: 173.822509765625\n",
            "Epoch: 397/1000  -  Loss: 173.8221435546875\n",
            "Epoch: 398/1000  -  Loss: 173.8230743408203\n",
            "Epoch: 399/1000  -  Loss: 173.82275390625\n",
            "Epoch: 400/1000  -  Loss: 173.8230743408203\n",
            "Epoch: 401/1000  -  Loss: 173.82275390625\n",
            "Epoch: 402/1000  -  Loss: 173.82244873046875\n",
            "Epoch: 403/1000  -  Loss: 173.82293701171875\n",
            "Epoch: 404/1000  -  Loss: 173.82249450683594\n",
            "Epoch: 405/1000  -  Loss: 173.8224639892578\n",
            "Epoch: 406/1000  -  Loss: 173.8221435546875\n",
            "Epoch: 407/1000  -  Loss: 173.82252502441406\n",
            "Epoch: 408/1000  -  Loss: 173.82276916503906\n",
            "Epoch: 409/1000  -  Loss: 173.82249450683594\n",
            "Epoch: 410/1000  -  Loss: 173.8226776123047\n",
            "Epoch: 411/1000  -  Loss: 173.82281494140625\n",
            "Epoch: 412/1000  -  Loss: 173.82276916503906\n",
            "Epoch: 413/1000  -  Loss: 173.8229522705078\n",
            "Epoch: 414/1000  -  Loss: 173.82281494140625\n",
            "Epoch: 415/1000  -  Loss: 173.82286071777344\n",
            "Epoch: 416/1000  -  Loss: 173.8223876953125\n",
            "Epoch: 417/1000  -  Loss: 173.8228302001953\n",
            "Epoch: 418/1000  -  Loss: 173.8230743408203\n",
            "Epoch: 419/1000  -  Loss: 173.82275390625\n",
            "Epoch: 420/1000  -  Loss: 173.82264709472656\n",
            "Epoch: 421/1000  -  Loss: 173.82301330566406\n",
            "Epoch: 422/1000  -  Loss: 173.82261657714844\n",
            "Epoch: 423/1000  -  Loss: 173.82257080078125\n",
            "Epoch: 424/1000  -  Loss: 173.82293701171875\n",
            "Epoch: 425/1000  -  Loss: 173.8223419189453\n",
            "Epoch: 426/1000  -  Loss: 173.82293701171875\n",
            "Epoch: 427/1000  -  Loss: 173.8223876953125\n",
            "Epoch: 428/1000  -  Loss: 173.82261657714844\n",
            "Epoch: 429/1000  -  Loss: 173.8223876953125\n",
            "Epoch: 430/1000  -  Loss: 173.82244873046875\n",
            "Epoch: 431/1000  -  Loss: 173.8229217529297\n",
            "Epoch: 432/1000  -  Loss: 173.8229217529297\n",
            "Epoch: 433/1000  -  Loss: 173.82298278808594\n",
            "Epoch: 434/1000  -  Loss: 173.82276916503906\n",
            "Epoch: 435/1000  -  Loss: 173.82261657714844\n",
            "Epoch: 436/1000  -  Loss: 173.82276916503906\n",
            "Epoch: 437/1000  -  Loss: 173.82313537597656\n",
            "Epoch: 438/1000  -  Loss: 173.82293701171875\n",
            "Epoch: 439/1000  -  Loss: 173.8227081298828\n",
            "Epoch: 440/1000  -  Loss: 173.82275390625\n",
            "Epoch: 441/1000  -  Loss: 173.82273864746094\n",
            "Epoch: 442/1000  -  Loss: 173.82244873046875\n",
            "Epoch: 443/1000  -  Loss: 173.8226776123047\n",
            "Epoch: 444/1000  -  Loss: 173.82215881347656\n",
            "Epoch: 445/1000  -  Loss: 173.82298278808594\n",
            "Epoch: 446/1000  -  Loss: 173.8225860595703\n",
            "Epoch: 447/1000  -  Loss: 173.8229217529297\n",
            "Epoch: 448/1000  -  Loss: 173.8224639892578\n",
            "Epoch: 449/1000  -  Loss: 173.8225555419922\n",
            "Epoch: 450/1000  -  Loss: 173.82286071777344\n",
            "Epoch: 451/1000  -  Loss: 173.82273864746094\n",
            "Epoch: 452/1000  -  Loss: 173.8228759765625\n",
            "Epoch: 453/1000  -  Loss: 173.82281494140625\n",
            "Epoch: 454/1000  -  Loss: 173.82286071777344\n",
            "Epoch: 455/1000  -  Loss: 173.822509765625\n",
            "Epoch: 456/1000  -  Loss: 173.82286071777344\n",
            "Epoch: 457/1000  -  Loss: 173.8227996826172\n",
            "Epoch: 458/1000  -  Loss: 173.8226318359375\n",
            "Epoch: 459/1000  -  Loss: 173.82301330566406\n",
            "Epoch: 460/1000  -  Loss: 173.82281494140625\n",
            "Epoch: 461/1000  -  Loss: 173.82252502441406\n",
            "Epoch: 462/1000  -  Loss: 173.82225036621094\n",
            "Epoch: 463/1000  -  Loss: 173.8228759765625\n",
            "Epoch: 464/1000  -  Loss: 173.82237243652344\n",
            "Epoch: 465/1000  -  Loss: 173.8226776123047\n",
            "Epoch: 466/1000  -  Loss: 173.82252502441406\n",
            "Epoch: 467/1000  -  Loss: 173.8223114013672\n",
            "Epoch: 468/1000  -  Loss: 173.82240295410156\n",
            "Epoch: 469/1000  -  Loss: 173.82261657714844\n",
            "Epoch: 470/1000  -  Loss: 173.8231201171875\n",
            "Epoch: 471/1000  -  Loss: 173.8224639892578\n",
            "Epoch: 472/1000  -  Loss: 173.8225860595703\n",
            "Epoch: 473/1000  -  Loss: 173.8222198486328\n",
            "Epoch: 474/1000  -  Loss: 173.82244873046875\n",
            "Epoch: 475/1000  -  Loss: 173.82264709472656\n",
            "Epoch: 476/1000  -  Loss: 173.82301330566406\n",
            "Epoch: 477/1000  -  Loss: 173.8225860595703\n",
            "Epoch: 478/1000  -  Loss: 173.8221893310547\n",
            "Epoch: 479/1000  -  Loss: 173.82276916503906\n",
            "Epoch: 480/1000  -  Loss: 173.82252502441406\n",
            "Epoch: 481/1000  -  Loss: 173.8229522705078\n",
            "Epoch: 482/1000  -  Loss: 173.8224334716797\n",
            "Epoch: 483/1000  -  Loss: 173.8229217529297\n",
            "Epoch: 484/1000  -  Loss: 173.82276916503906\n",
            "Epoch: 485/1000  -  Loss: 173.82281494140625\n",
            "Epoch: 486/1000  -  Loss: 173.82257080078125\n",
            "Epoch: 487/1000  -  Loss: 173.82252502441406\n",
            "Epoch: 488/1000  -  Loss: 173.8227081298828\n",
            "Epoch: 489/1000  -  Loss: 173.82275390625\n",
            "Epoch: 490/1000  -  Loss: 173.82330322265625\n",
            "Epoch: 491/1000  -  Loss: 173.82322692871094\n",
            "Epoch: 492/1000  -  Loss: 173.8225555419922\n",
            "Epoch: 493/1000  -  Loss: 173.8226318359375\n",
            "Epoch: 494/1000  -  Loss: 173.82289123535156\n",
            "Epoch: 495/1000  -  Loss: 173.8227996826172\n",
            "Epoch: 496/1000  -  Loss: 173.82244873046875\n",
            "Epoch: 497/1000  -  Loss: 173.82257080078125\n",
            "Epoch: 498/1000  -  Loss: 173.82298278808594\n",
            "Epoch: 499/1000  -  Loss: 173.82281494140625\n",
            "Epoch: 500/1000  -  Loss: 173.8227996826172\n",
            "Epoch: 501/1000  -  Loss: 173.82276916503906\n",
            "Epoch: 502/1000  -  Loss: 173.8226776123047\n",
            "Epoch: 503/1000  -  Loss: 173.8229217529297\n",
            "Epoch: 504/1000  -  Loss: 173.82301330566406\n",
            "Epoch: 505/1000  -  Loss: 173.8228759765625\n",
            "Epoch: 506/1000  -  Loss: 173.82293701171875\n",
            "Epoch: 507/1000  -  Loss: 173.8227996826172\n",
            "Epoch: 508/1000  -  Loss: 173.822998046875\n",
            "Epoch: 509/1000  -  Loss: 173.8225860595703\n",
            "Epoch: 510/1000  -  Loss: 173.82276916503906\n",
            "Epoch: 511/1000  -  Loss: 173.8225555419922\n",
            "Epoch: 512/1000  -  Loss: 173.82261657714844\n",
            "Epoch: 513/1000  -  Loss: 173.8227996826172\n",
            "Epoch: 514/1000  -  Loss: 173.8226318359375\n",
            "Epoch: 515/1000  -  Loss: 173.8226318359375\n",
            "Epoch: 516/1000  -  Loss: 173.82261657714844\n",
            "Epoch: 517/1000  -  Loss: 173.8225860595703\n",
            "Epoch: 518/1000  -  Loss: 173.82240295410156\n",
            "Epoch: 519/1000  -  Loss: 173.82289123535156\n",
            "Epoch: 520/1000  -  Loss: 173.8229522705078\n",
            "Epoch: 521/1000  -  Loss: 173.8226318359375\n",
            "Epoch: 522/1000  -  Loss: 173.8227081298828\n",
            "Epoch: 523/1000  -  Loss: 173.8226776123047\n",
            "Epoch: 524/1000  -  Loss: 173.82240295410156\n",
            "Epoch: 525/1000  -  Loss: 173.82293701171875\n",
            "Epoch: 526/1000  -  Loss: 173.8226318359375\n",
            "Epoch: 527/1000  -  Loss: 173.82276916503906\n",
            "Epoch: 528/1000  -  Loss: 173.82286071777344\n",
            "Epoch: 529/1000  -  Loss: 173.82240295410156\n",
            "Epoch: 530/1000  -  Loss: 173.8225555419922\n",
            "Epoch: 531/1000  -  Loss: 173.82249450683594\n",
            "Epoch: 532/1000  -  Loss: 173.8222198486328\n",
            "Epoch: 533/1000  -  Loss: 173.82275390625\n",
            "Epoch: 534/1000  -  Loss: 173.82298278808594\n",
            "Epoch: 535/1000  -  Loss: 173.82276916503906\n",
            "Epoch: 536/1000  -  Loss: 173.82275390625\n",
            "Epoch: 537/1000  -  Loss: 173.8223419189453\n",
            "Epoch: 538/1000  -  Loss: 173.82240295410156\n",
            "Epoch: 539/1000  -  Loss: 173.82313537597656\n",
            "Epoch: 540/1000  -  Loss: 173.82249450683594\n",
            "Epoch: 541/1000  -  Loss: 173.82261657714844\n",
            "Epoch: 542/1000  -  Loss: 173.82240295410156\n",
            "Epoch: 543/1000  -  Loss: 173.82281494140625\n",
            "Epoch: 544/1000  -  Loss: 173.82275390625\n",
            "Epoch: 545/1000  -  Loss: 173.82322692871094\n",
            "Epoch: 546/1000  -  Loss: 173.8228302001953\n",
            "Epoch: 547/1000  -  Loss: 173.82286071777344\n",
            "Epoch: 548/1000  -  Loss: 173.82269287109375\n",
            "Epoch: 549/1000  -  Loss: 173.82334899902344\n",
            "Epoch: 550/1000  -  Loss: 173.82273864746094\n",
            "Epoch: 551/1000  -  Loss: 173.8228759765625\n",
            "Epoch: 552/1000  -  Loss: 173.82252502441406\n",
            "Epoch: 553/1000  -  Loss: 173.8226776123047\n",
            "Epoch: 554/1000  -  Loss: 173.82276916503906\n",
            "Epoch: 555/1000  -  Loss: 173.82281494140625\n",
            "Epoch: 556/1000  -  Loss: 173.82276916503906\n",
            "Epoch: 557/1000  -  Loss: 173.8230438232422\n",
            "Epoch: 558/1000  -  Loss: 173.82305908203125\n",
            "Epoch: 559/1000  -  Loss: 173.8224334716797\n",
            "Epoch: 560/1000  -  Loss: 173.82313537597656\n",
            "Epoch: 561/1000  -  Loss: 173.82286071777344\n",
            "Epoch: 562/1000  -  Loss: 173.82261657714844\n",
            "Epoch: 563/1000  -  Loss: 173.82273864746094\n",
            "Epoch: 564/1000  -  Loss: 173.82313537597656\n",
            "Epoch: 565/1000  -  Loss: 173.82276916503906\n",
            "Epoch: 566/1000  -  Loss: 173.82261657714844\n",
            "Epoch: 567/1000  -  Loss: 173.8227996826172\n",
            "Epoch: 568/1000  -  Loss: 173.82275390625\n",
            "Epoch: 569/1000  -  Loss: 173.82232666015625\n",
            "Epoch: 570/1000  -  Loss: 173.82273864746094\n",
            "Epoch: 571/1000  -  Loss: 173.8227996826172\n",
            "Epoch: 572/1000  -  Loss: 173.82257080078125\n",
            "Epoch: 573/1000  -  Loss: 173.8226318359375\n",
            "Epoch: 574/1000  -  Loss: 173.82269287109375\n",
            "Epoch: 575/1000  -  Loss: 173.8226776123047\n",
            "Epoch: 576/1000  -  Loss: 173.8222198486328\n",
            "Epoch: 577/1000  -  Loss: 173.82276916503906\n",
            "Epoch: 578/1000  -  Loss: 173.82276916503906\n",
            "Epoch: 579/1000  -  Loss: 173.8230438232422\n",
            "Epoch: 580/1000  -  Loss: 173.822509765625\n",
            "Epoch: 581/1000  -  Loss: 173.82273864746094\n",
            "Epoch: 582/1000  -  Loss: 173.8224639892578\n",
            "Epoch: 583/1000  -  Loss: 173.8227996826172\n",
            "Epoch: 584/1000  -  Loss: 173.82264709472656\n",
            "Epoch: 585/1000  -  Loss: 173.82261657714844\n",
            "Epoch: 586/1000  -  Loss: 173.8226318359375\n",
            "Epoch: 587/1000  -  Loss: 173.8229217529297\n",
            "Epoch: 588/1000  -  Loss: 173.8225860595703\n",
            "Epoch: 589/1000  -  Loss: 173.82240295410156\n",
            "Epoch: 590/1000  -  Loss: 173.82220458984375\n",
            "Epoch: 591/1000  -  Loss: 173.82298278808594\n",
            "Epoch: 592/1000  -  Loss: 173.8224639892578\n",
            "Epoch: 593/1000  -  Loss: 173.8229217529297\n",
            "Epoch: 594/1000  -  Loss: 173.8221435546875\n",
            "Epoch: 595/1000  -  Loss: 173.82269287109375\n",
            "Epoch: 596/1000  -  Loss: 173.82293701171875\n",
            "Epoch: 597/1000  -  Loss: 173.8234100341797\n",
            "Epoch: 598/1000  -  Loss: 173.82286071777344\n",
            "Epoch: 599/1000  -  Loss: 173.82289123535156\n",
            "Epoch: 600/1000  -  Loss: 173.82310485839844\n",
            "Epoch: 601/1000  -  Loss: 173.82275390625\n",
            "Epoch: 602/1000  -  Loss: 173.8225860595703\n",
            "Epoch: 603/1000  -  Loss: 173.82269287109375\n",
            "Epoch: 604/1000  -  Loss: 173.8229522705078\n",
            "Epoch: 605/1000  -  Loss: 173.82273864746094\n",
            "Epoch: 606/1000  -  Loss: 173.82305908203125\n",
            "Epoch: 607/1000  -  Loss: 173.82273864746094\n",
            "Epoch: 608/1000  -  Loss: 173.82289123535156\n",
            "Epoch: 609/1000  -  Loss: 173.82273864746094\n",
            "Epoch: 610/1000  -  Loss: 173.82269287109375\n",
            "Epoch: 611/1000  -  Loss: 173.8230743408203\n",
            "Epoch: 612/1000  -  Loss: 173.82264709472656\n",
            "Epoch: 613/1000  -  Loss: 173.8225860595703\n",
            "Epoch: 614/1000  -  Loss: 173.82298278808594\n",
            "Epoch: 615/1000  -  Loss: 173.82276916503906\n",
            "Epoch: 616/1000  -  Loss: 173.82275390625\n",
            "Epoch: 617/1000  -  Loss: 173.82289123535156\n",
            "Epoch: 618/1000  -  Loss: 173.8227996826172\n",
            "Epoch: 619/1000  -  Loss: 173.82240295410156\n",
            "Epoch: 620/1000  -  Loss: 173.82275390625\n",
            "Epoch: 621/1000  -  Loss: 173.82281494140625\n",
            "Epoch: 622/1000  -  Loss: 173.822998046875\n",
            "Epoch: 623/1000  -  Loss: 173.8231658935547\n",
            "Epoch: 624/1000  -  Loss: 173.82293701171875\n",
            "Epoch: 625/1000  -  Loss: 173.82276916503906\n",
            "Epoch: 626/1000  -  Loss: 173.8228759765625\n",
            "Epoch: 627/1000  -  Loss: 173.822509765625\n",
            "Epoch: 628/1000  -  Loss: 173.82264709472656\n",
            "Epoch: 629/1000  -  Loss: 173.82261657714844\n",
            "Epoch: 630/1000  -  Loss: 173.8224639892578\n",
            "Epoch: 631/1000  -  Loss: 173.82269287109375\n",
            "Epoch: 632/1000  -  Loss: 173.82298278808594\n",
            "Epoch: 633/1000  -  Loss: 173.82275390625\n",
            "Epoch: 634/1000  -  Loss: 173.822509765625\n",
            "Epoch: 635/1000  -  Loss: 173.8224334716797\n",
            "Epoch: 636/1000  -  Loss: 173.82281494140625\n",
            "Epoch: 637/1000  -  Loss: 173.82269287109375\n",
            "Epoch: 638/1000  -  Loss: 173.82281494140625\n",
            "Epoch: 639/1000  -  Loss: 173.8229522705078\n",
            "Epoch: 640/1000  -  Loss: 173.8229217529297\n",
            "Epoch: 641/1000  -  Loss: 173.8227996826172\n",
            "Epoch: 642/1000  -  Loss: 173.82275390625\n",
            "Epoch: 643/1000  -  Loss: 173.82264709472656\n",
            "Epoch: 644/1000  -  Loss: 173.82273864746094\n",
            "Epoch: 645/1000  -  Loss: 173.82301330566406\n",
            "Epoch: 646/1000  -  Loss: 173.82276916503906\n",
            "Epoch: 647/1000  -  Loss: 173.8227996826172\n",
            "Epoch: 648/1000  -  Loss: 173.82281494140625\n",
            "Epoch: 649/1000  -  Loss: 173.82264709472656\n",
            "Epoch: 650/1000  -  Loss: 173.8224639892578\n",
            "Epoch: 651/1000  -  Loss: 173.82269287109375\n",
            "Epoch: 652/1000  -  Loss: 173.82257080078125\n",
            "Epoch: 653/1000  -  Loss: 173.8223419189453\n",
            "Epoch: 654/1000  -  Loss: 173.8227996826172\n",
            "Epoch: 655/1000  -  Loss: 173.82286071777344\n",
            "Epoch: 656/1000  -  Loss: 173.82276916503906\n",
            "Epoch: 657/1000  -  Loss: 173.8229522705078\n",
            "Epoch: 658/1000  -  Loss: 173.82264709472656\n",
            "Epoch: 659/1000  -  Loss: 173.8228302001953\n",
            "Epoch: 660/1000  -  Loss: 173.82276916503906\n",
            "Epoch: 661/1000  -  Loss: 173.8225860595703\n",
            "Epoch: 662/1000  -  Loss: 173.8224639892578\n",
            "Epoch: 663/1000  -  Loss: 173.82305908203125\n",
            "Epoch: 664/1000  -  Loss: 173.82200622558594\n",
            "Epoch: 665/1000  -  Loss: 173.82273864746094\n",
            "Epoch: 666/1000  -  Loss: 173.8221893310547\n",
            "Epoch: 667/1000  -  Loss: 173.82273864746094\n",
            "Epoch: 668/1000  -  Loss: 173.8228759765625\n",
            "Epoch: 669/1000  -  Loss: 173.82286071777344\n",
            "Epoch: 670/1000  -  Loss: 173.8226318359375\n",
            "Epoch: 671/1000  -  Loss: 173.82249450683594\n",
            "Epoch: 672/1000  -  Loss: 173.82298278808594\n",
            "Epoch: 673/1000  -  Loss: 173.822998046875\n",
            "Epoch: 674/1000  -  Loss: 173.8227996826172\n",
            "Epoch: 675/1000  -  Loss: 173.8226318359375\n",
            "Epoch: 676/1000  -  Loss: 173.8226318359375\n",
            "Epoch: 677/1000  -  Loss: 173.82244873046875\n",
            "Epoch: 678/1000  -  Loss: 173.8225555419922\n",
            "Epoch: 679/1000  -  Loss: 173.82273864746094\n",
            "Epoch: 680/1000  -  Loss: 173.8229217529297\n",
            "Epoch: 681/1000  -  Loss: 173.82293701171875\n",
            "Epoch: 682/1000  -  Loss: 173.82273864746094\n",
            "Epoch: 683/1000  -  Loss: 173.82293701171875\n",
            "Epoch: 684/1000  -  Loss: 173.8227996826172\n",
            "Epoch: 685/1000  -  Loss: 173.8226318359375\n",
            "Epoch: 686/1000  -  Loss: 173.82293701171875\n",
            "Epoch: 687/1000  -  Loss: 173.8228759765625\n",
            "Epoch: 688/1000  -  Loss: 173.8223114013672\n",
            "Epoch: 689/1000  -  Loss: 173.8227081298828\n",
            "Epoch: 690/1000  -  Loss: 173.8225555419922\n",
            "Epoch: 691/1000  -  Loss: 173.82293701171875\n",
            "Epoch: 692/1000  -  Loss: 173.82276916503906\n",
            "Epoch: 693/1000  -  Loss: 173.82281494140625\n",
            "Epoch: 694/1000  -  Loss: 173.82269287109375\n",
            "Epoch: 695/1000  -  Loss: 173.82281494140625\n",
            "Epoch: 696/1000  -  Loss: 173.8228759765625\n",
            "Epoch: 697/1000  -  Loss: 173.82281494140625\n",
            "Epoch: 698/1000  -  Loss: 173.8223876953125\n",
            "Epoch: 699/1000  -  Loss: 173.82286071777344\n",
            "Epoch: 700/1000  -  Loss: 173.82264709472656\n",
            "Epoch: 701/1000  -  Loss: 173.82289123535156\n",
            "Epoch: 702/1000  -  Loss: 173.82264709472656\n",
            "Epoch: 703/1000  -  Loss: 173.8228302001953\n",
            "Epoch: 704/1000  -  Loss: 173.82261657714844\n",
            "Epoch: 705/1000  -  Loss: 173.8230743408203\n",
            "Epoch: 706/1000  -  Loss: 173.82269287109375\n",
            "Epoch: 707/1000  -  Loss: 173.82264709472656\n",
            "Epoch: 708/1000  -  Loss: 173.82264709472656\n",
            "Epoch: 709/1000  -  Loss: 173.82237243652344\n",
            "Epoch: 710/1000  -  Loss: 173.8226318359375\n",
            "Epoch: 711/1000  -  Loss: 173.82269287109375\n",
            "Epoch: 712/1000  -  Loss: 173.8228302001953\n",
            "Epoch: 713/1000  -  Loss: 173.8228759765625\n",
            "Epoch: 714/1000  -  Loss: 173.8229522705078\n",
            "Epoch: 715/1000  -  Loss: 173.8225860595703\n",
            "Epoch: 716/1000  -  Loss: 173.8230438232422\n",
            "Epoch: 717/1000  -  Loss: 173.8226776123047\n",
            "Epoch: 718/1000  -  Loss: 173.82293701171875\n",
            "Epoch: 719/1000  -  Loss: 173.822509765625\n",
            "Epoch: 720/1000  -  Loss: 173.8229217529297\n",
            "Epoch: 721/1000  -  Loss: 173.8229217529297\n",
            "Epoch: 722/1000  -  Loss: 173.82301330566406\n",
            "Epoch: 723/1000  -  Loss: 173.8224639892578\n",
            "Epoch: 724/1000  -  Loss: 173.822509765625\n",
            "Epoch: 725/1000  -  Loss: 173.82301330566406\n",
            "Epoch: 726/1000  -  Loss: 173.82276916503906\n",
            "Epoch: 727/1000  -  Loss: 173.82289123535156\n",
            "Epoch: 728/1000  -  Loss: 173.8230438232422\n",
            "Epoch: 729/1000  -  Loss: 173.82298278808594\n",
            "Epoch: 730/1000  -  Loss: 173.82252502441406\n",
            "Epoch: 731/1000  -  Loss: 173.82269287109375\n",
            "Epoch: 732/1000  -  Loss: 173.8225555419922\n",
            "Epoch: 733/1000  -  Loss: 173.82293701171875\n",
            "Epoch: 734/1000  -  Loss: 173.82273864746094\n",
            "Epoch: 735/1000  -  Loss: 173.8223114013672\n",
            "Epoch: 736/1000  -  Loss: 173.8229217529297\n",
            "Epoch: 737/1000  -  Loss: 173.8231964111328\n",
            "Epoch: 738/1000  -  Loss: 173.82281494140625\n",
            "Epoch: 739/1000  -  Loss: 173.8226318359375\n",
            "Epoch: 740/1000  -  Loss: 173.8225860595703\n",
            "Epoch: 741/1000  -  Loss: 173.8226318359375\n",
            "Epoch: 742/1000  -  Loss: 173.8226318359375\n",
            "Epoch: 743/1000  -  Loss: 173.8229217529297\n",
            "Epoch: 744/1000  -  Loss: 173.82281494140625\n",
            "Epoch: 745/1000  -  Loss: 173.82275390625\n",
            "Epoch: 746/1000  -  Loss: 173.8226318359375\n",
            "Epoch: 747/1000  -  Loss: 173.822998046875\n",
            "Epoch: 748/1000  -  Loss: 173.8228759765625\n",
            "Epoch: 749/1000  -  Loss: 173.8231964111328\n",
            "Epoch: 750/1000  -  Loss: 173.8225555419922\n",
            "Epoch: 751/1000  -  Loss: 173.822509765625\n",
            "Epoch: 752/1000  -  Loss: 173.82257080078125\n",
            "Epoch: 753/1000  -  Loss: 173.82237243652344\n",
            "Epoch: 754/1000  -  Loss: 173.82289123535156\n",
            "Epoch: 755/1000  -  Loss: 173.82286071777344\n",
            "Epoch: 756/1000  -  Loss: 173.82237243652344\n",
            "Epoch: 757/1000  -  Loss: 173.8225555419922\n",
            "Epoch: 758/1000  -  Loss: 173.82289123535156\n",
            "Epoch: 759/1000  -  Loss: 173.82240295410156\n",
            "Epoch: 760/1000  -  Loss: 173.82261657714844\n",
            "Epoch: 761/1000  -  Loss: 173.8227996826172\n",
            "Epoch: 762/1000  -  Loss: 173.82252502441406\n",
            "Epoch: 763/1000  -  Loss: 173.8229217529297\n",
            "Epoch: 764/1000  -  Loss: 173.82232666015625\n",
            "Epoch: 765/1000  -  Loss: 173.82249450683594\n",
            "Epoch: 766/1000  -  Loss: 173.8224639892578\n",
            "Epoch: 767/1000  -  Loss: 173.82264709472656\n",
            "Epoch: 768/1000  -  Loss: 173.8234405517578\n",
            "Epoch: 769/1000  -  Loss: 173.8227996826172\n",
            "Epoch: 770/1000  -  Loss: 173.82275390625\n",
            "Epoch: 771/1000  -  Loss: 173.82281494140625\n",
            "Epoch: 772/1000  -  Loss: 173.8227081298828\n",
            "Epoch: 773/1000  -  Loss: 173.8228302001953\n",
            "Epoch: 774/1000  -  Loss: 173.82347106933594\n",
            "Epoch: 775/1000  -  Loss: 173.82257080078125\n",
            "Epoch: 776/1000  -  Loss: 173.82269287109375\n",
            "Epoch: 777/1000  -  Loss: 173.82273864746094\n",
            "Epoch: 778/1000  -  Loss: 173.82264709472656\n",
            "Epoch: 779/1000  -  Loss: 173.82273864746094\n",
            "Epoch: 780/1000  -  Loss: 173.82261657714844\n",
            "Epoch: 781/1000  -  Loss: 173.82261657714844\n",
            "Epoch: 782/1000  -  Loss: 173.82249450683594\n",
            "Epoch: 783/1000  -  Loss: 173.82293701171875\n",
            "Epoch: 784/1000  -  Loss: 173.82252502441406\n",
            "Epoch: 785/1000  -  Loss: 173.82286071777344\n",
            "Epoch: 786/1000  -  Loss: 173.82264709472656\n",
            "Epoch: 787/1000  -  Loss: 173.8225555419922\n",
            "Epoch: 788/1000  -  Loss: 173.8225860595703\n",
            "Epoch: 789/1000  -  Loss: 173.8229522705078\n",
            "Epoch: 790/1000  -  Loss: 173.82281494140625\n",
            "Epoch: 791/1000  -  Loss: 173.8225860595703\n",
            "Epoch: 792/1000  -  Loss: 173.8227996826172\n",
            "Epoch: 793/1000  -  Loss: 173.82252502441406\n",
            "Epoch: 794/1000  -  Loss: 173.82261657714844\n",
            "Epoch: 795/1000  -  Loss: 173.82276916503906\n",
            "Epoch: 796/1000  -  Loss: 173.82269287109375\n",
            "Epoch: 797/1000  -  Loss: 173.82281494140625\n",
            "Epoch: 798/1000  -  Loss: 173.82276916503906\n",
            "Epoch: 799/1000  -  Loss: 173.82269287109375\n",
            "Epoch: 800/1000  -  Loss: 173.8227996826172\n",
            "Epoch: 801/1000  -  Loss: 173.82275390625\n",
            "Epoch: 802/1000  -  Loss: 173.82305908203125\n",
            "Epoch: 803/1000  -  Loss: 173.82261657714844\n",
            "Epoch: 804/1000  -  Loss: 173.82305908203125\n",
            "Epoch: 805/1000  -  Loss: 173.8227996826172\n",
            "Epoch: 806/1000  -  Loss: 173.82257080078125\n",
            "Epoch: 807/1000  -  Loss: 173.8228302001953\n",
            "Epoch: 808/1000  -  Loss: 173.82281494140625\n",
            "Epoch: 809/1000  -  Loss: 173.8225555419922\n",
            "Epoch: 810/1000  -  Loss: 173.82273864746094\n",
            "Epoch: 811/1000  -  Loss: 173.82275390625\n",
            "Epoch: 812/1000  -  Loss: 173.822998046875\n",
            "Epoch: 813/1000  -  Loss: 173.82275390625\n",
            "Epoch: 814/1000  -  Loss: 173.8225860595703\n",
            "Epoch: 815/1000  -  Loss: 173.82264709472656\n",
            "Epoch: 816/1000  -  Loss: 173.82293701171875\n",
            "Epoch: 817/1000  -  Loss: 173.82249450683594\n",
            "Epoch: 818/1000  -  Loss: 173.8230743408203\n",
            "Epoch: 819/1000  -  Loss: 173.8227081298828\n",
            "Epoch: 820/1000  -  Loss: 173.8227996826172\n",
            "Epoch: 821/1000  -  Loss: 173.822998046875\n",
            "Epoch: 822/1000  -  Loss: 173.82261657714844\n",
            "Epoch: 823/1000  -  Loss: 173.8222198486328\n",
            "Epoch: 824/1000  -  Loss: 173.82276916503906\n",
            "Epoch: 825/1000  -  Loss: 173.8224639892578\n",
            "Epoch: 826/1000  -  Loss: 173.82281494140625\n",
            "Epoch: 827/1000  -  Loss: 173.82261657714844\n",
            "Epoch: 828/1000  -  Loss: 173.8225555419922\n",
            "Epoch: 829/1000  -  Loss: 173.8229522705078\n",
            "Epoch: 830/1000  -  Loss: 173.82276916503906\n",
            "Epoch: 831/1000  -  Loss: 173.82313537597656\n",
            "Epoch: 832/1000  -  Loss: 173.822509765625\n",
            "Epoch: 833/1000  -  Loss: 173.8224639892578\n",
            "Epoch: 834/1000  -  Loss: 173.82281494140625\n",
            "Epoch: 835/1000  -  Loss: 173.82276916503906\n",
            "Epoch: 836/1000  -  Loss: 173.82281494140625\n",
            "Epoch: 837/1000  -  Loss: 173.8229217529297\n",
            "Epoch: 838/1000  -  Loss: 173.82293701171875\n",
            "Epoch: 839/1000  -  Loss: 173.8227996826172\n",
            "Epoch: 840/1000  -  Loss: 173.8228759765625\n",
            "Epoch: 841/1000  -  Loss: 173.8228759765625\n",
            "Epoch: 842/1000  -  Loss: 173.8223876953125\n",
            "Epoch: 843/1000  -  Loss: 173.82275390625\n",
            "Epoch: 844/1000  -  Loss: 173.8225860595703\n",
            "Epoch: 845/1000  -  Loss: 173.8228302001953\n",
            "Epoch: 846/1000  -  Loss: 173.8227996826172\n",
            "Epoch: 847/1000  -  Loss: 173.8225555419922\n",
            "Epoch: 848/1000  -  Loss: 173.82252502441406\n",
            "Epoch: 849/1000  -  Loss: 173.8225860595703\n",
            "Epoch: 850/1000  -  Loss: 173.8228759765625\n",
            "Epoch: 851/1000  -  Loss: 173.82273864746094\n",
            "Epoch: 852/1000  -  Loss: 173.82257080078125\n",
            "Epoch: 853/1000  -  Loss: 173.82232666015625\n",
            "Epoch: 854/1000  -  Loss: 173.82249450683594\n",
            "Epoch: 855/1000  -  Loss: 173.8227081298828\n",
            "Epoch: 856/1000  -  Loss: 173.8226318359375\n",
            "Epoch: 857/1000  -  Loss: 173.82228088378906\n",
            "Epoch: 858/1000  -  Loss: 173.82275390625\n",
            "Epoch: 859/1000  -  Loss: 173.8227996826172\n",
            "Epoch: 860/1000  -  Loss: 173.82240295410156\n",
            "Epoch: 861/1000  -  Loss: 173.82286071777344\n",
            "Epoch: 862/1000  -  Loss: 173.8224334716797\n",
            "Epoch: 863/1000  -  Loss: 173.82276916503906\n",
            "Epoch: 864/1000  -  Loss: 173.82276916503906\n",
            "Epoch: 865/1000  -  Loss: 173.82273864746094\n",
            "Epoch: 866/1000  -  Loss: 173.82313537597656\n",
            "Epoch: 867/1000  -  Loss: 173.82275390625\n",
            "Epoch: 868/1000  -  Loss: 173.82228088378906\n",
            "Epoch: 869/1000  -  Loss: 173.8226776123047\n",
            "Epoch: 870/1000  -  Loss: 173.8223419189453\n",
            "Epoch: 871/1000  -  Loss: 173.82252502441406\n",
            "Epoch: 872/1000  -  Loss: 173.8227996826172\n",
            "Epoch: 873/1000  -  Loss: 173.822998046875\n",
            "Epoch: 874/1000  -  Loss: 173.8228759765625\n",
            "Epoch: 875/1000  -  Loss: 173.8225860595703\n",
            "Epoch: 876/1000  -  Loss: 173.8225555419922\n",
            "Epoch: 877/1000  -  Loss: 173.8228759765625\n",
            "Epoch: 878/1000  -  Loss: 173.8227996826172\n",
            "Epoch: 879/1000  -  Loss: 173.82244873046875\n",
            "Epoch: 880/1000  -  Loss: 173.822265625\n",
            "Epoch: 881/1000  -  Loss: 173.82293701171875\n",
            "Epoch: 882/1000  -  Loss: 173.82293701171875\n",
            "Epoch: 883/1000  -  Loss: 173.82269287109375\n",
            "Epoch: 884/1000  -  Loss: 173.82275390625\n",
            "Epoch: 885/1000  -  Loss: 173.82275390625\n",
            "Epoch: 886/1000  -  Loss: 173.8229522705078\n",
            "Epoch: 887/1000  -  Loss: 173.82240295410156\n",
            "Epoch: 888/1000  -  Loss: 173.8229522705078\n",
            "Epoch: 889/1000  -  Loss: 173.82276916503906\n",
            "Epoch: 890/1000  -  Loss: 173.8228302001953\n",
            "Epoch: 891/1000  -  Loss: 173.82269287109375\n",
            "Epoch: 892/1000  -  Loss: 173.8226776123047\n",
            "Epoch: 893/1000  -  Loss: 173.82273864746094\n",
            "Epoch: 894/1000  -  Loss: 173.8226318359375\n",
            "Epoch: 895/1000  -  Loss: 173.8229217529297\n",
            "Epoch: 896/1000  -  Loss: 173.82244873046875\n",
            "Epoch: 897/1000  -  Loss: 173.82275390625\n",
            "Epoch: 898/1000  -  Loss: 173.82286071777344\n",
            "Epoch: 899/1000  -  Loss: 173.8231658935547\n",
            "Epoch: 900/1000  -  Loss: 173.82298278808594\n",
            "Epoch: 901/1000  -  Loss: 173.82261657714844\n",
            "Epoch: 902/1000  -  Loss: 173.8227996826172\n",
            "Epoch: 903/1000  -  Loss: 173.82264709472656\n",
            "Epoch: 904/1000  -  Loss: 173.82269287109375\n",
            "Epoch: 905/1000  -  Loss: 173.82228088378906\n",
            "Epoch: 906/1000  -  Loss: 173.82273864746094\n",
            "Epoch: 907/1000  -  Loss: 173.8230438232422\n",
            "Epoch: 908/1000  -  Loss: 173.8225860595703\n",
            "Epoch: 909/1000  -  Loss: 173.82269287109375\n",
            "Epoch: 910/1000  -  Loss: 173.82275390625\n",
            "Epoch: 911/1000  -  Loss: 173.8228759765625\n",
            "Epoch: 912/1000  -  Loss: 173.8226776123047\n",
            "Epoch: 913/1000  -  Loss: 173.82252502441406\n",
            "Epoch: 914/1000  -  Loss: 173.82301330566406\n",
            "Epoch: 915/1000  -  Loss: 173.82273864746094\n",
            "Epoch: 916/1000  -  Loss: 173.8228759765625\n",
            "Epoch: 917/1000  -  Loss: 173.8227996826172\n",
            "Epoch: 918/1000  -  Loss: 173.822998046875\n",
            "Epoch: 919/1000  -  Loss: 173.82301330566406\n",
            "Epoch: 920/1000  -  Loss: 173.8226318359375\n",
            "Epoch: 921/1000  -  Loss: 173.822998046875\n",
            "Epoch: 922/1000  -  Loss: 173.8228302001953\n",
            "Epoch: 923/1000  -  Loss: 173.8227996826172\n",
            "Epoch: 924/1000  -  Loss: 173.82252502441406\n",
            "Epoch: 925/1000  -  Loss: 173.8227081298828\n",
            "Epoch: 926/1000  -  Loss: 173.82257080078125\n",
            "Epoch: 927/1000  -  Loss: 173.82252502441406\n",
            "Epoch: 928/1000  -  Loss: 173.82293701171875\n",
            "Epoch: 929/1000  -  Loss: 173.8230743408203\n",
            "Epoch: 930/1000  -  Loss: 173.82264709472656\n",
            "Epoch: 931/1000  -  Loss: 173.82261657714844\n",
            "Epoch: 932/1000  -  Loss: 173.8225860595703\n",
            "Epoch: 933/1000  -  Loss: 173.822265625\n",
            "Epoch: 934/1000  -  Loss: 173.8228302001953\n",
            "Epoch: 935/1000  -  Loss: 173.82281494140625\n",
            "Epoch: 936/1000  -  Loss: 173.82286071777344\n",
            "Epoch: 937/1000  -  Loss: 173.82261657714844\n",
            "Epoch: 938/1000  -  Loss: 173.82298278808594\n",
            "Epoch: 939/1000  -  Loss: 173.82261657714844\n",
            "Epoch: 940/1000  -  Loss: 173.82252502441406\n",
            "Epoch: 941/1000  -  Loss: 173.82275390625\n",
            "Epoch: 942/1000  -  Loss: 173.82325744628906\n",
            "Epoch: 943/1000  -  Loss: 173.8228759765625\n",
            "Epoch: 944/1000  -  Loss: 173.8229217529297\n",
            "Epoch: 945/1000  -  Loss: 173.8227996826172\n",
            "Epoch: 946/1000  -  Loss: 173.82244873046875\n",
            "Epoch: 947/1000  -  Loss: 173.8223114013672\n",
            "Epoch: 948/1000  -  Loss: 173.8223419189453\n",
            "Epoch: 949/1000  -  Loss: 173.822509765625\n",
            "Epoch: 950/1000  -  Loss: 173.822509765625\n",
            "Epoch: 951/1000  -  Loss: 173.82276916503906\n",
            "Epoch: 952/1000  -  Loss: 173.822509765625\n",
            "Epoch: 953/1000  -  Loss: 173.8229522705078\n",
            "Epoch: 954/1000  -  Loss: 173.8226318359375\n",
            "Epoch: 955/1000  -  Loss: 173.8230743408203\n",
            "Epoch: 956/1000  -  Loss: 173.8223876953125\n",
            "Epoch: 957/1000  -  Loss: 173.8230438232422\n",
            "Epoch: 958/1000  -  Loss: 173.8228302001953\n",
            "Epoch: 959/1000  -  Loss: 173.8228302001953\n",
            "Epoch: 960/1000  -  Loss: 173.82252502441406\n",
            "Epoch: 961/1000  -  Loss: 173.8228302001953\n",
            "Epoch: 962/1000  -  Loss: 173.8226776123047\n",
            "Epoch: 963/1000  -  Loss: 173.8229522705078\n",
            "Epoch: 964/1000  -  Loss: 173.82281494140625\n",
            "Epoch: 965/1000  -  Loss: 173.8228302001953\n",
            "Epoch: 966/1000  -  Loss: 173.82269287109375\n",
            "Epoch: 967/1000  -  Loss: 173.8227081298828\n",
            "Epoch: 968/1000  -  Loss: 173.8229217529297\n",
            "Epoch: 969/1000  -  Loss: 173.8227996826172\n",
            "Epoch: 970/1000  -  Loss: 173.82261657714844\n",
            "Epoch: 971/1000  -  Loss: 173.82249450683594\n",
            "Epoch: 972/1000  -  Loss: 173.82276916503906\n",
            "Epoch: 973/1000  -  Loss: 173.82261657714844\n",
            "Epoch: 974/1000  -  Loss: 173.82244873046875\n",
            "Epoch: 975/1000  -  Loss: 173.8231201171875\n",
            "Epoch: 976/1000  -  Loss: 173.8226318359375\n",
            "Epoch: 977/1000  -  Loss: 173.82289123535156\n",
            "Epoch: 978/1000  -  Loss: 173.8226318359375\n",
            "Epoch: 979/1000  -  Loss: 173.82240295410156\n",
            "Epoch: 980/1000  -  Loss: 173.82286071777344\n",
            "Epoch: 981/1000  -  Loss: 173.82275390625\n",
            "Epoch: 982/1000  -  Loss: 173.82281494140625\n",
            "Epoch: 983/1000  -  Loss: 173.8231964111328\n",
            "Epoch: 984/1000  -  Loss: 173.82244873046875\n",
            "Epoch: 985/1000  -  Loss: 173.8223876953125\n",
            "Epoch: 986/1000  -  Loss: 173.82276916503906\n",
            "Epoch: 987/1000  -  Loss: 173.8228302001953\n",
            "Epoch: 988/1000  -  Loss: 173.8225555419922\n",
            "Epoch: 989/1000  -  Loss: 173.82273864746094\n",
            "Epoch: 990/1000  -  Loss: 173.82252502441406\n",
            "Epoch: 991/1000  -  Loss: 173.8225860595703\n",
            "Epoch: 992/1000  -  Loss: 173.82232666015625\n",
            "Epoch: 993/1000  -  Loss: 173.82276916503906\n",
            "Epoch: 994/1000  -  Loss: 173.82264709472656\n",
            "Epoch: 995/1000  -  Loss: 173.82257080078125\n",
            "Epoch: 996/1000  -  Loss: 173.8224639892578\n",
            "Epoch: 997/1000  -  Loss: 173.8230743408203\n",
            "Epoch: 998/1000  -  Loss: 173.8227081298828\n",
            "Epoch: 999/1000  -  Loss: 173.8226318359375\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "num_topics = 5\n",
        "t_hidden_size = 100\n",
        "rho_size = len(embedding_data[0])\n",
        "emb_size = len(embedding_data[0])\n",
        "theta_act = \"relu\"\n",
        "\n",
        "class TrainArguments:\n",
        "      def __init__(self, epochs, batch_size, log_interval):\n",
        "          self.epochs = epochs\n",
        "          self.batch_size = batch_size\n",
        "          self.log_interval = log_interval\n",
        "\n",
        "class OptimizerArguments:\n",
        "      def __init__(self, optimizer_name, lr, wdecay):\n",
        "            self.optimizer = optimizer_name\n",
        "            self.lr = lr\n",
        "            self.wdecay = wdecay\n",
        "            \n",
        "train_args = TrainArguments(epochs=1000, batch_size=6, log_interval=None)\n",
        "optimizer_args = OptimizerArguments(optimizer_name=\"adam\", lr=0.001, wdecay=0.1)\n",
        "\n",
        "print(train_args.epochs)\n",
        "print(optimizer_args.optimizer)\n",
        "\n",
        "training_set = train_set\n",
        "\n",
        "# define the ETM-model with setting-parameters\n",
        "etm_model = ETM(\n",
        "      num_topics, \n",
        "      vocab_size, \n",
        "      t_hidden_size, rho_size, emb_size, theta_act, \n",
        "      embedding_data, \n",
        "      enc_drop=0.5)\n",
        "\n",
        "# start training\n",
        "train_class = TrainETM().train(\n",
        "    etm_model,\n",
        "    vocab_size, \n",
        "    train_args, optimizer_args, training_set) \n",
        "    #num_topics, t_hidden_size, rho_size, emb_size, theta_act, embedding_data, 0.5)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "notebook_replication.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}