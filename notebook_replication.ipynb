{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hanhluukim/replication-topic-modelling-in-embedding-space/blob/main/notebook_replication.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PJ7P852F7yzU"
      },
      "source": [
        "# **Das Projekt aus dem Github klonen und in den Projektsordner**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "id": "riOxinNHJcIB"
      },
      "outputs": [],
      "source": [
        "#wenn die Ordner noch nicht geklont ist, soll dieser Fehler zuerst durchgeführt werden.\n",
        "#!git clone https://github.com/hanhluukim/replication-topic-modelling-in-embedding-space.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B_6em-5qJg5e",
        "outputId": "a7fec29d-2f46-43ac-e1f1-84c0b0fbdcfc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/replication-topic-modelling-in-embedding-space\n"
          ]
        }
      ],
      "source": [
        "cd /content/replication-topic-modelling-in-embedding-space"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6AAG98vV1JCg"
      },
      "source": [
        "#**Die benötige Paketen für das Projekt mittels requirements.txt installieren**\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YcBay625sD5D",
        "outputId": "b5d4d010-0201-48c8-fb81-3b9660556662"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: gensim in /usr/local/lib/python3.7/dist-packages (from -r /content/replication-topic-modelling-in-embedding-space/requirements.txt (line 1)) (3.6.0)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.7/dist-packages (from -r /content/replication-topic-modelling-in-embedding-space/requirements.txt (line 2)) (3.2.5)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from -r /content/replication-topic-modelling-in-embedding-space/requirements.txt (line 3)) (1.21.6)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from -r /content/replication-topic-modelling-in-embedding-space/requirements.txt (line 4)) (1.0.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from -r /content/replication-topic-modelling-in-embedding-space/requirements.txt (line 5)) (1.4.1)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.7/dist-packages (from -r /content/replication-topic-modelling-in-embedding-space/requirements.txt (line 6)) (1.11.0+cu113)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.7/dist-packages (from -r /content/replication-topic-modelling-in-embedding-space/requirements.txt (line 7)) (4.18.0)\n",
            "Requirement already satisfied: umap-learn in /usr/local/lib/python3.7/dist-packages (from -r /content/replication-topic-modelling-in-embedding-space/requirements.txt (line 8)) (0.5.3)\n",
            "Requirement already satisfied: plotly==5.7.0 in /usr/local/lib/python3.7/dist-packages (from -r /content/replication-topic-modelling-in-embedding-space/requirements.txt (line 9)) (5.7.0)\n",
            "Requirement already satisfied: pathlib in /usr/local/lib/python3.7/dist-packages (from -r /content/replication-topic-modelling-in-embedding-space/requirements.txt (line 10)) (1.0.1)\n",
            "Requirement already satisfied: pyyaml==5.4.1 in /usr/local/lib/python3.7/dist-packages (from -r /content/replication-topic-modelling-in-embedding-space/requirements.txt (line 11)) (5.4.1)\n",
            "Requirement already satisfied: kaleido in /usr/local/lib/python3.7/dist-packages (from -r /content/replication-topic-modelling-in-embedding-space/requirements.txt (line 12)) (0.2.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from plotly==5.7.0->-r /content/replication-topic-modelling-in-embedding-space/requirements.txt (line 9)) (1.15.0)\n",
            "Requirement already satisfied: tenacity>=6.2.0 in /usr/local/lib/python3.7/dist-packages (from plotly==5.7.0->-r /content/replication-topic-modelling-in-embedding-space/requirements.txt (line 9)) (8.0.1)\n",
            "Requirement already satisfied: smart-open>=1.2.1 in /usr/local/lib/python3.7/dist-packages (from gensim->-r /content/replication-topic-modelling-in-embedding-space/requirements.txt (line 1)) (6.0.0)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->-r /content/replication-topic-modelling-in-embedding-space/requirements.txt (line 4)) (1.1.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->-r /content/replication-topic-modelling-in-embedding-space/requirements.txt (line 4)) (3.1.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch->-r /content/replication-topic-modelling-in-embedding-space/requirements.txt (line 6)) (4.2.0)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers->-r /content/replication-topic-modelling-in-embedding-space/requirements.txt (line 7)) (4.11.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers->-r /content/replication-topic-modelling-in-embedding-space/requirements.txt (line 7)) (3.6.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers->-r /content/replication-topic-modelling-in-embedding-space/requirements.txt (line 7)) (21.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers->-r /content/replication-topic-modelling-in-embedding-space/requirements.txt (line 7)) (4.64.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.1.0 in /usr/local/lib/python3.7/dist-packages (from transformers->-r /content/replication-topic-modelling-in-embedding-space/requirements.txt (line 7)) (0.5.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers->-r /content/replication-topic-modelling-in-embedding-space/requirements.txt (line 7)) (2019.12.20)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers->-r /content/replication-topic-modelling-in-embedding-space/requirements.txt (line 7)) (0.0.53)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.13,>=0.11.1 in /usr/local/lib/python3.7/dist-packages (from transformers->-r /content/replication-topic-modelling-in-embedding-space/requirements.txt (line 7)) (0.12.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers->-r /content/replication-topic-modelling-in-embedding-space/requirements.txt (line 7)) (2.23.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers->-r /content/replication-topic-modelling-in-embedding-space/requirements.txt (line 7)) (3.0.8)\n",
            "Requirement already satisfied: numba>=0.49 in /usr/local/lib/python3.7/dist-packages (from umap-learn->-r /content/replication-topic-modelling-in-embedding-space/requirements.txt (line 8)) (0.51.2)\n",
            "Requirement already satisfied: pynndescent>=0.5 in /usr/local/lib/python3.7/dist-packages (from umap-learn->-r /content/replication-topic-modelling-in-embedding-space/requirements.txt (line 8)) (0.5.6)\n",
            "Requirement already satisfied: llvmlite<0.35,>=0.34.0.dev0 in /usr/local/lib/python3.7/dist-packages (from numba>=0.49->umap-learn->-r /content/replication-topic-modelling-in-embedding-space/requirements.txt (line 8)) (0.34.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from numba>=0.49->umap-learn->-r /content/replication-topic-modelling-in-embedding-space/requirements.txt (line 8)) (57.4.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers->-r /content/replication-topic-modelling-in-embedding-space/requirements.txt (line 7)) (3.8.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers->-r /content/replication-topic-modelling-in-embedding-space/requirements.txt (line 7)) (2021.10.8)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers->-r /content/replication-topic-modelling-in-embedding-space/requirements.txt (line 7)) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers->-r /content/replication-topic-modelling-in-embedding-space/requirements.txt (line 7)) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers->-r /content/replication-topic-modelling-in-embedding-space/requirements.txt (line 7)) (1.24.3)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers->-r /content/replication-topic-modelling-in-embedding-space/requirements.txt (line 7)) (7.1.2)\n"
          ]
        }
      ],
      "source": [
        "# Falls die Packages noch nicht installiert wurden, \n",
        "!pip install -r \"/content/replication-topic-modelling-in-embedding-space/requirements.txt\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k7xiPgja8eZe"
      },
      "source": [
        "# **Gebrauchte Paketen importieren**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "id": "uV7KZhGq1P7g"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from pathlib import Path\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "import umap.umap_ as umap\n",
        "import time\n",
        "import plotly.express as px\n",
        "from sklearn import cluster\n",
        "from sklearn import metrics"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QzWqQhPQdJWV"
      },
      "source": [
        "# **Vorverarbeitung und BOW-Repräsentationen für Textdaten durchführen**\n",
        "1. Vocabular erstellen\n",
        "2. BOW-Repräsentationen für allen Teildatensätzen"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "id": "1OCULr82pfgk"
      },
      "outputs": [],
      "source": [
        "from src.prepare_dataset import TextDataLoader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cy0PpjxEpbrR",
        "outputId": "7219d945-582f-4173-8447-2b5c4dd31818"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loading texts: ...\n",
            "finished load!\n",
            "check some sample texts of the dataset\n",
            "['From', ':', 'lerxst', '@', 'wam', '.', 'umd', '.', 'edu', '(', \"where's\", 'my', 'thing', ')', 'Subject', ':', 'WHAT', 'car', 'is', 'this', '!', '?', 'Nntp', 'Posting', 'Host', ':', 'rac3', '.', 'wam', '.', 'umd', '.', 'edu', 'Organization', ':', 'University', 'of', 'Maryland', ',', 'College', 'Park', 'Lines', ':', '15', 'I', 'was', 'wondering', 'if', 'anyone', 'out', 'there', 'could', 'enlighten', 'me', 'on', 'this', 'car', 'I', 'saw', 'the', 'other', 'day', '.', 'It', 'was', 'a', '2', 'door', 'sports', 'car', ',', 'looked', 'to', 'be', 'from', 'the', 'late', '60s', '/', 'early', '70s', '.', 'It', 'was', 'called', 'a', 'Bricklin', '.', 'The', 'doors', 'were', 'really', 'small', '.', 'In', 'addition', ',', 'the', 'front', 'bumper', 'was', 'separate', 'from', 'the', 'rest', 'of', 'the', 'body', '.', 'This', 'is', 'all', 'I', 'know', '.', 'If', 'anyone', 'can', 'tellme', 'a', 'model', 'name', ',', 'engine', 'specs', ',', 'years', 'of', 'production', ',', 'where', 'this', 'car', 'is', 'made', ',', 'history', ',', 'or', 'whatever', 'info', 'you', 'have', 'on', 'this', 'funky', 'looking', 'car', ',', 'please', 'e', 'mail', '.', 'Thanks', ',', 'IL', 'brought', 'to', 'you', 'by', 'your', 'neighborhood', 'Lerxst']\n",
            "====================================================================================================\n",
            "['From', ':', 'guykuo', '@', 'carson', '.', 'u', '.', 'washington', '.', 'edu', '(', 'Guy', 'Kuo', ')', 'Subject', ':', 'SI', 'Clock', 'Poll', 'Final', 'Call', 'Summary', ':', 'Final', 'call', 'for', 'SI', 'clock', 'reports', 'Keywords', ':', 'SI', ',', 'acceleration', ',', 'clock', ',', 'upgrade', 'Article', 'I', '.', 'D', '.', ':', 'shelley', '.', '1qvfo9INNc3s', 'Organization', ':', 'University', 'of', 'Washington', 'Lines', ':', '11', 'NNTP', 'Posting', 'Host', ':', 'carson', '.', 'u', '.', 'washington', '.', 'edu', 'A', 'fair', 'number', 'of', 'brave', 'souls', 'who', 'upgraded', 'their', 'SI', 'clock', 'oscillator', 'have', 'shared', 'their', 'experiences', 'for', 'this', 'poll', '.', 'Please', 'send', 'a', 'brief', 'message', 'detailing', 'your', 'experiences', 'with', 'the', 'procedure', '.', 'Top', 'speed', 'attained', ',', 'CPU', 'rated', 'speed', ',', 'add', 'on', 'cards', 'and', 'adapters', ',', 'heat', 'sinks', ',', 'hour', 'of', 'usage', 'per', 'day', ',', 'floppy', 'disk', 'functionality', 'with', '800', 'and', '1', '.', '4', 'm', 'floppies', 'are', 'especially', 'requested', '.', 'I', 'will', 'be', 'summarizing', 'in', 'the', 'next', 'two', 'days', ',', 'so', 'please', 'add', 'to', 'the', 'network', 'knowledge', 'base', 'if', 'you', 'have', 'done', 'the', 'clock', 'upgrade', 'and', \"haven't\", 'answered', 'this', 'poll', '.', 'Thanks', '.', 'Guy', 'Kuo', '<', 'guykuo', '@', 'u', '.', 'washington', '.', 'edu', '>']\n",
            "====================================================================================================\n"
          ]
        }
      ],
      "source": [
        "# init TextDataLoader für die Datenquelle 20 News Groups\n",
        "# Daten abrufen vom Sklearn, tokenisieren und besondere Charaktern entfernen\n",
        "textsloader = TextDataLoader(source=\"20newsgroups\", train_size=None, test_size=None)\n",
        "textsloader.load_tokenize_texts(\"20newsgroups\")\n",
        "# Beispiel von Textdaten\n",
        "textsloader.show_example_raw_texts(n_docs=2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5odpQDJ7qPTt",
        "outputId": "4b210143-58c1-45df-e591-b4758e820ef6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "start: preprocessing: ...\n",
            "finised: preprocessing!\n"
          ]
        }
      ],
      "source": [
        "# Vorverarbeitung von Daten mit folgenden Schritten:\n",
        "textsloader.preprocess_texts(length_one_remove=True, punctuation_lower = True, stopwords_filter = True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PRRCNPa9qXfq",
        "outputId": "e95a754b-dd5d-4386-d2e8-be8989eb526e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "test-document-frequency: \n",
            "[[ 15  17  12  18  11  16  14  20  12  17  19 135  16  10  15  36  15  19\n",
            "   11  21  11  10  35  10  13  17  21  54  10  30  24  10  10  15  13  12\n",
            "   31  29  17  14  10  14  10  10  11  12  12  14  10  17  13  11  13  57\n",
            "   10  13  12  10  27  12  11  22  19  45  18  20  13  19  21  15  14  13\n",
            "   19  17  12  16  11  11  62  12  10  10  17  13  11  10  14  11  28  23\n",
            "   14  12  10  11  11  30  10  19  16  12  14  10  35  12  13  11  21  17\n",
            "   12  13  13  10  10  15  22  19  46  14  13  28  26  16  10  17  16  25\n",
            "   11  10  23  10  17  10  12  10  10  13 136  13  11  17  13  17  11  22\n",
            "   23  12  10  14  11  11  19  11  17  11  10  12  22  12  29  18  11  15\n",
            "   11  14  18  21  11  21  10  14  29  10  21  13  14  12  12  26  31  17\n",
            "   48  14  10  13  16  14  21  16  12  21  12  10  17  16  10  18  18  11\n",
            "   14  21  18  14  32  19  14 135  14  30  13  14  12  23  12  14  11  10\n",
            "   25  12  10  13  67  11  21  23  37  10  10  25  16 141  21  13  16  39\n",
            "   26  22  12  16  24  43  10  14  10  10  27  11  33  17  10  10  10  15\n",
            "   10  17  71  11  19  14  11  11  12  10  15  26  11  10  14  24  10  15\n",
            "   13  13  16  12  12  16  11  16  10  15  12  16  26  13  10  14  16  18\n",
            "   14  36  16  10  14  18  19  18  14  35  19  10  10  14  10  24  12  26\n",
            "   28  11  22  67  21  15  21  12  11  10  13  12  27  11  17  10  20  18\n",
            "   11 125  43  27  17  11  11  13  12  12  21  12  15  32  52  10  10  14\n",
            "  149  11  15  25  23  29]]\n",
            "vocab-size in df: 348\n",
            "start creating vocabulary ...\n",
            "length of the vocabulary: 348\n",
            "sample ten words of the vocabulary: ['days', 'feel', 'thing', 'early', 'kind', 'de', 'cost', 'late', 'higher', 'power']\n",
            "length word2id list: 348\n",
            "length id2word list: 348\n",
            "finished: creating vocabulary\n"
          ]
        }
      ],
      "source": [
        "# Daten zerlegen für Train, Test und Validation. Erstellen Vocabular aus dem Trainset\n",
        "textsloader.split_and_create_voca_from_trainset(max_df=0.7, min_df=10, stopwords_remove_from_voca=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "etzyjh_nqi19",
        "outputId": "b0b872e7-3b25-405d-be81-e1807ff4e3fc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "length train-documents-indices : 4275\n",
            "length of the vocabulary: 348\n",
            "\n",
            "\n",
            "start: creating bow representation...\n",
            "finised creating bow input!\n",
            "\n",
            "start: creating bow representation...\n",
            "finised creating bow input!\n",
            "\n",
            "start: creating bow representation...\n",
            "finised creating bow input!\n",
            "\n",
            "start: creating bow representation...\n",
            "finised creating bow input!\n",
            "\n",
            "start: creating bow representation...\n",
            "finised creating bow input!\n",
            "\n",
            "id2word befor saving: dict_keys([0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252, 253, 254, 255, 256, 257, 258, 259, 260, 261, 262, 263, 264, 265, 266, 267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298, 299, 300, 301, 302, 303, 304, 305, 306, 307, 308, 309, 310, 311, 312, 313, 314, 315, 316, 317, 318, 319, 320, 321, 322, 323, 324, 325, 326, 327, 328, 329, 330, 331, 332, 333, 334, 335, 336, 337, 338, 339, 340, 341, 342, 343, 344, 345, 346, 347])\n"
          ]
        }
      ],
      "source": [
        "# Erstellen BOW-Repräsentation für ETM Modell\n",
        "for_lda_model = False \n",
        "word2id, id2word, train_set, test_set, val_set = textsloader.create_bow_and_savebow_for_each_set(for_lda_model=for_lda_model)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r-DXUMguC8zM"
      },
      "source": [
        "# **Vocabular und IDs anzeigen als Beispiel**\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "6RBJYhLHCfwy",
        "outputId": "9f5f0ff4-342d-4ebc-bf98-6528ff0476f9"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "        word  id\n",
              "0       days   0\n",
              "1       feel   1\n",
              "2      thing   2\n",
              "3      early   3\n",
              "4       kind   4\n",
              "..       ...  ..\n",
              "95   support  95\n",
              "96      line  96\n",
              "97  assuming  97\n",
              "98   general  98\n",
              "99  thinking  99\n",
              "\n",
              "[100 rows x 2 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-8d1f1427-32d3-477f-b73f-93ed7fddae19\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>word</th>\n",
              "      <th>id</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>days</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>feel</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>thing</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>early</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>kind</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>95</th>\n",
              "      <td>support</td>\n",
              "      <td>95</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>96</th>\n",
              "      <td>line</td>\n",
              "      <td>96</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>97</th>\n",
              "      <td>assuming</td>\n",
              "      <td>97</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>98</th>\n",
              "      <td>general</td>\n",
              "      <td>98</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>99</th>\n",
              "      <td>thinking</td>\n",
              "      <td>99</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>100 rows × 2 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-8d1f1427-32d3-477f-b73f-93ed7fddae19')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-8d1f1427-32d3-477f-b73f-93ed7fddae19 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-8d1f1427-32d3-477f-b73f-93ed7fddae19');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 58
        }
      ],
      "source": [
        "# show for samples: 100 word2id and id2 word\n",
        "word2id_df_100 = pd.DataFrame()\n",
        "word2id_df_100['word'] = list(word2id.keys())[:100]\n",
        "word2id_df_100['id'] = list(word2id.values())[:100]\n",
        "word2id_df_100"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tupeI6Pw85_L"
      },
      "source": [
        "# **Die Größe von Datensätzen kontrollieren**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n1d-5ji3qwE8",
        "outputId": "9a650eeb-f7e5-468c-a4b3-82e034093b07"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Size of the vocabulary after prprocessing ist: 348\n",
            "Size of train set: 139\n",
            "Size of val set: 101\n",
            "Size of test set: 60\n"
          ]
        }
      ],
      "source": [
        "# Kontrollieren die Größen von verschiedenen Datensätzen\n",
        "print(f'Size of the vocabulary after prprocessing ist: {len(textsloader.vocabulary)}')\n",
        "print(f'Size of train set: {len(train_set[\"tokens\"])}')\n",
        "print(f'Size of val set: {len(val_set[\"tokens\"])}')\n",
        "print(f'Size of test set: {len(test_set[\"test\"][\"tokens\"])}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bxQL5jQtDb1c"
      },
      "source": [
        "# **Dokumenten wiederstellen für Word2Vec Embedding**\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "PDXEEBHfq3Cy",
        "outputId": "1fb84bef-7922-4115-d30b-09adf2e29dd9"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                             text-after-preprocessing\n",
              "0   reply college disclaimer care info robert writ...\n",
              "1   cs university department computer science figu...\n",
              "2   card questions reply bit ram bit true general ...\n",
              "3   article institute nntp posting host article wr...\n",
              "4   call originator ca institute send internationa...\n",
              "..                                                ...\n",
              "95  nasa gov laboratory distribution world nntp po...\n",
              "96  wanted nntp posting host institute distributio...\n",
              "97  article apr writes expressed major university ...\n",
              "98  computer systems division distribution world n...\n",
              "99  james read nntp posting host engineering compu...\n",
              "\n",
              "[100 rows x 1 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-93e3d12c-b820-4350-85ae-38d21b0dd900\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text-after-preprocessing</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>reply college disclaimer care info robert writ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>cs university department computer science figu...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>card questions reply bit ram bit true general ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>article institute nntp posting host article wr...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>call originator ca institute send internationa...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>95</th>\n",
              "      <td>nasa gov laboratory distribution world nntp po...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>96</th>\n",
              "      <td>wanted nntp posting host institute distributio...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>97</th>\n",
              "      <td>article apr writes expressed major university ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>98</th>\n",
              "      <td>computer systems division distribution world n...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>99</th>\n",
              "      <td>james read nntp posting host engineering compu...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>100 rows × 1 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-93e3d12c-b820-4350-85ae-38d21b0dd900')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-93e3d12c-b820-4350-85ae-38d21b0dd900 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-93e3d12c-b820-4350-85ae-38d21b0dd900');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 60
        }
      ],
      "source": [
        "# re-erstellen von Dokumenten nach der Vorverarbeitungen. Die Dokumenten sind in Wörtern und werden für Word-Embedding Training benutzt\n",
        "docs_tr, docs_t, docs_v = textsloader.get_docs_in_words_for_each_set()\n",
        "train_docs_df = pd.DataFrame()\n",
        "train_docs_df['text-after-preprocessing'] = [' '.join(doc) for doc in docs_tr[:100]]\n",
        "train_docs_df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ds_KuUTQrK5P"
      },
      "source": [
        "# **Word-Embedding trainieren mit dem Traindatensatz**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "KBexKIVf8Qs5",
        "outputId": "6b5f4256-b165-4971-a9d4-055460af7e62"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "word-embedding train begins\n",
            "word-embedding train finished\n",
            "length of vocabulary from word-embedding model 348\n",
            "length of the vocabulary of prepraring-dataset-vocabulary: 348\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 348/348 [00:00<00:00, 17674.13it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cluster id labels for inputted data\n",
            "[3 4 0 1 1 1 3 6 6 7 1 5 2 8 0 9 5 8 0 3 8 2 3 5 1 8 3 6 3 1 8 1 5 9 3 0 2\n",
            " 2 2 0 3 8 9 9 8 2 9 2 3 6 1 5 5 8 0 7 5 9 4 1 9 0 3 5 8 1 5 5 0 9 5 9 2 4\n",
            " 8 0 3 1 5 0 5 5 7 2 3 9 1 7 6 4 0 0 6 5 4 6 6 0 2 1 7 9 9 4 6 6 1 2 6 8 1\n",
            " 6 0 1 1 1 1 8 0 5 1 4 5 5 3 5 3 2 1 4 8 2 0 5 2 5 6 9 2 5 1 2 7 6 4 4 3 6\n",
            " 1 7 7 7 6 3 3 1 9 0 0 7 2 7 0 4 2 9 8 1 0 7 0 0 4 4 8 1 3 6 4 6 8 3 2 0 8\n",
            " 3 1 6 0 2 9 0 0 3 3 9 5 1 0 3 9 8 4 0 1 2 1 2 9 9 5 7 6 4 8 9 7 0 1 2 6 1\n",
            " 4 3 6 9 7 7 6 5 4 0 8 3 6 2 8 4 6 7 6 7 1 3 2 0 6 1 3 2 3 1 9 7 1 8 0 2 2\n",
            " 7 6 2 8 1 5 4 8 1 6 5 4 2 2 8 4 5 4 9 8 4 1 2 7 1 8 6 8 8 4 4 9 0 2 2 1 2\n",
            " 1 4 5 8 6 3 2 0 4 0 1 9 6 6 4 8 0 8 9 2 3 0 4 0 7 4 6 7 3 4 5 2 7 4 1 6 2\n",
            " 6 4 2 9 9 4 4 6 4 4 6 2 4 4 1]\n",
            "Centroids data\n",
            "[[ 0.0121438  -0.05749342 -0.04003314 -0.07299303  0.01781435 -0.05021415\n",
            "   0.02494711  0.01247798  0.01163443 -0.01318349]\n",
            " [-0.0293486  -0.05113077 -0.04338542 -0.02908022  0.00814724 -0.02124481\n",
            "  -0.00755317  0.00367485  0.03157994  0.01458998]\n",
            " [ 0.01779225 -0.01517054 -0.0194391  -0.04415096  0.0054964  -0.01556404\n",
            "  -0.0260227  -0.00135478  0.01134342  0.00196946]\n",
            " [-0.03851359 -0.07674317 -0.04563022 -0.1098343   0.04764524 -0.04113737\n",
            "   0.01949026  0.01003345  0.02439015 -0.00734373]\n",
            " [-0.01178396 -0.02979321 -0.00350464 -0.05080464  0.01253418 -0.0101695\n",
            "   0.031762   -0.02238961  0.02303896  0.00383122]\n",
            " [-0.01861862 -0.04690784 -0.0197635  -0.11293282  0.03762976 -0.00196451\n",
            "  -0.01504175  0.00965751  0.01769717 -0.02860588]\n",
            " [-0.03040221 -0.01073997 -0.01361326 -0.03036302 -0.00842188 -0.0187123\n",
            "  -0.01653924  0.00655445  0.00617736 -0.03666027]\n",
            " [-0.02256662 -0.00558299  0.00839994 -0.05705669  0.037573   -0.01863734\n",
            "   0.01696214  0.02357048 -0.0050785   0.00360951]\n",
            " [-0.03770639 -0.04142888 -0.04778722 -0.05078003  0.03386947 -0.01743449\n",
            "   0.02068097 -0.01430357  0.01700825 -0.03982175]\n",
            " [-0.01473399 -0.05180681 -0.01970063 -0.02182674  0.04139153 -0.02682887\n",
            "  -0.0194784   0.01845001 -0.00873518 -0.01549233]]\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script src=\"https://cdn.plot.ly/plotly-2.11.1.min.js\"></script>                <div id=\"d553b5f5-12e3-473b-ab69-20c02bf8a1dc\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"d553b5f5-12e3-473b-ab69-20c02bf8a1dc\")) {                    Plotly.newPlot(                        \"d553b5f5-12e3-473b-ab69-20c02bf8a1dc\",                        [{\"hovertemplate\":\"cluster=cluster 3<br>x=%{x}<br>y=%{y}<br>word=%{text}<extra></extra>\",\"legendgroup\":\"cluster 3\",\"marker\":{\"color\":\"#636efa\",\"symbol\":\"circle\"},\"mode\":\"markers+text\",\"name\":\"cluster 3\",\"orientation\":\"v\",\"showlegend\":true,\"text\":[\"reply\",\"writes\",\"cs\",\"computer\",\"place\",\"reason\",\"true\",\"read\",\"article\",\"people\",\"number\",\"great\",\"things\",\"control\",\"time\",\"laboratory\",\"nasa\",\"children\",\"real\",\"buy\",\"john\",\"power\",\"result\",\"sun\",\"space\",\"ac\",\"group\",\"put\",\"design\",\"law\",\"program\"],\"x\":[1.9639824628829956,1.5783113241195679,2.144157886505127,1.8557934761047363,2.087235450744629,1.2194950580596924,2.2161765098571777,2.1957061290740967,0.9633592367172241,2.7236292362213135,1.8276658058166504,2.6685543060302734,1.8468323945999146,2.2562685012817383,2.22346568107605,2.3186254501342773,0.6652584671974182,0.836847186088562,2.299436092376709,0.1213088110089302,1.9864681959152222,1.1286771297454834,2.5764975547790527,1.992509126663208,2.033071517944336,1.5470069646835327,2.0380566120147705,0.3228796720504761,2.19792103767395,2.242748737335205,1.8575793504714966],\"xaxis\":\"x\",\"y\":[1.6304506063461304,1.6909865140914917,1.9911023378372192,2.5567963123321533,2.9973344802856445,2.2454185485839844,1.8177422285079956,2.245671033859253,1.8007785081863403,2.0771195888519287,2.8758139610290527,2.6160411834716797,2.3683788776397705,1.9103307723999023,1.7762272357940674,2.0354130268096924,2.139645576477051,1.9097843170166016,2.189309597015381,2.1704230308532715,2.435293197631836,2.4374849796295166,2.7610907554626465,1.7725787162780762,2.2270069122314453,2.842388391494751,2.840719699859619,2.041877031326294,3.247285842895508,3.041316032409668,1.999260425567627],\"yaxis\":\"y\",\"type\":\"scatter\"},{\"hovertemplate\":\"cluster=cluster 4<br>x=%{x}<br>y=%{y}<br>word=%{text}<extra></extra>\",\"legendgroup\":\"cluster 4\",\"marker\":{\"color\":\"#EF553B\",\"symbol\":\"circle\"},\"mode\":\"markers+text\",\"name\":\"cluster 4\",\"orientation\":\"v\",\"showlegend\":true,\"text\":[\"college\",\"close\",\"issue\",\"technology\",\"life\",\"rest\",\"radio\",\"summary\",\"sound\",\"pretty\",\"internet\",\"miles\",\"ago\",\"free\",\"gas\",\"wondering\",\"systems\",\"guy\",\"worse\",\"nice\",\"point\",\"history\",\"key\",\"assuming\",\"disk\",\"left\",\"references\",\"board\",\"word\",\"months\",\"source\",\"including\",\"note\",\"sell\",\"white\",\"city\",\"hear\",\"friend\",\"jim\",\"interested\"],\"x\":[0.42747893929481506,0.6833004951477051,2.00848388671875,1.8225805759429932,-0.5545064806938171,2.7246031761169434,1.206796407699585,1.5448644161224365,-0.0016292817890644073,1.7798808813095093,2.5206868648529053,2.035083055496216,1.8668403625488281,1.982460856437683,0.6751846075057983,2.5281474590301514,1.7728408575057983,1.7661138772964478,0.7395321726799011,0.598143994808197,1.8884522914886475,2.0836188793182373,0.08553484827280045,1.7215129137039185,0.3586170971393585,2.6399383544921875,1.305117130279541,1.1172493696212769,0.5321734547615051,1.3623650074005127,-0.10294204205274582,1.1391046047210693,2.5786211490631104,0.6520385146141052,1.0323811769485474,0.8493355512619019,0.21062123775482178,0.15246674418449402,0.9095193147659302,0.08228996396064758],\"xaxis\":\"x\",\"y\":[4.9869704246521,6.179361820220947,3.544703722000122,3.521740674972534,4.689548015594482,5.034550666809082,3.372555732727051,3.6738314628601074,4.343115329742432,3.3844945430755615,5.129220008850098,4.2388529777526855,4.101866245269775,4.769068717956543,4.012173175811768,4.896155834197998,4.717427730560303,3.702744245529175,5.1055707931518555,4.870500087738037,3.7931411266326904,3.4142370223999023,4.002467155456543,4.630501747131348,4.955966472625732,5.29600715637207,3.287158727645874,4.630023002624512,4.054022312164307,4.345813274383545,4.541240692138672,3.3648483753204346,5.232670307159424,5.954854965209961,5.753753185272217,3.724830150604248,4.756507396697998,4.108778476715088,4.940854549407959,5.0995774269104],\"yaxis\":\"y\",\"type\":\"scatter\"},{\"hovertemplate\":\"cluster=cluster 0<br>x=%{x}<br>y=%{y}<br>word=%{text}<extra></extra>\",\"legendgroup\":\"cluster 0\",\"marker\":{\"color\":\"#00cc96\",\"symbol\":\"circle\"},\"mode\":\"markers+text\",\"name\":\"cluster 0\",\"orientation\":\"v\",\"showlegend\":true,\"text\":[\"disclaimer\",\"faster\",\"answer\",\"general\",\"problem\",\"thought\",\"long\",\"call\",\"contact\",\"research\",\"asked\",\"question\",\"understanding\",\"means\",\"single\",\"gov\",\"dept\",\"line\",\"hope\",\"found\",\"windows\",\"division\",\"car\",\"fact\",\"year\",\"world\",\"access\",\"agree\",\"making\",\"response\",\"days\",\"version\",\"light\",\"based\",\"higher\",\"talking\",\"au\",\"bike\"],\"x\":[-0.05614689737558365,1.1466764211654663,-0.6383351683616638,-0.1454032063484192,-0.0024996378924697638,-0.3432976007461548,0.8243876099586487,1.6895594596862793,0.32380014657974243,-0.20193874835968018,0.375224769115448,1.5968637466430664,1.3294012546539307,0.9020398259162903,0.7225569486618042,0.9049670100212097,1.0375319719314575,2.5686652660369873,0.9034359455108643,1.2781442403793335,0.4580889642238617,0.16242772340774536,0.21931226551532745,1.927260398864746,1.0070221424102783,0.07859467715024948,1.4634711742401123,0.7403398752212524,0.36972764134407043,-0.007585565559566021,0.35331040620803833,1.3878201246261597,0.03493857756257057,0.06685152649879456,0.35138288140296936,1.7170031070709229,2.245696783065796,1.3126314878463745],\"xaxis\":\"x\",\"y\":[6.705934047698975,2.2268834114074707,2.8108811378479004,2.8173611164093018,3.387028932571411,2.740018129348755,2.8168797492980957,1.6959160566329956,3.3495302200317383,2.638432025909424,3.568044900894165,2.8629605770111084,2.7441508769989014,2.940629482269287,2.8765580654144287,3.2318665981292725,3.117063283920288,2.3036112785339355,3.220632314682007,2.719292640686035,3.287006378173828,3.0007171630859375,2.465789794921875,3.34167218208313,3.641822338104248,2.4196417331695557,1.648866057395935,2.9694905281066895,2.46645188331604,2.9801571369171143,2.992704153060913,1.7819442749023438,3.545952558517456,3.395301342010498,2.6327295303344727,1.819726586341858,2.8570709228515625,1.9418059587478638],\"yaxis\":\"y\",\"type\":\"scatter\"},{\"hovertemplate\":\"cluster=cluster 1<br>x=%{x}<br>y=%{y}<br>word=%{text}<extra></extra>\",\"legendgroup\":\"cluster 1\",\"marker\":{\"color\":\"#ab63fa\",\"symbol\":\"circle\"},\"mode\":\"markers+text\",\"name\":\"cluster 1\",\"orientation\":\"v\",\"showlegend\":true,\"text\":[\"care\",\"info\",\"robert\",\"give\",\"figure\",\"set\",\"questions\",\"nntp\",\"machine\",\"stuff\",\"week\",\"problems\",\"appreciated\",\"person\",\"end\",\"home\",\"distribution\",\"cc\",\"org\",\"toronto\",\"email\",\"rate\",\"software\",\"hp\",\"service\",\"hard\",\"late\",\"government\",\"company\",\"tom\",\"public\",\"list\",\"thing\",\"fax\",\"address\",\"mike\",\"bible\",\"form\",\"speed\",\"continue\",\"man\",\"image\",\"full\",\"sort\",\"ms\"],\"x\":[-0.5680135488510132,-1.0984852313995361,-1.2047733068466187,-0.4961085021495819,-1.0364667177200317,-0.961067795753479,-0.9433590173721313,-0.6816681623458862,-1.0669925212860107,-0.9901085495948792,-1.1250731945037842,-0.620103657245636,-0.4463643729686737,-1.0274016857147217,-1.3455547094345093,-0.3847489655017853,-0.058061808347702026,-1.0665968656539917,-0.9635012149810791,-0.08010746538639069,-0.7683612704277039,-1.2708135843276978,-0.8212447166442871,-0.8614465594291687,-0.8160811066627502,-1.0449694395065308,-0.03666405379772186,-0.5272284150123596,-1.2374439239501953,-0.3960861563682556,-1.2157318592071533,-0.2879451513290405,-1.4184608459472656,-0.7866154909133911,-1.543874979019165,-1.1743428707122803,-1.2517699003219604,-0.7742758989334106,-1.543369174003601,-1.0414949655532837,-1.346612572669983,-0.5724592208862305,-0.16786596179008484,0.32253292202949524,-0.9107458591461182],\"xaxis\":\"x\",\"y\":[5.03255033493042,6.235599994659424,6.019787788391113,6.166889667510986,4.019726753234863,4.801090717315674,6.255582809448242,3.481208324432373,5.143050670623779,5.646829605102539,5.570528507232666,4.5948805809021,6.020977020263672,5.445294380187988,5.5491862297058105,4.856110572814941,3.8081629276275635,5.513924598693848,5.347096920013428,4.12013578414917,5.933043479919434,4.946547031402588,5.68299674987793,5.3838911056518555,5.368211269378662,4.095253944396973,3.725088596343994,4.900578498840332,5.317927360534668,5.140125751495361,4.254019737243652,6.4526801109313965,5.527500629425049,4.6849894523620605,5.432057857513428,6.124125957489014,5.7829179763793945,6.1713972091674805,5.796121120452881,6.303089141845703,4.462428092956543,6.26833438873291,6.378800868988037,7.2699737548828125,5.478293418884277],\"yaxis\":\"y\",\"type\":\"scatter\"},{\"hovertemplate\":\"cluster=cluster 6<br>x=%{x}<br>y=%{y}<br>word=%{text}<extra></extra>\",\"legendgroup\":\"cluster 6\",\"marker\":{\"color\":\"#FFA15A\",\"symbol\":\"circle\"},\"mode\":\"markers+text\",\"name\":\"cluster 6\",\"orientation\":\"v\",\"showlegend\":true,\"text\":[\"understand\",\"current\",\"application\",\"institute\",\"mind\",\"show\",\"live\",\"kind\",\"written\",\"final\",\"interest\",\"open\",\"expressed\",\"folks\",\"code\",\"numbers\",\"top\",\"rights\",\"order\",\"clear\",\"corporation\",\"network\",\"tin\",\"original\",\"stop\",\"jews\",\"guess\",\"east\",\"religious\",\"required\",\"uk\",\"hell\",\"related\",\"exists\",\"dos\",\"claim\",\"experience\",\"reading\"],\"x\":[2.2696783542633057,1.0468322038650513,2.9885783195495605,2.474905252456665,2.5055036544799805,0.3068661093711853,2.871337652206421,0.04208001866936684,0.12913775444030762,2.868375778198242,0.5690614581108093,2.560023784637451,2.2752010822296143,0.16450490057468414,2.1746444702148438,2.450721502304077,0.443864107131958,0.284819632768631,2.257208824157715,2.2075514793395996,0.2952771782875061,2.6915948390960693,3.0971946716308594,1.6536768674850464,2.365628719329834,3.16701340675354,2.6637284755706787,2.8806324005126953,2.549006223678589,2.4028677940368652,3.120497941970825,-0.9468516111373901,2.3792691230773926,2.6848959922790527,1.1522504091262817,2.6518664360046387,1.7325513362884521,2.351651668548584],\"xaxis\":\"x\",\"y\":[6.519789218902588,4.876675605773926,6.161562919616699,7.16338586807251,6.518992900848389,6.7266082763671875,6.235671520233154,5.561951160430908,5.780121326446533,6.345136642456055,5.326291084289551,7.06608772277832,7.1514177322387695,4.3107709884643555,5.556708335876465,7.045943737030029,5.647376537322998,4.585192680358887,7.206357479095459,6.610021591186523,4.464565753936768,5.673821926116943,5.8683857917785645,6.001391887664795,6.682858943939209,5.8211846351623535,6.585036754608154,6.02239465713501,6.3791022300720215,7.029919624328613,5.892453193664551,6.345615386962891,6.106987953186035,6.076469898223877,6.538844108581543,6.251994609832764,6.7481842041015625,5.951656818389893],\"yaxis\":\"y\",\"type\":\"scatter\"},{\"hovertemplate\":\"cluster=cluster 7<br>x=%{x}<br>y=%{y}<br>word=%{text}<extra></extra>\",\"legendgroup\":\"cluster 7\",\"marker\":{\"color\":\"#19d3f3\",\"symbol\":\"circle\"},\"mode\":\"markers+text\",\"name\":\"cluster 7\",\"orientation\":\"v\",\"showlegend\":true,\"text\":[\"situation\",\"net\",\"mentioned\",\"computing\",\"coming\",\"pc\",\"wanted\",\"box\",\"california\",\"remember\",\"idea\",\"phone\",\"considered\",\"western\",\"matter\",\"newsreader\",\"similar\",\"population\",\"sale\",\"canada\",\"sense\",\"worth\",\"engineering\",\"couple\"],\"x\":[1.3254369497299194,0.910995364189148,1.655503511428833,1.2557157278060913,1.8446601629257202,3.0391597747802734,1.4701292514801025,1.1914480924606323,1.1484309434890747,2.6579670906066895,1.4855111837387085,0.6567755937576294,0.6807640194892883,2.5086777210235596,1.6287428140640259,1.7342286109924316,2.380958318710327,1.9370520114898682,0.5373460650444031,1.4809409379959106,2.308176279067993,1.9697030782699585,2.1152167320251465,2.4919986724853516],\"xaxis\":\"x\",\"y\":[5.646396636962891,6.737311363220215,6.465897083282471,5.996652603149414,6.336963653564453,4.76814079284668,5.882804870605469,5.825338363647461,6.466805458068848,4.258199691772461,6.357578754425049,6.676270484924316,5.215939044952393,4.780501842498779,5.0443525314331055,5.052394866943359,4.5391974449157715,4.917318820953369,5.707695960998535,5.831775665283203,4.926098823547363,4.95681095123291,4.669241905212402,3.5324220657348633],\"yaxis\":\"y\",\"type\":\"scatter\"},{\"hovertemplate\":\"cluster=cluster 5<br>x=%{x}<br>y=%{y}<br>word=%{text}<extra></extra>\",\"legendgroup\":\"cluster 5\",\"marker\":{\"color\":\"#FF6692\",\"symbol\":\"circle\"},\"mode\":\"markers+text\",\"name\":\"cluster 5\",\"orientation\":\"v\",\"showlegend\":true,\"text\":[\"years\",\"system\",\"science\",\"bit\",\"posting\",\"host\",\"mail\",\"receive\",\"drive\",\"usa\",\"ca\",\"part\",\"project\",\"news\",\"side\",\"small\",\"back\",\"work\",\"big\",\"good\",\"simple\",\"data\",\"cost\",\"bad\",\"god\",\"book\",\"times\",\"made\",\"simply\",\"turn\"],\"x\":[3.5496082305908203,2.9939334392547607,2.574681043624878,2.1810755729675293,3.009126901626587,3.5151636600494385,3.446568250656128,2.71740984916687,3.31937575340271,2.8333656787872314,3.51945161819458,2.9386773109436035,2.1308562755584717,2.3591930866241455,3.359361171722412,2.847168207168579,2.500577211380005,2.854154109954834,3.160987138748169,2.801213264465332,3.0543670654296875,3.351578712463379,3.249406099319458,3.409494638442993,3.537100076675415,2.1500589847564697,2.6625256538391113,3.174849271774292,1.0554146766662598,2.953777313232422],\"xaxis\":\"x\",\"y\":[3.8678553104400635,2.512328863143921,4.207818508148193,3.4387967586517334,3.973813533782959,3.516561508178711,3.291553020477295,4.312382698059082,4.487287998199463,2.793424606323242,4.004073143005371,2.9142773151397705,2.7650504112243652,3.175492763519287,3.159961223602295,3.4085323810577393,3.8725173473358154,2.4902331829071045,3.476952075958252,3.705657720565796,2.7979700565338135,3.8291523456573486,4.588359832763672,3.391167163848877,4.043365478515625,4.031554698944092,2.7105274200439453,4.030444622039795,6.850518703460693,3.825409173965454],\"yaxis\":\"y\",\"type\":\"scatter\"},{\"hovertemplate\":\"cluster=cluster 2<br>x=%{x}<br>y=%{y}<br>word=%{text}<extra></extra>\",\"legendgroup\":\"cluster 2\",\"marker\":{\"color\":\"#B6E880\",\"symbol\":\"circle\"},\"mode\":\"markers+text\",\"name\":\"cluster 2\",\"orientation\":\"v\",\"showlegend\":true,\"text\":[\"add\",\"department\",\"heard\",\"run\",\"write\",\"pay\",\"early\",\"international\",\"interesting\",\"advance\",\"common\",\"high\",\"post\",\"day\",\"hardware\",\"easy\",\"school\",\"display\",\"money\",\"type\",\"sci\",\"steve\",\"truth\",\"ibm\",\"minutes\",\"change\",\"technical\",\"short\",\"due\",\"effect\",\"results\",\"lost\",\"james\",\"hold\",\"christian\",\"love\",\"dod\",\"takes\",\"de\",\"copy\",\"chip\"],\"x\":[-0.8224020600318909,0.5529180765151978,-1.532275676727295,-1.228978157043457,-0.8202580809593201,1.4112892150878906,-1.4473707675933838,-0.37269288301467896,0.6328008770942688,-1.295603632926941,-1.3231325149536133,-1.1152081489562988,0.9408749341964722,0.29291921854019165,2.7742602825164795,0.9102343916893005,-1.1787980794906616,-1.4087413549423218,0.8043579459190369,1.4417402744293213,0.33084532618522644,-1.1948330402374268,0.444652795791626,0.840089738368988,-0.799251914024353,2.4621026515960693,0.5092962384223938,0.03243179991841316,0.42753565311431885,0.733511745929718,2.5915544033050537,0.6672900915145874,0.316101998090744,-0.7665843963623047,0.4843440651893616,0.3093484044075012,-1.291850209236145,1.2313580513000488,0.45826420187950134,2.4291017055511475,1.4147204160690308],\"xaxis\":\"x\",\"y\":[3.0074453353881836,7.253093242645264,4.48966646194458,4.315837383270264,2.9266066551208496,6.557744026184082,4.593899250030518,6.364375114440918,7.344351291656494,4.424557209014893,4.52567195892334,4.491026401519775,7.032430171966553,6.877704620361328,4.156561851501465,7.300487041473389,4.659198760986328,4.352969646453857,6.713693141937256,7.146414756774902,5.435352802276611,4.013117790222168,6.013979434967041,6.066988468170166,5.783758640289307,4.436119079589844,5.871650695800781,6.6824259757995605,6.736098766326904,7.235166072845459,4.774003028869629,6.787487983703613,7.076840877532959,2.9044525623321533,6.789436340332031,5.689868450164795,4.812483787536621,7.188920974731445,6.427217960357666,5.872574329376221,7.132170677185059],\"yaxis\":\"y\",\"type\":\"scatter\"},{\"hovertemplate\":\"cluster=cluster 8<br>x=%{x}<br>y=%{y}<br>word=%{text}<extra></extra>\",\"legendgroup\":\"cluster 8\",\"marker\":{\"color\":\"#FF97FF\",\"symbol\":\"circle\"},\"mode\":\"markers+text\",\"name\":\"cluster 8\",\"orientation\":\"v\",\"showlegend\":true,\"text\":[\"memory\",\"mac\",\"university\",\"make\",\"card\",\"important\",\"price\",\"wrote\",\"message\",\"information\",\"job\",\"case\",\"state\",\"bill\",\"feel\",\"low\",\"thinking\",\"support\",\"error\",\"center\",\"national\",\"apr\",\"religion\",\"large\",\"parts\",\"gun\",\"view\",\"taking\",\"washington\",\"told\",\"date\",\"fine\"],\"x\":[1.2134171724319458,0.6912697553634644,2.687567710876465,0.7965803146362305,0.18424388766288757,1.4690091609954834,3.4200828075408936,1.274391770362854,0.8260522484779358,2.9083495140075684,1.379492163658142,2.795527219772339,3.2535014152526855,1.33955979347229,1.3165743350982666,3.28542160987854,1.1479583978652954,2.9918205738067627,0.8926711082458496,0.5404238104820251,2.954819917678833,0.23590421676635742,1.7786805629730225,1.465916633605957,1.6194331645965576,1.3782567977905273,1.4992142915725708,2.9304096698760986,3.100914478302002,0.9932295083999634,0.5629689693450928,1.2780406475067139],\"xaxis\":\"x\",\"y\":[4.330798149108887,3.970874786376953,3.5776097774505615,2.190079689025879,4.268104553222656,4.40307092666626,5.404976844787598,2.340468168258667,3.950700044631958,3.2140564918518066,5.076791286468506,3.2910284996032715,4.564871311187744,5.439257621765137,4.3073344230651855,4.296570301055908,4.420095443725586,5.557315826416016,4.095998287200928,2.258638858795166,5.52641487121582,4.317746639251709,4.251994609832764,4.059476852416992,4.540750980377197,4.510324954986572,4.143945217132568,3.236238956451416,4.743772983551025,2.220869541168213,4.555136680603027,4.188863277435303],\"yaxis\":\"y\",\"type\":\"scatter\"},{\"hovertemplate\":\"cluster=cluster 9<br>x=%{x}<br>y=%{y}<br>word=%{text}<extra></extra>\",\"legendgroup\":\"cluster 9\",\"marker\":{\"color\":\"#FECB52\",\"symbol\":\"circle\"},\"mode\":\"markers+text\",\"name\":\"cluster 9\",\"orientation\":\"v\",\"showlegend\":true,\"text\":[\"today\",\"ram\",\"strong\",\"opinion\",\"lot\",\"mine\",\"file\",\"originator\",\"send\",\"called\",\"hand\",\"calls\",\"opinions\",\"keywords\",\"texas\",\"class\",\"makes\",\"find\",\"david\",\"mark\",\"possibly\",\"wrong\",\"major\",\"game\",\"front\",\"total\",\"deleted\",\"posted\",\"start\"],\"x\":[2.050790309906006,1.6255414485931396,2.121338129043579,-0.282210111618042,-0.20381993055343628,-0.21718131005764008,1.9866114854812622,2.0371153354644775,-0.09284531325101852,1.2121158838272095,-0.02796962670981884,1.0370349884033203,0.8023865818977356,0.6578155159950256,1.724688172340393,0.2936153709888458,-0.3516724705696106,3.2463998794555664,-1.41025710105896,1.525956153869629,1.1056495904922485,-0.05328835919499397,3.3466060161590576,1.938337802886963,1.7737969160079956,0.4803164601325989,-0.05373043194413185,0.9690268039703369,0.31171005964279175],\"xaxis\":\"x\",\"y\":[5.651379585266113,6.187698841094971,3.9689018726348877,5.547030448913574,5.254297256469727,5.314878940582275,5.612438201904297,5.651787281036377,5.748095512390137,5.824690341949463,6.7278828620910645,6.41755485534668,5.281892776489258,6.345611095428467,5.547398567199707,6.4246015548706055,5.0002875328063965,5.5131940841674805,5.044714450836182,5.480835914611816,6.334959983825684,6.146060466766357,3.1025819778442383,5.302262783050537,5.440976142883301,5.238314628601074,6.376184940338135,6.4840826988220215,2.1749162673950195],\"yaxis\":\"y\",\"type\":\"scatter\"}],                        {\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}},\"xaxis\":{\"anchor\":\"y\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"x\"}},\"yaxis\":{\"anchor\":\"x\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"y\"}},\"legend\":{\"title\":{\"text\":\"cluster\"},\"tracegroupgap\":0},\"title\":{\"text\":\"word embedding samples\"}},                        {\"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('d553b5f5-12e3-473b-ab69-20c02bf8a1dc');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };                            </script>        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 61
        }
      ],
      "source": [
        "from src.embedding import WordEmbeddingCreator\n",
        "from pathlib import Path\n",
        "save_path = Path.joinpath(Path.cwd(), \"vocab_embedding.txt\")\n",
        "wb_creator = WordEmbeddingCreator(model_name=\"cbow\", documents = docs_tr, save_path= save_path)\n",
        "wb_creator.train(min_count=0, embedding_size= 10)\n",
        "vocab = list(word2id.keys())\n",
        "wb_creator.create_and_save_vocab_embedding(vocab, save_path)\n",
        "wb_creator.cluster_words(embedding_save_path = save_path, fig_path = Path('figures'), n_components=2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f23xipx7MSV4",
        "outputId": "b8e23a1c-154a-4a43-99e5-8deb2727a58f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "word-embedding of the word-- reply: \n",
            "vector: [-0.055647593, -0.08603645, -0.050223187, -0.07851673, 0.06465466, -0.058570564, -0.018530225, 0.051920176, 0.016091611, -0.019912569]\n",
            "dim of vector: 10\n"
          ]
        }
      ],
      "source": [
        "v = list(wb_creator.model.wv.vocab)[0]\n",
        "vec = list(wb_creator.model.wv.__getitem__(v))\n",
        "print(f'word-embedding of the word-- {v}: ')\n",
        "print(f'vector: {vec}')\n",
        "print(f'dim of vector: {len(vec)}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l53_jkUS-hl-"
      },
      "source": [
        "# **Word-Embeddings visualieren als Beispiel**\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {
        "id": "o96LsIWkNrZS"
      },
      "outputs": [],
      "source": [
        "# read word-embedding files\n",
        "with open(save_path) as f:\n",
        "  lines = f.readlines()\n",
        "embedding_data = []\n",
        "words_data = []\n",
        "for t in lines:\n",
        "  w = t.split(\"\\t\")[0]\n",
        "  v = [float(e) for e in t.split(\"\\t\")[1].split(\" \")]\n",
        "  words_data.append(w)\n",
        "  embedding_data.append(v)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "99hYOKPwB5aw",
        "outputId": "674f6c66-c870-4138-9282-264c9fa66554"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cluster id labels for inputted data\n",
            "[1 6 7 5 5 5 1 2 2 6 5 8 3 9 9 2 8 9 4 1 8 0 4 8 5 3 8 2 1 5 0 2 1 2 1 4 0\n",
            " 5 3 4 1 9 5 3 3 7 3 5 1 7 3 1 8 9 4 7 1 3 6 5 3 9 1 8 9 5 8 8 9 6 8 3 7 4\n",
            " 1 0 4 5 7 4 1 8 7 7 4 7 5 6 2 4 0 4 7 1 5 2 2 1 5 5 7 5 7 6 2 2 3 0 6 9 5\n",
            " 2 9 0 0 5 0 4 9 8 0 4 8 9 1 1 1 5 0 5 3 7 4 8 7 8 7 6 7 8 5 7 6 0 0 4 1 2\n",
            " 9 6 6 7 2 1 3 0 7 4 4 8 5 4 7 6 0 2 9 5 1 7 4 4 5 9 9 3 3 6 2 0 3 1 7 4 9\n",
            " 3 0 7 4 7 7 4 4 4 1 5 8 0 1 4 3 3 9 4 3 6 3 5 5 9 1 6 2 6 9 6 8 4 5 6 0 7\n",
            " 0 1 2 3 6 6 2 8 4 4 1 1 6 6 3 6 2 3 2 6 3 4 7 4 2 0 4 8 3 5 3 6 9 0 1 6 7\n",
            " 6 2 7 3 5 4 6 0 2 2 8 4 7 8 9 4 8 0 9 9 6 9 7 6 2 3 2 1 8 6 6 3 4 7 7 5 7\n",
            " 2 4 7 9 2 4 6 0 6 3 5 6 2 2 0 3 1 9 7 5 4 9 9 9 6 0 2 4 1 4 8 7 8 6 7 7 7\n",
            " 2 6 6 7 3 6 9 2 0 0 2 7 6 6 9]\n"
          ]
        }
      ],
      "source": [
        "# clustering words with KMeans and Words-Vectors\n",
        "kmeans = cluster.KMeans(n_clusters=10)\n",
        "kmeans.fit(embedding_data)\n",
        " \n",
        "labels = kmeans.labels_\n",
        "centroids = kmeans.cluster_centers_\n",
        " \n",
        "print (\"Cluster id labels for inputted data\")\n",
        "print (labels)\n",
        "#print (\"Centroids data\")\n",
        "#print (centroids)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LAMgZ9aIE9A6",
        "outputId": "90d6a0ca-9be5-429b-ed0f-9303c3c70450"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Duration: 6.1561439037323 seconds\n"
          ]
        }
      ],
      "source": [
        "# dimension reduction with umap\n",
        "start = time.time()\n",
        "reducer = umap.UMAP(random_state=42,n_components=3)\n",
        "embedding = reducer.fit_transform(embedding_data)\n",
        "print('Duration: {} seconds'.format(time.time() - start))\n",
        "\n",
        "# show samples after dim-reduction in dataframe\n",
        "wb = pd.DataFrame(embedding, columns=['x', 'y', 'z'])\n",
        "wb['word'] = words_data\n",
        "wb['cluster'] = ['cluster ' + str(c) for c in labels]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 542
        },
        "id": "spomMOt_yy0W",
        "outputId": "ba694d66-5844-4582-c3d2-249f2d4666f1"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script src=\"https://cdn.plot.ly/plotly-2.11.1.min.js\"></script>                <div id=\"0fd44ef6-924b-477a-b9a5-2ecacaa1fd54\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"0fd44ef6-924b-477a-b9a5-2ecacaa1fd54\")) {                    Plotly.newPlot(                        \"0fd44ef6-924b-477a-b9a5-2ecacaa1fd54\",                        [{\"hovertemplate\":\"cluster=cluster 1<br>x=%{x}<br>y=%{y}<br>z=%{z}<br>word=%{text}<extra></extra>\",\"legendgroup\":\"cluster 1\",\"marker\":{\"color\":\"#636efa\",\"symbol\":\"circle\"},\"mode\":\"markers+text\",\"name\":\"cluster 1\",\"scene\":\"scene\",\"showlegend\":true,\"text\":[\"reply\",\"writes\",\"cs\",\"reason\",\"bit\",\"true\",\"read\",\"article\",\"posting\",\"mail\",\"people\",\"information\",\"project\",\"side\",\"understanding\",\"things\",\"big\",\"control\",\"time\",\"laboratory\",\"found\",\"real\",\"power\",\"access\",\"bad\",\"sun\",\"center\",\"space\",\"version\",\"taking\",\"talking\",\"program\"],\"x\":[8.469653129577637,8.891770362854004,8.999683380126953,8.777932167053223,9.130446434020996,8.622505187988281,9.332722663879395,9.081926345825195,8.820033073425293,8.692059516906738,8.82679557800293,9.001551628112793,9.516900062561035,8.544600486755371,9.003911018371582,9.361574172973633,8.998323440551758,8.8253173828125,9.00867748260498,9.016593933105469,8.967702865600586,9.188122749328613,8.956521987915039,8.449020385742188,8.904085159301758,8.928711891174316,8.920981407165527,9.127795219421387,8.422135353088379,8.91726016998291,8.699132919311523,8.856744766235352],\"y\":[10.11330795288086,9.57571029663086,9.52833366394043,10.039937973022461,8.709761619567871,9.342246055603027,9.280488967895508,10.481670379638672,8.237561225891113,8.113009452819824,8.897116661071777,8.401158332824707,9.007356643676758,8.240747451782227,9.404240608215332,9.755206108093262,8.061652183532715,9.384263038635254,9.291529655456543,9.318680763244629,9.321098327636719,9.150070190429688,9.91724967956543,9.694284439086914,8.243924140930176,9.129327774047852,10.339214324951172,9.50219440460205,9.75167179107666,8.418848991394043,9.673311233520508,9.604612350463867],\"z\":[10.675250053405762,9.105443954467773,9.28018569946289,9.923444747924805,10.278736114501953,9.333527565002441,9.290816307067871,10.64113712310791,10.567486763000488,9.720300674438477,9.46133804321289,9.453778266906738,9.70962905883789,9.791936874389648,10.297266960144043,9.625056266784668,9.553561210632324,9.316259384155273,9.126093864440918,9.33272933959961,10.372088432312012,9.281582832336426,10.108802795410156,9.666070938110352,9.738274574279785,9.121346473693848,10.822454452514648,9.305469512939453,9.825862884521484,9.415689468383789,9.524246215820312,9.469062805175781],\"type\":\"scatter3d\"},{\"hovertemplate\":\"cluster=cluster 6<br>x=%{x}<br>y=%{y}<br>z=%{z}<br>word=%{text}<extra></extra>\",\"legendgroup\":\"cluster 6\",\"marker\":{\"color\":\"#EF553B\",\"symbol\":\"circle\"},\"mode\":\"markers+text\",\"name\":\"cluster 6\",\"scene\":\"scene\",\"showlegend\":true,\"text\":[\"college\",\"situation\",\"close\",\"originator\",\"computing\",\"rest\",\"interest\",\"opinions\",\"pc\",\"wanted\",\"box\",\"internet\",\"top\",\"sci\",\"considered\",\"wondering\",\"possibly\",\"truth\",\"matter\",\"newsreader\",\"original\",\"ibm\",\"worse\",\"population\",\"sale\",\"technical\",\"canada\",\"nice\",\"assuming\",\"sense\",\"disk\",\"left\",\"love\",\"board\",\"total\",\"worth\",\"note\",\"sell\",\"copy\",\"white\",\"jim\",\"interested\"],\"x\":[11.454142570495605,11.169927597045898,10.875049591064453,9.620630264282227,11.117466926574707,10.509839057922363,11.476730346679688,10.028626441955566,10.360041618347168,11.155856132507324,11.06714916229248,10.53731632232666,11.291251182556152,10.728130340576172,11.490164756774902,10.637606620788574,10.274991989135742,10.851330757141113,11.182940483093262,10.484903335571289,10.952231407165527,10.667794227600098,11.47735595703125,10.820883750915527,11.052206039428711,10.980047225952148,11.1655855178833,11.284037590026855,10.770072937011719,10.646300315856934,11.244244575500488,10.451187133789062,10.97492504119873,10.625336647033691,10.442561149597168,10.63821792602539,10.489704132080078,11.014396667480469,10.411946296691895,11.030219078063965,11.323554039001465,11.023959159851074],\"y\":[9.151715278625488,7.990437984466553,8.495720863342285,7.921757698059082,7.9692535400390625,7.3224196434021,8.766082763671875,8.858657836914062,7.3536553382873535,7.894567489624023,8.220688819885254,7.406117916107178,8.657495498657227,9.159494400024414,8.774433135986328,7.561193943023682,8.135047912597656,8.680840492248535,8.252608299255371,8.026562690734863,7.8604302406311035,8.444533348083496,8.856698036193848,7.861347675323486,8.776673316955566,8.760743141174316,7.943814754486084,9.02185344696045,8.370624542236328,7.724800109863281,9.175930976867676,7.3562798500061035,8.96541690826416,8.946111679077148,9.011853218078613,8.015122413635254,7.402730941772461,8.619534492492676,7.402419090270996,8.309784889221191,8.821807861328125,9.311965942382812],\"z\":[11.959458351135254,11.449036598205566,11.961615562438965,11.900984764099121,11.657556533813477,11.409293174743652,12.125768661499023,11.82845687866211,10.571394920349121,11.487212181091309,11.501648902893066,11.404596328735352,12.530019760131836,12.395837783813477,11.855951309204102,10.998745918273926,12.42774486541748,12.756040573120117,10.759512901306152,11.077561378479004,12.27415657043457,12.621736526489258,11.860508918762207,10.80698013305664,12.496243476867676,12.652056694030762,11.535953521728516,11.679051399230957,10.941977500915527,11.136127471923828,11.900253295898438,11.549845695495605,12.745139122009277,11.315095901489258,11.901771545410156,10.922595024108887,11.447972297668457,11.946004867553711,12.014988899230957,11.616424560546875,11.61754035949707,12.161806106567383],\"type\":\"scatter3d\"},{\"hovertemplate\":\"cluster=cluster 7<br>x=%{x}<br>y=%{y}<br>z=%{z}<br>word=%{text}<extra></extra>\",\"legendgroup\":\"cluster 7\",\"marker\":{\"color\":\"#00cc96\",\"symbol\":\"circle\"},\"mode\":\"markers+text\",\"name\":\"cluster 7\",\"scene\":\"scene\",\"showlegend\":true,\"text\":[\"disclaimer\",\"pay\",\"institute\",\"net\",\"international\",\"part\",\"mentioned\",\"interesting\",\"called\",\"show\",\"coming\",\"calls\",\"post\",\"day\",\"expressed\",\"hardware\",\"easy\",\"california\",\"keywords\",\"hope\",\"phone\",\"money\",\"order\",\"type\",\"class\",\"list\",\"minutes\",\"short\",\"due\",\"effect\",\"lost\",\"james\",\"hold\",\"christian\",\"simply\",\"deleted\",\"takes\",\"sort\",\"dos\",\"de\",\"posted\",\"chip\"],\"x\":[9.466029167175293,8.89426040649414,9.844803810119629,9.67322826385498,9.94442367553711,8.669903755187988,8.872748374938965,9.601985931396484,9.039932250976562,10.121722221374512,8.992424964904785,10.234053611755371,9.357141494750977,10.025323867797852,10.140547752380371,8.911959648132324,9.892508506774902,10.127522468566895,10.081076622009277,8.86759090423584,9.504830360412598,9.97800064086914,9.708016395568848,10.475617408752441,9.536566734313965,9.813749313354492,10.133183479309082,9.749695777893066,10.257752418518066,9.562122344970703,9.9642915725708,9.800209999084473,8.57839584350586,10.059670448303223,9.383013725280762,9.725385665893555,10.358288764953613,9.63174057006836,10.171856880187988,10.47298526763916,10.095422744750977,10.439156532287598],\"y\":[9.328200340270996,8.304582595825195,7.010167121887207,8.144068717956543,9.27700424194336,8.538989067077637,8.23748779296875,8.641430854797363,8.371228218078613,8.675692558288574,8.039071083068848,8.08847713470459,8.270808219909668,8.691454887390137,7.247700214385986,8.051851272583008,8.311275482177734,8.062236785888672,8.31393051147461,9.10935115814209,8.343655586242676,8.423789978027344,7.120372772216797,7.715869426727295,8.67977237701416,9.082500457763672,9.6062650680542,8.771721839904785,8.398741722106934,8.583499908447266,8.258597373962402,8.790019035339355,8.812618255615234,8.457612991333008,8.12919807434082,8.970077514648438,7.885946750640869,8.923567771911621,7.962230205535889,8.494128227233887,8.06089973449707,7.748189449310303],\"z\":[12.302082061767578,12.556147575378418,12.686760902404785,12.732087135314941,12.794730186462402,10.655951499938965,12.516568183898926,13.325230598449707,11.691736221313477,13.249710083007812,12.463786125183105,12.613401412963867,12.888895988464355,13.173437118530273,12.852360725402832,10.936529159545898,13.37474536895752,12.464190483093262,12.622552871704102,11.199424743652344,11.753859519958496,12.898447036743164,12.75904655456543,13.01627254486084,12.640795707702637,12.952322959899902,12.306645393371582,12.706686973571777,12.95902156829834,13.2483491897583,12.993393898010254,13.192047119140625,12.53520679473877,13.088763236999512,12.798433303833008,12.75808048248291,13.118738174438477,13.179886817932129,12.579310417175293,12.899247169494629,12.603878021240234,12.965944290161133],\"type\":\"scatter3d\"},{\"hovertemplate\":\"cluster=cluster 5<br>x=%{x}<br>y=%{y}<br>z=%{z}<br>word=%{text}<extra></extra>\",\"legendgroup\":\"cluster 5\",\"marker\":{\"color\":\"#ab63fa\",\"symbol\":\"circle\"},\"mode\":\"markers+text\",\"name\":\"cluster 5\",\"scene\":\"scene\",\"showlegend\":true,\"text\":[\"care\",\"info\",\"robert\",\"give\",\"figure\",\"set\",\"run\",\"strong\",\"early\",\"machine\",\"stuff\",\"week\",\"problems\",\"life\",\"advance\",\"appreciated\",\"hand\",\"end\",\"cc\",\"high\",\"summary\",\"rate\",\"school\",\"service\",\"miles\",\"makes\",\"steve\",\"david\",\"public\",\"address\",\"bible\",\"man\",\"full\",\"dod\"],\"x\":[10.830869674682617,9.181851387023926,9.282540321350098,9.36966609954834,9.536800384521484,9.653093338012695,9.977935791015625,9.359704971313477,10.389307975769043,10.109859466552734,10.148673057556152,9.797261238098145,10.641857147216797,10.706645011901855,10.154205322265625,9.758976936340332,9.087068557739258,9.586986541748047,9.945051193237305,9.936026573181152,10.052596092224121,10.023774147033691,10.608041763305664,10.011149406433105,9.526607513427734,10.837630271911621,9.845407485961914,10.115036964416504,9.665328025817871,9.419687271118164,9.570046424865723,10.034431457519531,9.65112018585205,10.256797790527344],\"y\":[9.850008010864258,10.028824806213379,10.16080093383789,8.817540168762207,10.767227172851562,9.921581268310547,10.561331748962402,8.617854118347168,10.417284965515137,10.461640357971191,9.901739120483398,10.23273754119873,10.180997848510742,10.23229694366455,10.483173370361328,9.795357704162598,9.509565353393555,10.302112579345703,10.196803092956543,10.448197364807129,9.259922981262207,10.423187255859375,10.253473281860352,10.042654991149902,8.519906044006348,9.71664810180664,10.647847175598145,10.23851203918457,10.656612396240234,10.479762077331543,10.250399589538574,10.356890678405762,9.066777229309082,10.231871604919434],\"z\":[12.30067253112793,12.749029159545898,12.562505722045898,11.93727970123291,12.055744171142578,13.02281379699707,12.84995174407959,10.993700981140137,13.101821899414062,12.188505172729492,12.440778732299805,12.492086410522461,12.270716667175293,12.110371589660645,13.039971351623535,12.654587745666504,12.075181007385254,12.165995597839355,12.371614456176758,12.93305492401123,10.608920097351074,12.685229301452637,12.928643226623535,12.242560386657715,11.1476411819458,12.113873481750488,12.933209419250488,12.581396102905273,12.426850318908691,12.281563758850098,12.454292297363281,12.957817077636719,12.771554946899414,12.75253677368164],\"type\":\"scatter3d\"},{\"hovertemplate\":\"cluster=cluster 2<br>x=%{x}<br>y=%{y}<br>z=%{z}<br>word=%{text}<extra></extra>\",\"legendgroup\":\"cluster 2\",\"marker\":{\"color\":\"#FFA15A\",\"symbol\":\"circle\"},\"mode\":\"markers+text\",\"name\":\"cluster 2\",\"scene\":\"scene\",\"showlegend\":true,\"text\":[\"understand\",\"current\",\"today\",\"application\",\"questions\",\"ram\",\"mind\",\"live\",\"kind\",\"written\",\"final\",\"open\",\"code\",\"numbers\",\"texas\",\"free\",\"clear\",\"network\",\"tin\",\"stop\",\"jews\",\"guess\",\"east\",\"form\",\"religious\",\"continue\",\"required\",\"image\",\"uk\",\"hell\",\"related\",\"exists\",\"claim\",\"experience\",\"reading\"],\"x\":[9.995587348937988,11.362495422363281,9.510586738586426,9.600497245788574,9.307978630065918,9.30469036102295,9.46302318572998,9.270153999328613,10.769503593444824,10.676347732543945,9.525812149047852,9.839384078979492,9.427553176879883,9.863171577453613,9.301880836486816,9.876747131347656,9.96495246887207,10.220248222351074,9.377691268920898,9.83175277709961,9.1568021774292,9.504287719726562,9.602245330810547,9.471290588378906,9.364176750183105,9.12423324584961,9.823591232299805,9.501100540161133,9.167792320251465,9.102737426757812,10.193899154663086,9.944195747375488,9.640823364257812,10.15870475769043,9.39624309539795],\"y\":[7.535635471343994,8.486077308654785,7.832780838012695,7.111471176147461,9.701162338256836,8.565571784973145,7.179819583892822,7.264801979064941,9.244053840637207,8.847846031188965,7.1165056228637695,6.985866069793701,7.788166522979736,7.027207374572754,8.203783988952637,7.817335605621338,7.327728748321533,7.208003520965576,7.159007549285889,7.118625640869141,7.3255462646484375,7.097126007080078,7.180356979370117,9.69074535369873,7.21810245513916,9.949040412902832,7.094213962554932,9.5128755569458,7.234505653381348,9.882189750671387,7.143551826477051,7.027583599090576,7.091902256011963,7.919983386993408,7.607931613922119],\"z\":[12.52551555633545,10.807544708251953,11.927567481994629,11.628666877746582,12.784966468811035,12.365330696105957,12.135986328125,11.864049911499023,12.75869369506836,12.777599334716797,11.795184135437012,12.530914306640625,11.721254348754883,12.58410930633545,12.015384674072266,10.999876022338867,12.334848403930664,11.52431869506836,11.496953964233398,12.372989654541016,11.369017601013184,12.195516586303711,11.612167358398438,12.75001049041748,12.151069641113281,12.79078197479248,12.60360336303711,12.678251266479492,11.397592544555664,12.798966407775879,12.096075057983398,11.825532913208008,12.059968948364258,12.943528175354004,11.846479415893555],\"type\":\"scatter3d\"},{\"hovertemplate\":\"cluster=cluster 8<br>x=%{x}<br>y=%{y}<br>z=%{z}<br>word=%{text}<extra></extra>\",\"legendgroup\":\"cluster 8\",\"marker\":{\"color\":\"#19d3f3\",\"symbol\":\"circle\"},\"mode\":\"markers+text\",\"name\":\"cluster 8\",\"scene\":\"scene\",\"showlegend\":true,\"text\":[\"years\",\"system\",\"university\",\"science\",\"place\",\"host\",\"receive\",\"drive\",\"usa\",\"ca\",\"news\",\"small\",\"back\",\"good\",\"simple\",\"data\",\"remember\",\"cost\",\"western\",\"god\",\"change\",\"times\",\"results\",\"made\",\"washington\",\"turn\",\"couple\"],\"x\":[8.984050750732422,8.756244659423828,9.440964698791504,9.697331428527832,9.72326374053955,8.60871696472168,9.461730003356934,10.10339641571045,8.892768859863281,9.011920928955078,9.541219711303711,8.91002082824707,9.8574800491333,9.199981689453125,8.631575584411621,8.792481422424316,10.020715713500977,9.576251029968262,10.48773193359375,9.1254243850708,9.390917778015137,8.646259307861328,9.666354179382324,8.901702880859375,10.017578125,8.88899040222168,9.596137046813965],\"y\":[7.494811534881592,8.653739929199219,8.107051849365234,7.957826137542725,8.511847496032715,8.099507331848145,8.179678916931152,7.335978984832764,8.653849601745605,7.586815357208252,8.678384780883789,8.194019317626953,8.144695281982422,8.004953384399414,8.43678092956543,7.87693452835083,7.986596584320068,7.275974750518799,7.664373397827148,7.486717700958252,8.049195289611816,8.791874885559082,7.810098171234131,7.897493839263916,7.311204433441162,7.970432281494141,8.011270523071289],\"z\":[10.364067077636719,9.756086349487305,9.754883766174316,10.69891357421875,9.674104690551758,9.849209785461426,10.870794296264648,10.367636680603027,10.13587474822998,10.402612686157227,9.382868766784668,9.712026596069336,10.117634773254395,9.955740928649902,10.393045425415039,10.466570854187012,10.452445030212402,10.49638843536377,10.547547340393066,10.235246658325195,11.174150466918945,10.048907279968262,11.23774242401123,10.68677806854248,10.539567947387695,10.588839530944824,9.914264678955078],\"type\":\"scatter3d\"},{\"hovertemplate\":\"cluster=cluster 3<br>x=%{x}<br>y=%{y}<br>z=%{z}<br>word=%{text}<extra></extra>\",\"legendgroup\":\"cluster 3\",\"marker\":{\"color\":\"#FF6692\",\"symbol\":\"circle\"},\"mode\":\"markers+text\",\"name\":\"cluster 3\",\"scene\":\"scene\",\"showlegend\":true,\"text\":[\"add\",\"make\",\"write\",\"opinion\",\"price\",\"lot\",\"nntp\",\"mine\",\"file\",\"send\",\"person\",\"state\",\"nasa\",\"hard\",\"children\",\"low\",\"buy\",\"find\",\"support\",\"company\",\"tom\",\"wrong\",\"national\",\"similar\",\"thing\",\"put\",\"major\",\"religion\",\"view\",\"front\",\"higher\",\"date\",\"start\"],\"x\":[8.480607986450195,8.813676834106445,8.487059593200684,10.648397445678711,8.991739273071289,10.465810775756836,9.217175483703613,10.632357597351074,9.238029479980469,10.292169570922852,9.150713920593262,10.173579216003418,8.838726997375488,9.41089153289795,8.619458198547363,9.930219650268555,9.114497184753418,8.920433044433594,9.820103645324707,9.279964447021484,10.67402458190918,9.498616218566895,9.9203462600708,10.549208641052246,9.461636543273926,9.019680976867676,8.490592002868652,10.494161605834961,10.729944229125977,9.085317611694336,8.8516263961792,11.290022850036621,8.824148178100586],\"y\":[9.018963813781738,10.172618865966797,8.997653007507324,9.264885902404785,7.416162967681885,9.452370643615723,10.739538192749023,9.461462020874023,8.017374992370605,9.253826141357422,10.325796127319336,7.331610679626465,10.329228401184082,10.757367134094238,10.290424346923828,7.511422157287598,10.709781646728516,7.728891849517822,7.219795227050781,10.342647552490234,9.796636581420898,9.000307083129883,7.182168960571289,7.677242279052734,10.436452865600586,10.644491195678711,8.397026062011719,8.338945388793945,8.529985427856445,8.36439323425293,9.983909606933594,8.961556434631348,10.34566593170166],\"z\":[12.653412818908691,10.356822967529297,12.599279403686523,12.744447708129883,11.07769775390625,12.285470962524414,11.387324333190918,12.54532527923584,11.749783515930176,12.453607559204102,11.855756759643555,10.382804870605469,10.394342422485352,12.12047290802002,10.950429916381836,10.189717292785645,11.239290237426758,11.238508224487305,10.984827995300293,11.789804458618164,12.035112380981445,12.550406455993652,11.00450611114502,10.614709854125977,11.864585876464844,11.044879913330078,9.85438060760498,10.235993385314941,10.13805866241455,11.858457565307617,11.05762004852295,10.932385444641113,11.160289764404297],\"type\":\"scatter3d\"},{\"hovertemplate\":\"cluster=cluster 9<br>x=%{x}<br>y=%{y}<br>z=%{z}<br>word=%{text}<extra></extra>\",\"legendgroup\":\"cluster 9\",\"marker\":{\"color\":\"#B6E880\",\"symbol\":\"circle\"},\"mode\":\"markers+text\",\"name\":\"cluster 9\",\"scene\":\"scene\",\"showlegend\":true,\"text\":[\"memory\",\"faster\",\"mac\",\"important\",\"wrote\",\"long\",\"message\",\"call\",\"job\",\"means\",\"single\",\"work\",\"software\",\"bill\",\"ago\",\"feel\",\"thinking\",\"gas\",\"mark\",\"error\",\"mike\",\"parts\",\"game\",\"gun\",\"speed\",\"told\",\"fine\",\"au\",\"months\",\"bike\",\"city\",\"ms\"],\"x\":[10.781379699707031,8.455902099609375,10.52489948272705,10.818138122558594,8.916804313659668,8.97792911529541,10.549079895019531,8.516009330749512,9.363903045654297,8.922503471374512,8.915696144104004,8.618379592895508,9.961502075195312,9.33709716796875,9.779594421386719,10.9798583984375,11.035771369934082,10.478890419006348,8.935585021972656,10.808402061462402,9.224936485290527,11.129720687866211,9.417624473571777,10.616047859191895,9.15796184539795,8.493345260620117,10.84985065460205,9.011394500732422,10.441507339477539,8.411993026733398,10.358011245727539,9.952749252319336],\"y\":[8.985304832458496,9.560256004333496,9.362433433532715,8.692842483520508,9.979682922363281,9.700117111206055,9.232773780822754,9.656752586364746,8.40745735168457,9.568655014038086,9.708087921142578,8.74412727355957,9.95051383972168,8.37483024597168,8.775717735290527,8.784640312194824,8.800273895263672,9.495038032531738,8.475207328796387,9.116284370422363,9.989740371704102,8.344828605651855,8.42492961883545,8.75564193725586,10.398526191711426,9.727239608764648,8.75148868560791,9.108115196228027,9.001566886901855,9.658428192138672,9.51204776763916,10.136067390441895],\"z\":[10.080506324768066,10.017260551452637,10.799043655395508,10.460941314697266,10.095541954040527,10.695209503173828,10.71701431274414,9.760730743408203,12.033698081970215,10.802152633666992,10.85743522644043,10.24875259399414,11.844918251037598,12.237915992736816,10.855761528015137,10.269430160522461,10.270350456237793,10.982808113098145,11.751522064208984,10.453386306762695,12.654025077819824,10.543848991394043,11.564505577087402,10.626571655273438,11.920429229736328,10.204404830932617,10.13123607635498,10.347844123840332,10.764351844787598,10.0135498046875,10.714132308959961,11.974411010742188],\"type\":\"scatter3d\"},{\"hovertemplate\":\"cluster=cluster 4<br>x=%{x}<br>y=%{y}<br>z=%{z}<br>word=%{text}<extra></extra>\",\"legendgroup\":\"cluster 4\",\"marker\":{\"color\":\"#FF97FF\",\"symbol\":\"circle\"},\"mode\":\"markers+text\",\"name\":\"cluster 4\",\"scene\":\"scene\",\"showlegend\":true,\"text\":[\"answer\",\"computer\",\"general\",\"problem\",\"thought\",\"issue\",\"number\",\"research\",\"great\",\"technology\",\"question\",\"case\",\"radio\",\"gov\",\"pretty\",\"dept\",\"line\",\"idea\",\"windows\",\"division\",\"car\",\"fact\",\"year\",\"world\",\"john\",\"result\",\"agree\",\"making\",\"guy\",\"response\",\"ac\",\"days\",\"group\",\"book\",\"point\",\"history\",\"light\",\"references\",\"design\",\"law\",\"engineering\",\"including\"],\"x\":[8.433350563049316,9.569351196289062,8.8584623336792,9.922192573547363,8.517349243164062,10.120332717895508,9.873331069946289,8.628412246704102,9.412464141845703,10.00400161743164,9.190169334411621,8.733208656311035,9.252386093139648,8.818455696105957,9.791019439697266,9.378893852233887,9.037158012390137,8.892525672912598,10.16896915435791,9.702879905700684,8.783864974975586,10.004158020019531,9.651004791259766,8.897435188293457,9.418145179748535,9.336265563964844,8.873034477233887,8.758183479309082,10.304656028747559,9.58310604095459,9.44581127166748,9.796981811523438,9.618574142456055,9.342988967895508,9.534029960632324,9.8490629196167,10.028903007507324,9.659198760986328,9.793289184570312,9.521478652954102,10.660419464111328,9.310189247131348],\"y\":[9.162284851074219,9.673531532287598,9.5015230178833,10.0683012008667,9.236353874206543,8.83018684387207,9.400391578674316,9.719022750854492,8.961115837097168,9.08702564239502,9.486833572387695,8.36526870727539,9.123869895935059,9.158675193786621,9.076035499572754,9.618668556213379,9.229735374450684,8.680944442749023,10.079086303710938,10.167825698852539,10.143956184387207,9.172184944152832,9.13209056854248,10.27250862121582,9.6245698928833,8.933271408081055,9.425232887268066,10.128971099853516,8.9425048828125,10.073671340942383,9.651936531066895,9.997390747070312,9.110273361206055,8.63033676147461,8.946127891540527,8.859217643737793,10.038110733032227,9.440336227416992,8.589337348937988,8.898669242858887,7.786713123321533,9.210360527038574],\"z\":[12.207856178283691,9.767903327941895,11.598114967346191,10.51962947845459,11.89127254486084,10.332780838012695,9.896122932434082,11.460465431213379,10.0323486328125,10.423964500427246,10.189440727233887,9.606277465820312,10.897356986999512,11.182774543762207,10.360689163208008,10.616340637207031,9.533181190490723,12.200821876525879,10.323773384094238,10.507896423339844,11.179245948791504,9.94018268585205,11.475484848022461,11.271893501281738,9.740668296813965,10.046781539916992,10.975212097167969,11.128792762756348,10.960068702697754,10.952329635620117,10.26259708404541,10.37736701965332,9.456708908081055,11.044830322265625,10.83253288269043,10.177207946777344,10.705727577209473,10.594785690307617,9.804967880249023,9.966917037963867,10.741156578063965,11.064934730529785],\"type\":\"scatter3d\"},{\"hovertemplate\":\"cluster=cluster 0<br>x=%{x}<br>y=%{y}<br>z=%{z}<br>word=%{text}<extra></extra>\",\"legendgroup\":\"cluster 0\",\"marker\":{\"color\":\"#FECB52\",\"symbol\":\"circle\"},\"mode\":\"markers+text\",\"name\":\"cluster 0\",\"scene\":\"scene\",\"showlegend\":true,\"text\":[\"department\",\"card\",\"heard\",\"contact\",\"asked\",\"common\",\"home\",\"distribution\",\"org\",\"toronto\",\"email\",\"folks\",\"sound\",\"hp\",\"display\",\"rights\",\"late\",\"government\",\"corporation\",\"systems\",\"fax\",\"apr\",\"large\",\"key\",\"based\",\"word\",\"source\",\"hear\",\"friend\"],\"x\":[9.758657455444336,11.142655372619629,10.297025680541992,10.376479148864746,10.558858871459961,10.301019668579102,10.724567413330078,10.504313468933105,10.144488334655762,11.232574462890625,9.846805572509766,11.428271293640137,10.640864372253418,10.111198425292969,10.415356636047363,11.322402954101562,10.40829849243164,10.854220390319824,11.379905700683594,10.934910774230957,10.811909675598145,11.342192649841309,10.827031135559082,11.134354591369629,10.236852645874023,10.333357810974121,10.616890907287598,11.36478042602539,11.31314754486084],\"y\":[8.815923690795898,9.379999160766602,10.2431001663208,10.179408073425293,9.994790077209473,10.404592514038086,10.049551010131836,10.118484497070312,10.379561424255371,9.890517234802246,9.644954681396484,9.483064651489258,9.914213180541992,10.154047966003418,10.282025337219238,9.156026840209961,10.195037841796875,9.912704467773438,9.128674507141113,8.317683219909668,10.05250358581543,9.371390342712402,8.608304023742676,9.79571533203125,10.25191593170166,9.671016693115234,9.869129180908203,9.336297035217285,9.673032760620117],\"z\":[13.372912406921387,10.752945899963379,13.26978588104248,10.473145484924316,10.472867012023926,13.167366027832031,11.73748779296875,10.90334415435791,12.145904541015625,11.183412551879883,12.884100914001465,11.043581008911133,11.179244995117188,11.982277870178223,13.204998016357422,11.075348854064941,10.838773727416992,12.196534156799316,11.114365577697754,10.745065689086914,12.638890266418457,10.923492431640625,10.010637283325195,10.951942443847656,10.611077308654785,10.881611824035645,11.284013748168945,11.799154281616211,10.948753356933594],\"type\":\"scatter3d\"}],                        {\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}},\"scene\":{\"domain\":{\"x\":[0.0,1.0],\"y\":[0.0,1.0]},\"xaxis\":{\"title\":{\"text\":\"x\"}},\"yaxis\":{\"title\":{\"text\":\"y\"}},\"zaxis\":{\"title\":{\"text\":\"z\"}}},\"legend\":{\"title\":{\"text\":\"cluster\"},\"tracegroupgap\":0},\"title\":{\"text\":\"word-embedding-samples\"}},                        {\"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('0fd44ef6-924b-477a-b9a5-2ecacaa1fd54');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };                            </script>        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "# visualization\n",
        "fig = px.scatter_3d(wb, \n",
        "                    text = wb['word'],\n",
        "                    x='x', y='y', z='z',\n",
        "                    color = wb['cluster'],\n",
        "                    title =\"word-embedding-samples\")\n",
        "fig.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P9jSI12r9zqu"
      },
      "source": [
        "# **ETM Model**\n",
        "\n",
        "ETM hat die Architektur eines Variational Autoencoders. \n",
        "ETM wird mit den pretrainierten Embedding kombiniert. Die Embeddings für Topics werden als Gewichten eines Teiles des Netzes aktualiert mittels der ELBO Loss\n",
        "\n",
        "![ETM.drawio.png](data:image/png;base64,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)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fwiU9zWCIUh_",
        "outputId": "c90090b7-6fe2-4cc3-e9ff-c7541b0de3b5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "number train-samples: 139\n",
            "sum of sample vector: 1.0\n",
            "length of sample vector: 0.238095223903656\n"
          ]
        }
      ],
      "source": [
        "# using DocSet to use easier the modul DataSet from torch\n",
        "from src.train_etm import DocSet, TrainETM\n",
        "from src.etm import ETM\n",
        "import torch\n",
        "\n",
        "vocab_size = len(list(word2id.keys()))\n",
        "tr_set = DocSet(\"train\", vocab_size, train_set, normalize_data=True)\n",
        "print(f'number train-samples: {len(tr_set)}')\n",
        "print(f'sum of sample vector: {sum(tr_set.__getitem__(0))}')\n",
        "print(f'length of sample vector: {torch.norm(tr_set.__getitem__(0))}')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Trainingsparametern vorbereiten**\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "U4Z-7za3VYOv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class TrainArguments:\n",
        "      def __init__(self, epochs, batch_size, log_interval):\n",
        "          self.epochs = epochs\n",
        "          self.batch_size = batch_size\n",
        "          self.log_interval = log_interval\n",
        "\n",
        "class OptimizerArguments:\n",
        "      def __init__(self, optimizer_name, lr, wdecay):\n",
        "            self.optimizer = optimizer_name\n",
        "            self.lr = lr\n",
        "            self.wdecay = wdecay\n",
        "            \n",
        "train_args = TrainArguments(epochs=1000, batch_size=6, log_interval=None)\n",
        "optimizer_args = OptimizerArguments(optimizer_name=\"adam\", lr=0.001, wdecay=0.1)\n",
        "print(train_args.epochs)\n",
        "print(optimizer_args.optimizer)\n",
        "\n",
        "num_topics = 5\n",
        "t_hidden_size = 100\n",
        "rho_size = len(embedding_data[0])\n",
        "emb_size = len(embedding_data[0])\n",
        "theta_act = \"tanh\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oPKPTWbZVWuT",
        "outputId": "da3753fb-9c3b-4e3e-ac69-e22636593bda"
      },
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1000\n",
            "adam\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**ETM initialisieren**"
      ],
      "metadata": {
        "id": "WjO6yHpgVljt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# define the ETM-model with setting-parameters\n",
        "etm_model = ETM(\n",
        "      num_topics, \n",
        "      vocab_size, \n",
        "      t_hidden_size, rho_size, emb_size, theta_act, \n",
        "      embedding_data, \n",
        "      enc_drop=0.5)\n",
        "\n",
        "print(etm_model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IJ70hPX3VlOF",
        "outputId": "f728db97-b7da-4cee-cfbc-edfd6474f3a8"
      },
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ETM(\n",
            "  (t_drop): Dropout(p=0.5, inplace=False)\n",
            "  (theta_act): Tanh()\n",
            "  (topic_embeddings_alphas): Linear(in_features=10, out_features=5, bias=False)\n",
            "  (q_theta): Sequential(\n",
            "    (0): Linear(in_features=348, out_features=100, bias=True)\n",
            "    (1): Tanh()\n",
            "    (2): Linear(in_features=100, out_features=100, bias=True)\n",
            "    (3): Tanh()\n",
            "  )\n",
            "  (mu_q_theta): Linear(in_features=100, out_features=5, bias=True)\n",
            "  (logsigma_q_theta): Linear(in_features=100, out_features=5, bias=True)\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**trainieren**"
      ],
      "metadata": {
        "id": "gSPGu9NNV1_n"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 70,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "kbJIWLZpJRnG",
        "outputId": "a5616cee-0e0e-42b0-b620-9a5e6dc174b3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "number of batches: 23\n",
            "Epoch: 0/1000  -  Loss: 5.8624467849731445 \t Rec: 5.851572513580322 \t KL: 0.010874700732529163\n",
            "Epoch: 1/1000  -  Loss: 5.853898525238037 \t Rec: 5.851564407348633 \t KL: 0.0023341618943959475\n",
            "Epoch: 2/1000  -  Loss: 5.852960109710693 \t Rec: 5.851778984069824 \t KL: 0.0011818701168522239\n",
            "Epoch: 3/1000  -  Loss: 5.852344036102295 \t Rec: 5.851748466491699 \t KL: 0.000597165955696255\n",
            "Epoch: 4/1000  -  Loss: 5.852108001708984 \t Rec: 5.851848602294922 \t KL: 0.0002593557583168149\n",
            "Epoch: 5/1000  -  Loss: 5.8518266677856445 \t Rec: 5.8517303466796875 \t KL: 9.61982223088853e-05\n",
            "Epoch: 6/1000  -  Loss: 5.851770877838135 \t Rec: 5.851742267608643 \t KL: 2.8573947929544374e-05\n",
            "Epoch: 7/1000  -  Loss: 5.851799964904785 \t Rec: 5.851791858673096 \t KL: 7.114334039215464e-06\n",
            "Epoch: 8/1000  -  Loss: 5.851741790771484 \t Rec: 5.851740837097168 \t KL: 1.427056190550502e-06\n",
            "Epoch: 9/1000  -  Loss: 5.85178279876709 \t Rec: 5.85178279876709 \t KL: 2.1509502801109193e-07\n",
            "Epoch: 10/1000  -  Loss: 5.851741790771484 \t Rec: 5.851741790771484 \t KL: 2.6994857904583114e-08\n",
            "Epoch: 11/1000  -  Loss: 5.851758003234863 \t Rec: 5.851758003234863 \t KL: 2.1595882859770654e-09\n",
            "Epoch: 12/1000  -  Loss: 5.851769924163818 \t Rec: 5.851769924163818 \t KL: 4.3191772380879456e-10\n",
            "Epoch: 13/1000  -  Loss: 5.851773262023926 \t Rec: 5.851773262023926 \t KL: 0.0\n",
            "Epoch: 14/1000  -  Loss: 5.851778030395508 \t Rec: 5.851778030395508 \t KL: 0.0\n",
            "Epoch: 15/1000  -  Loss: 5.851782321929932 \t Rec: 5.851782321929932 \t KL: 0.0\n",
            "Epoch: 16/1000  -  Loss: 5.851785182952881 \t Rec: 5.851785182952881 \t KL: 0.0\n",
            "Epoch: 17/1000  -  Loss: 5.851789474487305 \t Rec: 5.851789474487305 \t KL: 0.0\n",
            "Epoch: 18/1000  -  Loss: 5.851789951324463 \t Rec: 5.851789951324463 \t KL: 0.0\n",
            "Epoch: 19/1000  -  Loss: 5.851788520812988 \t Rec: 5.851788520812988 \t KL: 0.0\n",
            "Epoch: 20/1000  -  Loss: 5.851800441741943 \t Rec: 5.851800441741943 \t KL: 0.0\n",
            "Epoch: 21/1000  -  Loss: 5.851788520812988 \t Rec: 5.851788520812988 \t KL: 0.0\n",
            "Epoch: 22/1000  -  Loss: 5.85179328918457 \t Rec: 5.85179328918457 \t KL: 0.0\n",
            "Epoch: 23/1000  -  Loss: 5.85180139541626 \t Rec: 5.85180139541626 \t KL: 0.0\n",
            "Epoch: 24/1000  -  Loss: 5.85179328918457 \t Rec: 5.85179328918457 \t KL: 0.0\n",
            "Epoch: 25/1000  -  Loss: 5.851797580718994 \t Rec: 5.851797580718994 \t KL: 0.0\n",
            "Epoch: 26/1000  -  Loss: 5.851795196533203 \t Rec: 5.851795196533203 \t KL: 0.0\n",
            "Epoch: 27/1000  -  Loss: 5.851806163787842 \t Rec: 5.851806163787842 \t KL: 0.0\n",
            "Epoch: 28/1000  -  Loss: 5.851800441741943 \t Rec: 5.851800441741943 \t KL: 0.0\n",
            "Epoch: 29/1000  -  Loss: 5.85180139541626 \t Rec: 5.85180139541626 \t KL: 0.0\n",
            "Epoch: 30/1000  -  Loss: 5.851797580718994 \t Rec: 5.851797580718994 \t KL: 0.0\n",
            "Epoch: 31/1000  -  Loss: 5.85180139541626 \t Rec: 5.85180139541626 \t KL: 0.0\n",
            "Epoch: 32/1000  -  Loss: 5.851801872253418 \t Rec: 5.851801872253418 \t KL: 0.0\n",
            "Epoch: 33/1000  -  Loss: 5.851805210113525 \t Rec: 5.851805210113525 \t KL: 0.0\n",
            "Epoch: 34/1000  -  Loss: 5.851802825927734 \t Rec: 5.851802825927734 \t KL: 0.0\n",
            "Epoch: 35/1000  -  Loss: 5.851800441741943 \t Rec: 5.851800441741943 \t KL: 0.0\n",
            "Epoch: 36/1000  -  Loss: 5.851799964904785 \t Rec: 5.851799964904785 \t KL: 0.0\n",
            "Epoch: 37/1000  -  Loss: 5.85180139541626 \t Rec: 5.85180139541626 \t KL: 0.0\n",
            "Epoch: 38/1000  -  Loss: 5.851802825927734 \t Rec: 5.851802825927734 \t KL: 0.0\n",
            "Epoch: 39/1000  -  Loss: 5.851805210113525 \t Rec: 5.851805210113525 \t KL: 0.0\n",
            "Epoch: 40/1000  -  Loss: 5.851803302764893 \t Rec: 5.851803302764893 \t KL: 0.0\n",
            "Epoch: 41/1000  -  Loss: 5.851806163787842 \t Rec: 5.851806163787842 \t KL: 0.0\n",
            "Epoch: 42/1000  -  Loss: 5.851803779602051 \t Rec: 5.851803779602051 \t KL: 0.0\n",
            "Epoch: 43/1000  -  Loss: 5.85180139541626 \t Rec: 5.85180139541626 \t KL: 0.0\n",
            "Epoch: 44/1000  -  Loss: 5.851803302764893 \t Rec: 5.851803302764893 \t KL: 0.0\n",
            "Epoch: 45/1000  -  Loss: 5.851803779602051 \t Rec: 5.851803779602051 \t KL: 0.0\n",
            "Epoch: 46/1000  -  Loss: 5.851803779602051 \t Rec: 5.851803779602051 \t KL: 0.0\n",
            "Epoch: 47/1000  -  Loss: 5.85180139541626 \t Rec: 5.85180139541626 \t KL: 0.0\n",
            "Epoch: 48/1000  -  Loss: 5.851806163787842 \t Rec: 5.851806163787842 \t KL: 0.0\n",
            "Epoch: 49/1000  -  Loss: 5.851803302764893 \t Rec: 5.851803302764893 \t KL: 0.0\n",
            "Epoch: 50/1000  -  Loss: 5.851806163787842 \t Rec: 5.851806163787842 \t KL: 0.0\n",
            "Epoch: 51/1000  -  Loss: 5.85180139541626 \t Rec: 5.85180139541626 \t KL: 0.0\n",
            "Epoch: 52/1000  -  Loss: 5.851808071136475 \t Rec: 5.851808071136475 \t KL: 0.0\n",
            "Epoch: 53/1000  -  Loss: 5.851801872253418 \t Rec: 5.851801872253418 \t KL: 0.0\n",
            "Epoch: 54/1000  -  Loss: 5.851801872253418 \t Rec: 5.851801872253418 \t KL: 0.0\n",
            "Epoch: 55/1000  -  Loss: 5.851801872253418 \t Rec: 5.851801872253418 \t KL: 0.0\n",
            "Epoch: 56/1000  -  Loss: 5.85180139541626 \t Rec: 5.85180139541626 \t KL: 0.0\n",
            "Epoch: 57/1000  -  Loss: 5.851806163787842 \t Rec: 5.851806163787842 \t KL: 0.0\n",
            "Epoch: 58/1000  -  Loss: 5.851806163787842 \t Rec: 5.851806163787842 \t KL: 0.0\n",
            "Epoch: 59/1000  -  Loss: 5.851799488067627 \t Rec: 5.851799488067627 \t KL: 0.0\n",
            "Epoch: 60/1000  -  Loss: 5.851800441741943 \t Rec: 5.851800441741943 \t KL: 0.0\n",
            "Epoch: 61/1000  -  Loss: 5.851802825927734 \t Rec: 5.851802825927734 \t KL: 0.0\n",
            "Epoch: 62/1000  -  Loss: 5.851806640625 \t Rec: 5.851806640625 \t KL: 0.0\n",
            "Epoch: 63/1000  -  Loss: 5.851802825927734 \t Rec: 5.851802825927734 \t KL: 0.0\n",
            "Epoch: 64/1000  -  Loss: 5.851809501647949 \t Rec: 5.851809501647949 \t KL: 0.0\n",
            "Epoch: 65/1000  -  Loss: 5.851805210113525 \t Rec: 5.851805210113525 \t KL: 0.0\n",
            "Epoch: 66/1000  -  Loss: 5.851799488067627 \t Rec: 5.851799488067627 \t KL: 0.0\n",
            "Epoch: 67/1000  -  Loss: 5.851800441741943 \t Rec: 5.851800441741943 \t KL: 0.0\n",
            "Epoch: 68/1000  -  Loss: 5.851800441741943 \t Rec: 5.851800441741943 \t KL: 0.0\n",
            "Epoch: 69/1000  -  Loss: 5.85180139541626 \t Rec: 5.85180139541626 \t KL: 0.0\n",
            "Epoch: 70/1000  -  Loss: 5.85180139541626 \t Rec: 5.85180139541626 \t KL: 0.0\n",
            "Epoch: 71/1000  -  Loss: 5.851805210113525 \t Rec: 5.851805210113525 \t KL: 0.0\n",
            "Epoch: 72/1000  -  Loss: 5.851804733276367 \t Rec: 5.851804733276367 \t KL: 0.0\n",
            "Epoch: 73/1000  -  Loss: 5.851802825927734 \t Rec: 5.851802825927734 \t KL: 0.0\n",
            "Epoch: 74/1000  -  Loss: 5.85180139541626 \t Rec: 5.85180139541626 \t KL: 0.0\n",
            "Epoch: 75/1000  -  Loss: 5.8517985343933105 \t Rec: 5.8517985343933105 \t KL: 0.0\n",
            "Epoch: 76/1000  -  Loss: 5.851805210113525 \t Rec: 5.851805210113525 \t KL: 0.0\n",
            "Epoch: 77/1000  -  Loss: 5.851805210113525 \t Rec: 5.851805210113525 \t KL: 0.0\n",
            "Epoch: 78/1000  -  Loss: 5.85180139541626 \t Rec: 5.85180139541626 \t KL: 0.0\n",
            "Epoch: 79/1000  -  Loss: 5.8517985343933105 \t Rec: 5.8517985343933105 \t KL: 0.0\n",
            "Epoch: 80/1000  -  Loss: 5.851803302764893 \t Rec: 5.851803302764893 \t KL: 0.0\n",
            "Epoch: 81/1000  -  Loss: 5.851805210113525 \t Rec: 5.851805210113525 \t KL: 0.0\n",
            "Epoch: 82/1000  -  Loss: 5.851806640625 \t Rec: 5.851806640625 \t KL: 0.0\n",
            "Epoch: 83/1000  -  Loss: 5.851806163787842 \t Rec: 5.851806163787842 \t KL: 0.0\n",
            "Epoch: 84/1000  -  Loss: 5.851794719696045 \t Rec: 5.851794719696045 \t KL: 0.0\n",
            "Epoch: 85/1000  -  Loss: 5.851807117462158 \t Rec: 5.851807117462158 \t KL: 0.0\n",
            "Epoch: 86/1000  -  Loss: 5.851804733276367 \t Rec: 5.851804733276367 \t KL: 0.0\n",
            "Epoch: 87/1000  -  Loss: 5.851803779602051 \t Rec: 5.851803779602051 \t KL: 0.0\n",
            "Epoch: 88/1000  -  Loss: 5.85180139541626 \t Rec: 5.85180139541626 \t KL: 0.0\n",
            "Epoch: 89/1000  -  Loss: 5.851809501647949 \t Rec: 5.851809501647949 \t KL: 0.0\n",
            "Epoch: 90/1000  -  Loss: 5.8517985343933105 \t Rec: 5.8517985343933105 \t KL: 0.0\n",
            "Epoch: 91/1000  -  Loss: 5.8517985343933105 \t Rec: 5.8517985343933105 \t KL: 0.0\n",
            "Epoch: 92/1000  -  Loss: 5.851806640625 \t Rec: 5.851806640625 \t KL: 0.0\n",
            "Epoch: 93/1000  -  Loss: 5.851804733276367 \t Rec: 5.851804733276367 \t KL: 0.0\n",
            "Epoch: 94/1000  -  Loss: 5.851805210113525 \t Rec: 5.851805210113525 \t KL: 0.0\n",
            "Epoch: 95/1000  -  Loss: 5.851801872253418 \t Rec: 5.851801872253418 \t KL: 0.0\n",
            "Epoch: 96/1000  -  Loss: 5.851802825927734 \t Rec: 5.851802825927734 \t KL: 0.0\n",
            "Epoch: 97/1000  -  Loss: 5.851805210113525 \t Rec: 5.851805210113525 \t KL: 0.0\n",
            "Epoch: 98/1000  -  Loss: 5.851809501647949 \t Rec: 5.851809501647949 \t KL: 0.0\n",
            "Epoch: 99/1000  -  Loss: 5.851801872253418 \t Rec: 5.851801872253418 \t KL: 0.0\n",
            "Epoch: 100/1000  -  Loss: 5.851806640625 \t Rec: 5.851806640625 \t KL: 0.0\n",
            "Epoch: 101/1000  -  Loss: 5.851805210113525 \t Rec: 5.851805210113525 \t KL: 0.0\n",
            "Epoch: 102/1000  -  Loss: 5.851804733276367 \t Rec: 5.851804733276367 \t KL: 0.0\n",
            "Epoch: 103/1000  -  Loss: 5.851803302764893 \t Rec: 5.851803302764893 \t KL: 0.0\n",
            "Epoch: 104/1000  -  Loss: 5.851806163787842 \t Rec: 5.851806163787842 \t KL: 0.0\n",
            "Epoch: 105/1000  -  Loss: 5.851801872253418 \t Rec: 5.851801872253418 \t KL: 0.0\n",
            "Epoch: 106/1000  -  Loss: 5.851799964904785 \t Rec: 5.851799964904785 \t KL: 0.0\n",
            "Epoch: 107/1000  -  Loss: 5.851809978485107 \t Rec: 5.851809978485107 \t KL: 0.0\n",
            "Epoch: 108/1000  -  Loss: 5.851806163787842 \t Rec: 5.851806163787842 \t KL: 0.0\n",
            "Epoch: 109/1000  -  Loss: 5.851806640625 \t Rec: 5.851806640625 \t KL: 0.0\n",
            "Epoch: 110/1000  -  Loss: 5.851803779602051 \t Rec: 5.851803779602051 \t KL: 0.0\n",
            "Epoch: 111/1000  -  Loss: 5.85180139541626 \t Rec: 5.85180139541626 \t KL: 0.0\n",
            "Epoch: 112/1000  -  Loss: 5.851804733276367 \t Rec: 5.851804733276367 \t KL: 0.0\n",
            "Epoch: 113/1000  -  Loss: 5.8517985343933105 \t Rec: 5.8517985343933105 \t KL: 0.0\n",
            "Epoch: 114/1000  -  Loss: 5.851805210113525 \t Rec: 5.851805210113525 \t KL: 0.0\n",
            "Epoch: 115/1000  -  Loss: 5.851805210113525 \t Rec: 5.851805210113525 \t KL: 0.0\n",
            "Epoch: 116/1000  -  Loss: 5.851808071136475 \t Rec: 5.851808071136475 \t KL: 0.0\n",
            "Epoch: 117/1000  -  Loss: 5.851803302764893 \t Rec: 5.851803302764893 \t KL: 0.0\n",
            "Epoch: 118/1000  -  Loss: 5.851806163787842 \t Rec: 5.851806163787842 \t KL: 0.0\n",
            "Epoch: 119/1000  -  Loss: 5.851802825927734 \t Rec: 5.851802825927734 \t KL: 0.0\n",
            "Epoch: 120/1000  -  Loss: 5.851799488067627 \t Rec: 5.851799488067627 \t KL: 0.0\n",
            "Epoch: 121/1000  -  Loss: 5.851807117462158 \t Rec: 5.851807117462158 \t KL: 0.0\n",
            "Epoch: 122/1000  -  Loss: 5.851807117462158 \t Rec: 5.851807117462158 \t KL: 0.0\n",
            "Epoch: 123/1000  -  Loss: 5.851801872253418 \t Rec: 5.851801872253418 \t KL: 0.0\n",
            "Epoch: 124/1000  -  Loss: 5.851802825927734 \t Rec: 5.851802825927734 \t KL: 0.0\n",
            "Epoch: 125/1000  -  Loss: 5.851802825927734 \t Rec: 5.851802825927734 \t KL: 0.0\n",
            "Epoch: 126/1000  -  Loss: 5.851803779602051 \t Rec: 5.851803779602051 \t KL: 0.0\n",
            "Epoch: 127/1000  -  Loss: 5.851805210113525 \t Rec: 5.851805210113525 \t KL: 0.0\n",
            "Epoch: 128/1000  -  Loss: 5.85180139541626 \t Rec: 5.85180139541626 \t KL: 0.0\n",
            "Epoch: 129/1000  -  Loss: 5.851811408996582 \t Rec: 5.851811408996582 \t KL: 0.0\n",
            "Epoch: 130/1000  -  Loss: 5.851799488067627 \t Rec: 5.851799488067627 \t KL: 0.0\n",
            "Epoch: 131/1000  -  Loss: 5.8517985343933105 \t Rec: 5.8517985343933105 \t KL: 0.0\n",
            "Epoch: 132/1000  -  Loss: 5.851803779602051 \t Rec: 5.851803779602051 \t KL: 0.0\n",
            "Epoch: 133/1000  -  Loss: 5.851802825927734 \t Rec: 5.851802825927734 \t KL: 0.0\n",
            "Epoch: 134/1000  -  Loss: 5.851809501647949 \t Rec: 5.851809501647949 \t KL: 0.0\n",
            "Epoch: 135/1000  -  Loss: 5.851802825927734 \t Rec: 5.851802825927734 \t KL: 0.0\n",
            "Epoch: 136/1000  -  Loss: 5.851806163787842 \t Rec: 5.851806163787842 \t KL: 0.0\n",
            "Epoch: 137/1000  -  Loss: 5.851803779602051 \t Rec: 5.851803779602051 \t KL: 0.0\n",
            "Epoch: 138/1000  -  Loss: 5.851804733276367 \t Rec: 5.851804733276367 \t KL: 0.0\n",
            "Epoch: 139/1000  -  Loss: 5.851806163787842 \t Rec: 5.851806163787842 \t KL: 0.0\n",
            "Epoch: 140/1000  -  Loss: 5.851803779602051 \t Rec: 5.851803779602051 \t KL: 0.0\n",
            "Epoch: 141/1000  -  Loss: 5.851807117462158 \t Rec: 5.851807117462158 \t KL: 0.0\n",
            "Epoch: 142/1000  -  Loss: 5.851802825927734 \t Rec: 5.851802825927734 \t KL: 0.0\n",
            "Epoch: 143/1000  -  Loss: 5.851808071136475 \t Rec: 5.851808071136475 \t KL: 0.0\n",
            "Epoch: 144/1000  -  Loss: 5.851799964904785 \t Rec: 5.851799964904785 \t KL: 0.0\n",
            "Epoch: 145/1000  -  Loss: 5.851812839508057 \t Rec: 5.851812839508057 \t KL: 0.0\n",
            "Epoch: 146/1000  -  Loss: 5.851794719696045 \t Rec: 5.851794719696045 \t KL: 0.0\n",
            "Epoch: 147/1000  -  Loss: 5.85181188583374 \t Rec: 5.85181188583374 \t KL: 0.0\n",
            "Epoch: 148/1000  -  Loss: 5.851805210113525 \t Rec: 5.851805210113525 \t KL: 0.0\n",
            "Epoch: 149/1000  -  Loss: 5.851799964904785 \t Rec: 5.851799964904785 \t KL: 0.0\n",
            "Epoch: 150/1000  -  Loss: 5.851806640625 \t Rec: 5.851806640625 \t KL: 0.0\n",
            "Epoch: 151/1000  -  Loss: 5.851803302764893 \t Rec: 5.851803302764893 \t KL: 0.0\n",
            "Epoch: 152/1000  -  Loss: 5.85180139541626 \t Rec: 5.85180139541626 \t KL: 0.0\n",
            "Epoch: 153/1000  -  Loss: 5.851810455322266 \t Rec: 5.851810455322266 \t KL: 0.0\n",
            "Epoch: 154/1000  -  Loss: 5.851806163787842 \t Rec: 5.851806163787842 \t KL: 0.0\n",
            "Epoch: 155/1000  -  Loss: 5.851804733276367 \t Rec: 5.851804733276367 \t KL: 0.0\n",
            "Epoch: 156/1000  -  Loss: 5.851798057556152 \t Rec: 5.851798057556152 \t KL: 0.0\n",
            "Epoch: 157/1000  -  Loss: 5.851806163787842 \t Rec: 5.851806163787842 \t KL: 0.0\n",
            "Epoch: 158/1000  -  Loss: 5.851801872253418 \t Rec: 5.851801872253418 \t KL: 0.0\n",
            "Epoch: 159/1000  -  Loss: 5.85180139541626 \t Rec: 5.85180139541626 \t KL: 0.0\n",
            "Epoch: 160/1000  -  Loss: 5.851810455322266 \t Rec: 5.851810455322266 \t KL: 0.0\n",
            "Epoch: 161/1000  -  Loss: 5.851802825927734 \t Rec: 5.851802825927734 \t KL: 0.0\n",
            "Epoch: 162/1000  -  Loss: 5.8518147468566895 \t Rec: 5.8518147468566895 \t KL: 0.0\n",
            "Epoch: 163/1000  -  Loss: 5.851801872253418 \t Rec: 5.851801872253418 \t KL: 0.0\n",
            "Epoch: 164/1000  -  Loss: 5.851805210113525 \t Rec: 5.851805210113525 \t KL: 0.0\n",
            "Epoch: 165/1000  -  Loss: 5.851803779602051 \t Rec: 5.851803779602051 \t KL: 0.0\n",
            "Epoch: 166/1000  -  Loss: 5.851816654205322 \t Rec: 5.851816654205322 \t KL: 0.0\n",
            "Epoch: 167/1000  -  Loss: 5.8517961502075195 \t Rec: 5.8517961502075195 \t KL: 0.0\n",
            "Epoch: 168/1000  -  Loss: 5.851803302764893 \t Rec: 5.851803302764893 \t KL: 0.0\n",
            "Epoch: 169/1000  -  Loss: 5.85180139541626 \t Rec: 5.85180139541626 \t KL: 0.0\n",
            "Epoch: 170/1000  -  Loss: 5.851803779602051 \t Rec: 5.851803779602051 \t KL: 0.0\n",
            "Epoch: 171/1000  -  Loss: 5.851809978485107 \t Rec: 5.851809978485107 \t KL: 0.0\n",
            "Epoch: 172/1000  -  Loss: 5.851808547973633 \t Rec: 5.851808547973633 \t KL: 0.0\n",
            "Epoch: 173/1000  -  Loss: 5.851803779602051 \t Rec: 5.851803779602051 \t KL: 0.0\n",
            "Epoch: 174/1000  -  Loss: 5.851803302764893 \t Rec: 5.851803302764893 \t KL: 0.0\n",
            "Epoch: 175/1000  -  Loss: 5.851810455322266 \t Rec: 5.851810455322266 \t KL: 0.0\n",
            "Epoch: 176/1000  -  Loss: 5.851803302764893 \t Rec: 5.851803302764893 \t KL: 0.0\n",
            "Epoch: 177/1000  -  Loss: 5.851806163787842 \t Rec: 5.851806163787842 \t KL: 0.0\n",
            "Epoch: 178/1000  -  Loss: 5.851797580718994 \t Rec: 5.851797580718994 \t KL: 0.0\n",
            "Epoch: 179/1000  -  Loss: 5.851808071136475 \t Rec: 5.851808071136475 \t KL: 0.0\n",
            "Epoch: 180/1000  -  Loss: 5.851805210113525 \t Rec: 5.851805210113525 \t KL: 0.0\n",
            "Epoch: 181/1000  -  Loss: 5.851808547973633 \t Rec: 5.851808547973633 \t KL: 0.0\n",
            "Epoch: 182/1000  -  Loss: 5.851797580718994 \t Rec: 5.851797580718994 \t KL: 0.0\n",
            "Epoch: 183/1000  -  Loss: 5.851808071136475 \t Rec: 5.851808071136475 \t KL: 0.0\n",
            "Epoch: 184/1000  -  Loss: 5.851804733276367 \t Rec: 5.851804733276367 \t KL: 0.0\n",
            "Epoch: 185/1000  -  Loss: 5.851809978485107 \t Rec: 5.851809978485107 \t KL: 0.0\n",
            "Epoch: 186/1000  -  Loss: 5.8517985343933105 \t Rec: 5.8517985343933105 \t KL: 0.0\n",
            "Epoch: 187/1000  -  Loss: 5.851802825927734 \t Rec: 5.851802825927734 \t KL: 0.0\n",
            "Epoch: 188/1000  -  Loss: 5.851803302764893 \t Rec: 5.851803302764893 \t KL: 0.0\n",
            "Epoch: 189/1000  -  Loss: 5.8518171310424805 \t Rec: 5.8518171310424805 \t KL: 0.0\n",
            "Epoch: 190/1000  -  Loss: 5.851796627044678 \t Rec: 5.851796627044678 \t KL: 0.0\n",
            "Epoch: 191/1000  -  Loss: 5.851799488067627 \t Rec: 5.851799488067627 \t KL: 0.0\n",
            "Epoch: 192/1000  -  Loss: 5.851808071136475 \t Rec: 5.851808071136475 \t KL: 0.0\n",
            "Epoch: 193/1000  -  Loss: 5.851806640625 \t Rec: 5.851806640625 \t KL: 0.0\n",
            "Epoch: 194/1000  -  Loss: 5.851803779602051 \t Rec: 5.851803779602051 \t KL: 0.0\n",
            "Epoch: 195/1000  -  Loss: 5.851796627044678 \t Rec: 5.851796627044678 \t KL: 0.0\n",
            "Epoch: 196/1000  -  Loss: 5.851803779602051 \t Rec: 5.851803779602051 \t KL: 0.0\n",
            "Epoch: 197/1000  -  Loss: 5.851808547973633 \t Rec: 5.851808547973633 \t KL: 0.0\n",
            "Epoch: 198/1000  -  Loss: 5.85180139541626 \t Rec: 5.85180139541626 \t KL: 0.0\n",
            "Epoch: 199/1000  -  Loss: 5.851801872253418 \t Rec: 5.851801872253418 \t KL: 0.0\n",
            "Epoch: 200/1000  -  Loss: 5.851808547973633 \t Rec: 5.851808547973633 \t KL: 0.0\n",
            "Epoch: 201/1000  -  Loss: 5.851808071136475 \t Rec: 5.851808071136475 \t KL: 0.0\n",
            "Epoch: 202/1000  -  Loss: 5.851801872253418 \t Rec: 5.851801872253418 \t KL: 0.0\n",
            "Epoch: 203/1000  -  Loss: 5.85180139541626 \t Rec: 5.85180139541626 \t KL: 0.0\n",
            "Epoch: 204/1000  -  Loss: 5.851805210113525 \t Rec: 5.851805210113525 \t KL: 0.0\n",
            "Epoch: 205/1000  -  Loss: 5.851812839508057 \t Rec: 5.851812839508057 \t KL: 0.0\n",
            "Epoch: 206/1000  -  Loss: 5.851803302764893 \t Rec: 5.851803302764893 \t KL: 0.0\n",
            "Epoch: 207/1000  -  Loss: 5.851813793182373 \t Rec: 5.851813793182373 \t KL: 0.0\n",
            "Epoch: 208/1000  -  Loss: 5.8517961502075195 \t Rec: 5.8517961502075195 \t KL: 0.0\n",
            "Epoch: 209/1000  -  Loss: 5.851803302764893 \t Rec: 5.851803302764893 \t KL: 0.0\n",
            "Epoch: 210/1000  -  Loss: 5.851812839508057 \t Rec: 5.851812839508057 \t KL: 0.0\n",
            "Epoch: 211/1000  -  Loss: 5.851796627044678 \t Rec: 5.851796627044678 \t KL: 0.0\n",
            "Epoch: 212/1000  -  Loss: 5.851811408996582 \t Rec: 5.851811408996582 \t KL: 0.0\n",
            "Epoch: 213/1000  -  Loss: 5.851806163787842 \t Rec: 5.851806163787842 \t KL: 0.0\n",
            "Epoch: 214/1000  -  Loss: 5.851799964904785 \t Rec: 5.851799964904785 \t KL: 0.0\n",
            "Epoch: 215/1000  -  Loss: 5.851806163787842 \t Rec: 5.851806163787842 \t KL: 0.0\n",
            "Epoch: 216/1000  -  Loss: 5.851804733276367 \t Rec: 5.851804733276367 \t KL: 0.0\n",
            "Epoch: 217/1000  -  Loss: 5.851805210113525 \t Rec: 5.851805210113525 \t KL: 0.0\n",
            "Epoch: 218/1000  -  Loss: 5.851810455322266 \t Rec: 5.851810455322266 \t KL: 0.0\n",
            "Epoch: 219/1000  -  Loss: 5.851804733276367 \t Rec: 5.851804733276367 \t KL: 0.0\n",
            "Epoch: 220/1000  -  Loss: 5.851799964904785 \t Rec: 5.851799964904785 \t KL: 0.0\n",
            "Epoch: 221/1000  -  Loss: 5.851807117462158 \t Rec: 5.851807117462158 \t KL: 0.0\n",
            "Epoch: 222/1000  -  Loss: 5.851803779602051 \t Rec: 5.851803779602051 \t KL: 0.0\n",
            "Epoch: 223/1000  -  Loss: 5.85180139541626 \t Rec: 5.85180139541626 \t KL: 0.0\n",
            "Epoch: 224/1000  -  Loss: 5.851805210113525 \t Rec: 5.851805210113525 \t KL: 0.0\n",
            "Epoch: 225/1000  -  Loss: 5.85180139541626 \t Rec: 5.85180139541626 \t KL: 0.0\n",
            "Epoch: 226/1000  -  Loss: 5.851808071136475 \t Rec: 5.851808071136475 \t KL: 0.0\n",
            "Epoch: 227/1000  -  Loss: 5.851809501647949 \t Rec: 5.851809501647949 \t KL: 0.0\n",
            "Epoch: 228/1000  -  Loss: 5.851804733276367 \t Rec: 5.851804733276367 \t KL: 0.0\n",
            "Epoch: 229/1000  -  Loss: 5.851799964904785 \t Rec: 5.851799964904785 \t KL: 0.0\n",
            "Epoch: 230/1000  -  Loss: 5.851806163787842 \t Rec: 5.851806163787842 \t KL: 0.0\n",
            "Epoch: 231/1000  -  Loss: 5.85180139541626 \t Rec: 5.85180139541626 \t KL: 0.0\n",
            "Epoch: 232/1000  -  Loss: 5.851807117462158 \t Rec: 5.851807117462158 \t KL: 0.0\n",
            "Epoch: 233/1000  -  Loss: 5.851808071136475 \t Rec: 5.851808071136475 \t KL: 0.0\n",
            "Epoch: 234/1000  -  Loss: 5.851798057556152 \t Rec: 5.851798057556152 \t KL: 0.0\n",
            "Epoch: 235/1000  -  Loss: 5.851809501647949 \t Rec: 5.851809501647949 \t KL: 0.0\n",
            "Epoch: 236/1000  -  Loss: 5.851803302764893 \t Rec: 5.851803302764893 \t KL: 0.0\n",
            "Epoch: 237/1000  -  Loss: 5.851803779602051 \t Rec: 5.851803779602051 \t KL: 0.0\n",
            "Epoch: 238/1000  -  Loss: 5.851798057556152 \t Rec: 5.851798057556152 \t KL: 0.0\n",
            "Epoch: 239/1000  -  Loss: 5.851800441741943 \t Rec: 5.851800441741943 \t KL: 0.0\n",
            "Epoch: 240/1000  -  Loss: 5.851809501647949 \t Rec: 5.851809501647949 \t KL: 0.0\n",
            "Epoch: 241/1000  -  Loss: 5.85180139541626 \t Rec: 5.85180139541626 \t KL: 0.0\n",
            "Epoch: 242/1000  -  Loss: 5.851800441741943 \t Rec: 5.851800441741943 \t KL: 0.0\n",
            "Epoch: 243/1000  -  Loss: 5.85180139541626 \t Rec: 5.85180139541626 \t KL: 0.0\n",
            "Epoch: 244/1000  -  Loss: 5.8518171310424805 \t Rec: 5.8518171310424805 \t KL: 0.0\n",
            "Epoch: 245/1000  -  Loss: 5.851799488067627 \t Rec: 5.851799488067627 \t KL: 0.0\n",
            "Epoch: 246/1000  -  Loss: 5.851808547973633 \t Rec: 5.851808547973633 \t KL: 0.0\n",
            "Epoch: 247/1000  -  Loss: 5.851807117462158 \t Rec: 5.851807117462158 \t KL: 0.0\n",
            "Epoch: 248/1000  -  Loss: 5.851807117462158 \t Rec: 5.851807117462158 \t KL: 0.0\n",
            "Epoch: 249/1000  -  Loss: 5.851801872253418 \t Rec: 5.851801872253418 \t KL: 0.0\n",
            "Epoch: 250/1000  -  Loss: 5.851808547973633 \t Rec: 5.851808547973633 \t KL: 0.0\n",
            "Epoch: 251/1000  -  Loss: 5.851803779602051 \t Rec: 5.851803779602051 \t KL: 0.0\n",
            "Epoch: 252/1000  -  Loss: 5.851806163787842 \t Rec: 5.851806163787842 \t KL: 0.0\n",
            "Epoch: 253/1000  -  Loss: 5.851808071136475 \t Rec: 5.851808071136475 \t KL: 0.0\n",
            "Epoch: 254/1000  -  Loss: 5.851802825927734 \t Rec: 5.851802825927734 \t KL: 0.0\n",
            "Epoch: 255/1000  -  Loss: 5.851806163787842 \t Rec: 5.851806163787842 \t KL: 0.0\n",
            "Epoch: 256/1000  -  Loss: 5.851808071136475 \t Rec: 5.851808071136475 \t KL: 0.0\n",
            "Epoch: 257/1000  -  Loss: 5.8517985343933105 \t Rec: 5.8517985343933105 \t KL: 0.0\n",
            "Epoch: 258/1000  -  Loss: 5.851805210113525 \t Rec: 5.851805210113525 \t KL: 0.0\n",
            "Epoch: 259/1000  -  Loss: 5.851799488067627 \t Rec: 5.851799488067627 \t KL: 0.0\n",
            "Epoch: 260/1000  -  Loss: 5.851805210113525 \t Rec: 5.851805210113525 \t KL: 0.0\n",
            "Epoch: 261/1000  -  Loss: 5.851805210113525 \t Rec: 5.851805210113525 \t KL: 0.0\n",
            "Epoch: 262/1000  -  Loss: 5.8517985343933105 \t Rec: 5.8517985343933105 \t KL: 0.0\n",
            "Epoch: 263/1000  -  Loss: 5.851809501647949 \t Rec: 5.851809501647949 \t KL: 0.0\n",
            "Epoch: 264/1000  -  Loss: 5.851803302764893 \t Rec: 5.851803302764893 \t KL: 0.0\n",
            "Epoch: 265/1000  -  Loss: 5.851803302764893 \t Rec: 5.851803302764893 \t KL: 0.0\n",
            "Epoch: 266/1000  -  Loss: 5.851807117462158 \t Rec: 5.851807117462158 \t KL: 0.0\n",
            "Epoch: 267/1000  -  Loss: 5.851799964904785 \t Rec: 5.851799964904785 \t KL: 0.0\n",
            "Epoch: 268/1000  -  Loss: 5.85181188583374 \t Rec: 5.85181188583374 \t KL: 0.0\n",
            "Epoch: 269/1000  -  Loss: 5.8517985343933105 \t Rec: 5.8517985343933105 \t KL: 0.0\n",
            "Epoch: 270/1000  -  Loss: 5.851804733276367 \t Rec: 5.851804733276367 \t KL: 0.0\n",
            "Epoch: 271/1000  -  Loss: 5.85180139541626 \t Rec: 5.85180139541626 \t KL: 0.0\n",
            "Epoch: 272/1000  -  Loss: 5.851806640625 \t Rec: 5.851806640625 \t KL: 0.0\n",
            "Epoch: 273/1000  -  Loss: 5.851804733276367 \t Rec: 5.851804733276367 \t KL: 0.0\n",
            "Epoch: 274/1000  -  Loss: 5.851815700531006 \t Rec: 5.851815700531006 \t KL: 0.0\n",
            "Epoch: 275/1000  -  Loss: 5.851808071136475 \t Rec: 5.851808071136475 \t KL: 0.0\n",
            "Epoch: 276/1000  -  Loss: 5.851802825927734 \t Rec: 5.851802825927734 \t KL: 0.0\n",
            "Epoch: 277/1000  -  Loss: 5.851809501647949 \t Rec: 5.851809501647949 \t KL: 0.0\n",
            "Epoch: 278/1000  -  Loss: 5.851805210113525 \t Rec: 5.851805210113525 \t KL: 0.0\n",
            "Epoch: 279/1000  -  Loss: 5.851805210113525 \t Rec: 5.851805210113525 \t KL: 0.0\n",
            "Epoch: 280/1000  -  Loss: 5.851807117462158 \t Rec: 5.851807117462158 \t KL: 0.0\n",
            "Epoch: 281/1000  -  Loss: 5.851804733276367 \t Rec: 5.851804733276367 \t KL: 0.0\n",
            "Epoch: 282/1000  -  Loss: 5.851802825927734 \t Rec: 5.851802825927734 \t KL: 0.0\n",
            "Epoch: 283/1000  -  Loss: 5.851798057556152 \t Rec: 5.851798057556152 \t KL: 0.0\n",
            "Epoch: 284/1000  -  Loss: 5.851816654205322 \t Rec: 5.851816654205322 \t KL: 0.0\n",
            "Epoch: 285/1000  -  Loss: 5.851800441741943 \t Rec: 5.851800441741943 \t KL: 1.2957531714263837e-09\n",
            "Epoch: 286/1000  -  Loss: 5.851801872253418 \t Rec: 5.851801872253418 \t KL: 0.0\n",
            "Epoch: 287/1000  -  Loss: 5.851805210113525 \t Rec: 5.851805210113525 \t KL: 0.0\n",
            "Epoch: 288/1000  -  Loss: 5.85181188583374 \t Rec: 5.85181188583374 \t KL: 0.0\n",
            "Epoch: 289/1000  -  Loss: 5.851802825927734 \t Rec: 5.851802825927734 \t KL: 1.2957531714263837e-09\n",
            "Epoch: 290/1000  -  Loss: 5.851804733276367 \t Rec: 5.851804733276367 \t KL: 0.0\n",
            "Epoch: 291/1000  -  Loss: 5.851803779602051 \t Rec: 5.851803779602051 \t KL: 0.0\n",
            "Epoch: 292/1000  -  Loss: 5.851809978485107 \t Rec: 5.851809978485107 \t KL: 0.0\n",
            "Epoch: 293/1000  -  Loss: 5.851803302764893 \t Rec: 5.851803302764893 \t KL: 0.0\n",
            "Epoch: 294/1000  -  Loss: 5.851803779602051 \t Rec: 5.851803779602051 \t KL: 0.0\n",
            "Epoch: 295/1000  -  Loss: 5.851805210113525 \t Rec: 5.851805210113525 \t KL: 0.0\n",
            "Epoch: 296/1000  -  Loss: 5.851809501647949 \t Rec: 5.851809501647949 \t KL: 0.0\n",
            "Epoch: 297/1000  -  Loss: 5.851806640625 \t Rec: 5.851806640625 \t KL: 0.0\n",
            "Epoch: 298/1000  -  Loss: 5.851808071136475 \t Rec: 5.851808071136475 \t KL: 0.0\n",
            "Epoch: 299/1000  -  Loss: 5.851803779602051 \t Rec: 5.851803779602051 \t KL: 0.0\n",
            "Epoch: 300/1000  -  Loss: 5.851804733276367 \t Rec: 5.851804733276367 \t KL: 0.0\n",
            "Epoch: 301/1000  -  Loss: 5.851804733276367 \t Rec: 5.851804733276367 \t KL: 0.0\n",
            "Epoch: 302/1000  -  Loss: 5.851803779602051 \t Rec: 5.851803779602051 \t KL: 0.0\n",
            "Epoch: 303/1000  -  Loss: 5.851802825927734 \t Rec: 5.851802825927734 \t KL: 0.0\n",
            "Epoch: 304/1000  -  Loss: 5.851802825927734 \t Rec: 5.851802825927734 \t KL: 0.0\n",
            "Epoch: 305/1000  -  Loss: 5.851812839508057 \t Rec: 5.851812839508057 \t KL: 0.0\n",
            "Epoch: 306/1000  -  Loss: 5.851804733276367 \t Rec: 5.851804733276367 \t KL: 0.0\n",
            "Epoch: 307/1000  -  Loss: 5.851801872253418 \t Rec: 5.851801872253418 \t KL: 0.0\n",
            "Epoch: 308/1000  -  Loss: 5.851802825927734 \t Rec: 5.851802825927734 \t KL: 0.0\n",
            "Epoch: 309/1000  -  Loss: 5.851808547973633 \t Rec: 5.851808547973633 \t KL: 0.0\n",
            "Epoch: 310/1000  -  Loss: 5.851811408996582 \t Rec: 5.851811408996582 \t KL: 0.0\n",
            "Epoch: 311/1000  -  Loss: 5.851807117462158 \t Rec: 5.851807117462158 \t KL: 0.0\n",
            "Epoch: 312/1000  -  Loss: 5.851799488067627 \t Rec: 5.851799488067627 \t KL: 0.0\n",
            "Epoch: 313/1000  -  Loss: 5.851802825927734 \t Rec: 5.851802825927734 \t KL: 0.0\n",
            "Epoch: 314/1000  -  Loss: 5.851813316345215 \t Rec: 5.851813316345215 \t KL: 0.0\n",
            "Epoch: 315/1000  -  Loss: 5.851801872253418 \t Rec: 5.851801872253418 \t KL: 0.0\n",
            "Epoch: 316/1000  -  Loss: 5.85181188583374 \t Rec: 5.85181188583374 \t KL: 0.0\n",
            "Epoch: 317/1000  -  Loss: 5.851807117462158 \t Rec: 5.851807117462158 \t KL: 0.0\n",
            "Epoch: 318/1000  -  Loss: 5.851803302764893 \t Rec: 5.851803302764893 \t KL: 0.0\n",
            "Epoch: 319/1000  -  Loss: 5.851806163787842 \t Rec: 5.851806163787842 \t KL: 0.0\n",
            "Epoch: 320/1000  -  Loss: 5.851786136627197 \t Rec: 5.851786136627197 \t KL: 0.0\n",
            "Epoch: 321/1000  -  Loss: 5.851808547973633 \t Rec: 5.851808547973633 \t KL: 0.0\n",
            "Epoch: 322/1000  -  Loss: 5.851801872253418 \t Rec: 5.851801872253418 \t KL: 0.0\n",
            "Epoch: 323/1000  -  Loss: 5.851802825927734 \t Rec: 5.851802825927734 \t KL: 0.0\n",
            "Epoch: 324/1000  -  Loss: 5.851809978485107 \t Rec: 5.851809978485107 \t KL: 0.0\n",
            "Epoch: 325/1000  -  Loss: 5.851799488067627 \t Rec: 5.851799488067627 \t KL: 0.0\n",
            "Epoch: 326/1000  -  Loss: 5.851808071136475 \t Rec: 5.851808071136475 \t KL: 0.0\n",
            "Epoch: 327/1000  -  Loss: 5.851816654205322 \t Rec: 5.851816654205322 \t KL: 0.0\n",
            "Epoch: 328/1000  -  Loss: 5.851797580718994 \t Rec: 5.851797580718994 \t KL: 0.0\n",
            "Epoch: 329/1000  -  Loss: 5.851807117462158 \t Rec: 5.851807117462158 \t KL: 0.0\n",
            "Epoch: 330/1000  -  Loss: 5.851805210113525 \t Rec: 5.851805210113525 \t KL: 0.0\n",
            "Epoch: 331/1000  -  Loss: 5.85180139541626 \t Rec: 5.85180139541626 \t KL: 1.2957531714263837e-09\n",
            "Epoch: 332/1000  -  Loss: 5.85181188583374 \t Rec: 5.85181188583374 \t KL: 0.0\n",
            "Epoch: 333/1000  -  Loss: 5.851796627044678 \t Rec: 5.851796627044678 \t KL: 0.0\n",
            "Epoch: 334/1000  -  Loss: 5.851804733276367 \t Rec: 5.851804733276367 \t KL: 0.0\n",
            "Epoch: 335/1000  -  Loss: 5.851809501647949 \t Rec: 5.851809501647949 \t KL: 0.0\n",
            "Epoch: 336/1000  -  Loss: 5.851805210113525 \t Rec: 5.851805210113525 \t KL: 0.0\n",
            "Epoch: 337/1000  -  Loss: 5.851806163787842 \t Rec: 5.851806163787842 \t KL: 0.0\n",
            "Epoch: 338/1000  -  Loss: 5.851809978485107 \t Rec: 5.851809978485107 \t KL: 1.2957531714263837e-09\n",
            "Epoch: 339/1000  -  Loss: 5.851800441741943 \t Rec: 5.851800441741943 \t KL: 0.0\n",
            "Epoch: 340/1000  -  Loss: 5.851803302764893 \t Rec: 5.851803302764893 \t KL: 0.0\n",
            "Epoch: 341/1000  -  Loss: 5.851808547973633 \t Rec: 5.851808547973633 \t KL: 0.0\n",
            "Epoch: 342/1000  -  Loss: 5.851800441741943 \t Rec: 5.851800441741943 \t KL: 0.0\n",
            "Epoch: 343/1000  -  Loss: 5.851804733276367 \t Rec: 5.851804733276367 \t KL: 0.0\n",
            "Epoch: 344/1000  -  Loss: 5.851813793182373 \t Rec: 5.851813793182373 \t KL: 0.0\n",
            "Epoch: 345/1000  -  Loss: 5.851799964904785 \t Rec: 5.851799964904785 \t KL: 0.0\n",
            "Epoch: 346/1000  -  Loss: 5.851807117462158 \t Rec: 5.851807117462158 \t KL: 0.0\n",
            "Epoch: 347/1000  -  Loss: 5.851803302764893 \t Rec: 5.851803302764893 \t KL: 2.5915063428527674e-09\n",
            "Epoch: 348/1000  -  Loss: 5.851803779602051 \t Rec: 5.851803779602051 \t KL: 0.0\n",
            "Epoch: 349/1000  -  Loss: 5.851798057556152 \t Rec: 5.851798057556152 \t KL: 0.0\n",
            "Epoch: 350/1000  -  Loss: 5.851805210113525 \t Rec: 5.851805210113525 \t KL: 0.0\n",
            "Epoch: 351/1000  -  Loss: 5.85180139541626 \t Rec: 5.85180139541626 \t KL: 0.0\n",
            "Epoch: 352/1000  -  Loss: 5.851808547973633 \t Rec: 5.851808547973633 \t KL: 0.0\n",
            "Epoch: 353/1000  -  Loss: 5.851805210113525 \t Rec: 5.851805210113525 \t KL: 0.0\n",
            "Epoch: 354/1000  -  Loss: 5.851806163787842 \t Rec: 5.851806163787842 \t KL: 0.0\n",
            "Epoch: 355/1000  -  Loss: 5.851804733276367 \t Rec: 5.851804733276367 \t KL: 0.0\n",
            "Epoch: 356/1000  -  Loss: 5.851810455322266 \t Rec: 5.851810455322266 \t KL: 0.0\n",
            "Epoch: 357/1000  -  Loss: 5.851799964904785 \t Rec: 5.851799964904785 \t KL: 0.0\n",
            "Epoch: 358/1000  -  Loss: 5.851803779602051 \t Rec: 5.851803779602051 \t KL: 0.0\n",
            "Epoch: 359/1000  -  Loss: 5.851808071136475 \t Rec: 5.851808071136475 \t KL: 0.0\n",
            "Epoch: 360/1000  -  Loss: 5.85180139541626 \t Rec: 5.85180139541626 \t KL: 0.0\n",
            "Epoch: 361/1000  -  Loss: 5.851809501647949 \t Rec: 5.851809501647949 \t KL: 0.0\n",
            "Epoch: 362/1000  -  Loss: 5.851803779602051 \t Rec: 5.851803779602051 \t KL: 1.2957531714263837e-09\n",
            "Epoch: 363/1000  -  Loss: 5.851801872253418 \t Rec: 5.851801872253418 \t KL: 2.5915063428527674e-09\n",
            "Epoch: 364/1000  -  Loss: 5.85181188583374 \t Rec: 5.85181188583374 \t KL: 0.0\n",
            "Epoch: 365/1000  -  Loss: 5.851800441741943 \t Rec: 5.851800441741943 \t KL: 0.0\n",
            "Epoch: 366/1000  -  Loss: 5.851805210113525 \t Rec: 5.851805210113525 \t KL: 0.0\n",
            "Epoch: 367/1000  -  Loss: 5.851803779602051 \t Rec: 5.851803779602051 \t KL: 0.0\n",
            "Epoch: 368/1000  -  Loss: 5.851806640625 \t Rec: 5.851806640625 \t KL: 0.0\n",
            "Epoch: 369/1000  -  Loss: 5.851804733276367 \t Rec: 5.851804733276367 \t KL: 0.0\n",
            "Epoch: 370/1000  -  Loss: 5.851800441741943 \t Rec: 5.851800441741943 \t KL: 0.0\n",
            "Epoch: 371/1000  -  Loss: 5.851808547973633 \t Rec: 5.851808547973633 \t KL: 0.0\n",
            "Epoch: 372/1000  -  Loss: 5.851803779602051 \t Rec: 5.851803779602051 \t KL: 0.0\n",
            "Epoch: 373/1000  -  Loss: 5.851804733276367 \t Rec: 5.851804733276367 \t KL: 0.0\n",
            "Epoch: 374/1000  -  Loss: 5.851803779602051 \t Rec: 5.851803779602051 \t KL: 1.2957531714263837e-09\n",
            "Epoch: 375/1000  -  Loss: 5.85180139541626 \t Rec: 5.85180139541626 \t KL: 0.0\n",
            "Epoch: 376/1000  -  Loss: 5.851806163787842 \t Rec: 5.851806163787842 \t KL: 0.0\n",
            "Epoch: 377/1000  -  Loss: 5.851807117462158 \t Rec: 5.851807117462158 \t KL: 0.0\n",
            "Epoch: 378/1000  -  Loss: 5.851815223693848 \t Rec: 5.851815223693848 \t KL: 1.2957531714263837e-09\n",
            "Epoch: 379/1000  -  Loss: 5.851803302764893 \t Rec: 5.851803302764893 \t KL: 0.0\n",
            "Epoch: 380/1000  -  Loss: 5.851806163787842 \t Rec: 5.851806163787842 \t KL: 0.0\n",
            "Epoch: 381/1000  -  Loss: 5.851799488067627 \t Rec: 5.851799488067627 \t KL: 0.0\n",
            "Epoch: 382/1000  -  Loss: 5.851811408996582 \t Rec: 5.851811408996582 \t KL: 0.0\n",
            "Epoch: 383/1000  -  Loss: 5.851806163787842 \t Rec: 5.851806163787842 \t KL: 0.0\n",
            "Epoch: 384/1000  -  Loss: 5.85180139541626 \t Rec: 5.85180139541626 \t KL: 0.0\n",
            "Epoch: 385/1000  -  Loss: 5.851803779602051 \t Rec: 5.851803779602051 \t KL: 0.0\n",
            "Epoch: 386/1000  -  Loss: 5.851806640625 \t Rec: 5.851806640625 \t KL: 1.2957531714263837e-09\n",
            "Epoch: 387/1000  -  Loss: 5.851803779602051 \t Rec: 5.851803779602051 \t KL: 1.2957531714263837e-09\n",
            "Epoch: 388/1000  -  Loss: 5.851811408996582 \t Rec: 5.851811408996582 \t KL: 0.0\n",
            "Epoch: 389/1000  -  Loss: 5.851805210113525 \t Rec: 5.851805210113525 \t KL: 0.0\n",
            "Epoch: 390/1000  -  Loss: 5.851809978485107 \t Rec: 5.851809978485107 \t KL: 0.0\n",
            "Epoch: 391/1000  -  Loss: 5.851796627044678 \t Rec: 5.851796627044678 \t KL: 1.2957531714263837e-09\n",
            "Epoch: 392/1000  -  Loss: 5.851812839508057 \t Rec: 5.851812839508057 \t KL: 0.0\n",
            "Epoch: 393/1000  -  Loss: 5.851803302764893 \t Rec: 5.851803302764893 \t KL: 0.0\n",
            "Epoch: 394/1000  -  Loss: 5.851813316345215 \t Rec: 5.851813316345215 \t KL: 1.2957531714263837e-09\n",
            "Epoch: 395/1000  -  Loss: 5.851798057556152 \t Rec: 5.851798057556152 \t KL: 0.0\n",
            "Epoch: 396/1000  -  Loss: 5.851811408996582 \t Rec: 5.851811408996582 \t KL: 0.0\n",
            "Epoch: 397/1000  -  Loss: 5.851805210113525 \t Rec: 5.851805210113525 \t KL: 3.887259403256849e-09\n",
            "Epoch: 398/1000  -  Loss: 5.851804733276367 \t Rec: 5.851804733276367 \t KL: 0.0\n",
            "Epoch: 399/1000  -  Loss: 5.851799964904785 \t Rec: 5.851799964904785 \t KL: 0.0\n",
            "Epoch: 400/1000  -  Loss: 5.851811408996582 \t Rec: 5.851811408996582 \t KL: 0.0\n",
            "Epoch: 401/1000  -  Loss: 5.851812839508057 \t Rec: 5.851812839508057 \t KL: 2.1595887300662753e-09\n",
            "Epoch: 402/1000  -  Loss: 5.85179328918457 \t Rec: 5.85179328918457 \t KL: 0.0\n",
            "Epoch: 403/1000  -  Loss: 5.851807117462158 \t Rec: 5.851807117462158 \t KL: 0.0\n",
            "Epoch: 404/1000  -  Loss: 5.851806640625 \t Rec: 5.851806640625 \t KL: 0.0\n",
            "Epoch: 405/1000  -  Loss: 5.851803779602051 \t Rec: 5.851803779602051 \t KL: 0.0\n",
            "Epoch: 406/1000  -  Loss: 5.851801872253418 \t Rec: 5.851801872253418 \t KL: 0.0\n",
            "Epoch: 407/1000  -  Loss: 5.851798057556152 \t Rec: 5.851798057556152 \t KL: 0.0\n",
            "Epoch: 408/1000  -  Loss: 5.851809501647949 \t Rec: 5.851809501647949 \t KL: 0.0\n",
            "Epoch: 409/1000  -  Loss: 5.851803302764893 \t Rec: 5.851803302764893 \t KL: 1.2957531714263837e-09\n",
            "Epoch: 410/1000  -  Loss: 5.85181188583374 \t Rec: 5.85181188583374 \t KL: 0.0\n",
            "Epoch: 411/1000  -  Loss: 5.851799488067627 \t Rec: 5.851799488067627 \t KL: 1.2957531714263837e-09\n",
            "Epoch: 412/1000  -  Loss: 5.851802825927734 \t Rec: 5.851802825927734 \t KL: 2.5915063428527674e-09\n",
            "Epoch: 413/1000  -  Loss: 5.851806640625 \t Rec: 5.851806640625 \t KL: 0.0\n",
            "Epoch: 414/1000  -  Loss: 5.85181188583374 \t Rec: 5.85181188583374 \t KL: 1.2957531714263837e-09\n",
            "Epoch: 415/1000  -  Loss: 5.851806640625 \t Rec: 5.851806640625 \t KL: 0.0\n",
            "Epoch: 416/1000  -  Loss: 5.851808547973633 \t Rec: 5.851808547973633 \t KL: 0.0\n",
            "Epoch: 417/1000  -  Loss: 5.851799964904785 \t Rec: 5.851799964904785 \t KL: 0.0\n",
            "Epoch: 418/1000  -  Loss: 5.85180139541626 \t Rec: 5.85180139541626 \t KL: 0.0\n",
            "Epoch: 419/1000  -  Loss: 5.851808547973633 \t Rec: 5.851808547973633 \t KL: 0.0\n",
            "Epoch: 420/1000  -  Loss: 5.8517985343933105 \t Rec: 5.8517985343933105 \t KL: 1.2957531714263837e-09\n",
            "Epoch: 421/1000  -  Loss: 5.851808071136475 \t Rec: 5.851808071136475 \t KL: 0.0\n",
            "Epoch: 422/1000  -  Loss: 5.85180139541626 \t Rec: 5.85180139541626 \t KL: 0.0\n",
            "Epoch: 423/1000  -  Loss: 5.851807117462158 \t Rec: 5.851807117462158 \t KL: 0.0\n",
            "Epoch: 424/1000  -  Loss: 5.851811408996582 \t Rec: 5.851811408996582 \t KL: 0.0\n",
            "Epoch: 425/1000  -  Loss: 5.851803302764893 \t Rec: 5.851803302764893 \t KL: 1.2957531714263837e-09\n",
            "Epoch: 426/1000  -  Loss: 5.851802825927734 \t Rec: 5.851802825927734 \t KL: 3.887259403256849e-09\n",
            "Epoch: 427/1000  -  Loss: 5.851800441741943 \t Rec: 5.851800441741943 \t KL: 3.2393827620325055e-09\n",
            "Epoch: 428/1000  -  Loss: 5.851807117462158 \t Rec: 5.851807117462158 \t KL: 0.0\n",
            "Epoch: 429/1000  -  Loss: 5.851799964904785 \t Rec: 5.851799964904785 \t KL: 0.0\n",
            "Epoch: 430/1000  -  Loss: 5.851815223693848 \t Rec: 5.851815223693848 \t KL: 0.0\n",
            "Epoch: 431/1000  -  Loss: 5.851798057556152 \t Rec: 5.851798057556152 \t KL: 1.5117119778196297e-09\n",
            "Epoch: 432/1000  -  Loss: 5.851801872253418 \t Rec: 5.851801872253418 \t KL: 0.0\n",
            "Epoch: 433/1000  -  Loss: 5.851799964904785 \t Rec: 5.851799964904785 \t KL: 0.0\n",
            "Epoch: 434/1000  -  Loss: 5.851803302764893 \t Rec: 5.851803302764893 \t KL: 0.0\n",
            "Epoch: 435/1000  -  Loss: 5.851806640625 \t Rec: 5.851806640625 \t KL: 0.0\n",
            "Epoch: 436/1000  -  Loss: 5.851806163787842 \t Rec: 5.851806163787842 \t KL: 0.0\n",
            "Epoch: 437/1000  -  Loss: 5.851795196533203 \t Rec: 5.851795196533203 \t KL: 0.0\n",
            "Epoch: 438/1000  -  Loss: 5.851806163787842 \t Rec: 5.851806163787842 \t KL: 1.2957531714263837e-09\n",
            "Epoch: 439/1000  -  Loss: 5.851808547973633 \t Rec: 5.851808547973633 \t KL: 3.887259403256849e-09\n",
            "Epoch: 440/1000  -  Loss: 5.851808547973633 \t Rec: 5.851808547973633 \t KL: 1.2957531714263837e-09\n",
            "Epoch: 441/1000  -  Loss: 5.851798057556152 \t Rec: 5.851798057556152 \t KL: 0.0\n",
            "Epoch: 442/1000  -  Loss: 5.851800441741943 \t Rec: 5.851800441741943 \t KL: 0.0\n",
            "Epoch: 443/1000  -  Loss: 5.851808071136475 \t Rec: 5.851808071136475 \t KL: 0.0\n",
            "Epoch: 444/1000  -  Loss: 5.851806640625 \t Rec: 5.851806640625 \t KL: 8.638354476175891e-10\n",
            "Epoch: 445/1000  -  Loss: 5.851803779602051 \t Rec: 5.851803779602051 \t KL: 3.887259403256849e-09\n",
            "Epoch: 446/1000  -  Loss: 5.851801872253418 \t Rec: 5.851801872253418 \t KL: 0.0\n",
            "Epoch: 447/1000  -  Loss: 5.851802825927734 \t Rec: 5.851802825927734 \t KL: 0.0\n",
            "Epoch: 448/1000  -  Loss: 5.851812839508057 \t Rec: 5.851812839508057 \t KL: 1.2957531714263837e-09\n",
            "Epoch: 449/1000  -  Loss: 5.851803302764893 \t Rec: 5.851803302764893 \t KL: 0.0\n",
            "Epoch: 450/1000  -  Loss: 5.851803779602051 \t Rec: 5.851803779602051 \t KL: 3.0234241776838644e-09\n",
            "Epoch: 451/1000  -  Loss: 5.85180139541626 \t Rec: 5.85180139541626 \t KL: 0.0\n",
            "Epoch: 452/1000  -  Loss: 5.851802825927734 \t Rec: 5.851802825927734 \t KL: 0.0\n",
            "Epoch: 453/1000  -  Loss: 5.851812839508057 \t Rec: 5.851812839508057 \t KL: 0.0\n",
            "Epoch: 454/1000  -  Loss: 5.851796627044678 \t Rec: 5.851796627044678 \t KL: 0.0\n",
            "Epoch: 455/1000  -  Loss: 5.851806163787842 \t Rec: 5.851806163787842 \t KL: 0.0\n",
            "Epoch: 456/1000  -  Loss: 5.851815700531006 \t Rec: 5.851815700531006 \t KL: 0.0\n",
            "Epoch: 457/1000  -  Loss: 5.851802825927734 \t Rec: 5.851802825927734 \t KL: 6.478765857131918e-10\n",
            "Epoch: 458/1000  -  Loss: 5.851808071136475 \t Rec: 5.851808071136475 \t KL: 1.2957531714263837e-09\n",
            "Epoch: 459/1000  -  Loss: 5.851803302764893 \t Rec: 5.851803302764893 \t KL: 0.0\n",
            "Epoch: 460/1000  -  Loss: 5.851804733276367 \t Rec: 5.851804733276367 \t KL: 0.0\n",
            "Epoch: 461/1000  -  Loss: 5.851806640625 \t Rec: 5.851806640625 \t KL: 6.478765857131918e-10\n",
            "Epoch: 462/1000  -  Loss: 5.851806163787842 \t Rec: 5.851806163787842 \t KL: 0.0\n",
            "Epoch: 463/1000  -  Loss: 5.851808071136475 \t Rec: 5.851808071136475 \t KL: 2.5915063428527674e-09\n",
            "Epoch: 464/1000  -  Loss: 5.851803302764893 \t Rec: 5.851803302764893 \t KL: 0.0\n",
            "Epoch: 465/1000  -  Loss: 5.851803302764893 \t Rec: 5.851803302764893 \t KL: 0.0\n",
            "Epoch: 466/1000  -  Loss: 5.851804733276367 \t Rec: 5.851804733276367 \t KL: 1.2957531714263837e-09\n",
            "Epoch: 467/1000  -  Loss: 5.851803779602051 \t Rec: 5.851803779602051 \t KL: 1.2957531714263837e-09\n",
            "Epoch: 468/1000  -  Loss: 5.851809501647949 \t Rec: 5.851809501647949 \t KL: 0.0\n",
            "Epoch: 469/1000  -  Loss: 5.851813793182373 \t Rec: 5.851813793182373 \t KL: 2.1595887300662753e-09\n",
            "Epoch: 470/1000  -  Loss: 5.851800441741943 \t Rec: 5.851800441741943 \t KL: 1.0797942540108352e-09\n",
            "Epoch: 471/1000  -  Loss: 5.851805210113525 \t Rec: 5.851805210113525 \t KL: 3.0234239556392595e-09\n",
            "Epoch: 472/1000  -  Loss: 5.851802825927734 \t Rec: 5.851802825927734 \t KL: 2.1595887300662753e-09\n",
            "Epoch: 473/1000  -  Loss: 5.851808071136475 \t Rec: 5.851808071136475 \t KL: 0.0\n",
            "Epoch: 474/1000  -  Loss: 5.851795196533203 \t Rec: 5.851795196533203 \t KL: 1.0797943650331376e-09\n",
            "Epoch: 475/1000  -  Loss: 5.851809978485107 \t Rec: 5.851809978485107 \t KL: 0.0\n",
            "Epoch: 476/1000  -  Loss: 5.851806640625 \t Rec: 5.851806640625 \t KL: 0.0\n",
            "Epoch: 477/1000  -  Loss: 5.85181188583374 \t Rec: 5.85181188583374 \t KL: 0.0\n",
            "Epoch: 478/1000  -  Loss: 5.851803302764893 \t Rec: 5.851803302764893 \t KL: 1.2957531714263837e-09\n",
            "Epoch: 479/1000  -  Loss: 5.8517985343933105 \t Rec: 5.8517985343933105 \t KL: 2.1595886190439728e-10\n",
            "Epoch: 480/1000  -  Loss: 5.851808547973633 \t Rec: 5.851808547973633 \t KL: 0.0\n",
            "Epoch: 481/1000  -  Loss: 5.851812839508057 \t Rec: 5.851812839508057 \t KL: 2.1595886190439728e-10\n",
            "Epoch: 482/1000  -  Loss: 5.851806163787842 \t Rec: 5.851806163787842 \t KL: 1.2957531714263837e-09\n",
            "Epoch: 483/1000  -  Loss: 5.851807117462158 \t Rec: 5.851807117462158 \t KL: 2.1595887300662753e-09\n",
            "Epoch: 484/1000  -  Loss: 5.851806163787842 \t Rec: 5.851806163787842 \t KL: 0.0\n",
            "Epoch: 485/1000  -  Loss: 5.851802825927734 \t Rec: 5.851802825927734 \t KL: 8.638354476175891e-10\n",
            "Epoch: 486/1000  -  Loss: 5.851816654205322 \t Rec: 5.851816654205322 \t KL: 0.0\n",
            "Epoch: 487/1000  -  Loss: 5.851794242858887 \t Rec: 5.851794242858887 \t KL: 0.0\n",
            "Epoch: 488/1000  -  Loss: 5.851805210113525 \t Rec: 5.851805210113525 \t KL: 0.0\n",
            "Epoch: 489/1000  -  Loss: 5.851809978485107 \t Rec: 5.851809978485107 \t KL: 0.0\n",
            "Epoch: 490/1000  -  Loss: 5.8517985343933105 \t Rec: 5.8517985343933105 \t KL: 0.0\n",
            "Epoch: 491/1000  -  Loss: 5.851807117462158 \t Rec: 5.851807117462158 \t KL: 1.5117119778196297e-09\n",
            "Epoch: 492/1000  -  Loss: 5.85181188583374 \t Rec: 5.85181188583374 \t KL: 2.8074651492460134e-09\n",
            "Epoch: 493/1000  -  Loss: 5.851801872253418 \t Rec: 5.851801872253418 \t KL: 1.7276708952351783e-09\n",
            "Epoch: 494/1000  -  Loss: 5.85180139541626 \t Rec: 5.85180139541626 \t KL: 1.2957531714263837e-09\n",
            "Epoch: 495/1000  -  Loss: 5.851810455322266 \t Rec: 5.851810455322266 \t KL: 0.0\n",
            "Epoch: 496/1000  -  Loss: 5.851804733276367 \t Rec: 5.851804733276367 \t KL: 0.0\n",
            "Epoch: 497/1000  -  Loss: 5.851800441741943 \t Rec: 5.851800441741943 \t KL: 8.638354476175891e-10\n",
            "Epoch: 498/1000  -  Loss: 5.851806163787842 \t Rec: 5.851806163787842 \t KL: 4.3191772380879456e-10\n",
            "Epoch: 499/1000  -  Loss: 5.851809501647949 \t Rec: 5.851809501647949 \t KL: 3.0234241776838644e-09\n",
            "Epoch: 500/1000  -  Loss: 5.851801872253418 \t Rec: 5.851801872253418 \t KL: 0.0\n",
            "Epoch: 501/1000  -  Loss: 5.851803302764893 \t Rec: 5.851803302764893 \t KL: 1.0797942540108352e-09\n",
            "Epoch: 502/1000  -  Loss: 5.851808547973633 \t Rec: 5.851808547973633 \t KL: 2.1595886190439728e-10\n",
            "Epoch: 503/1000  -  Loss: 5.851805210113525 \t Rec: 5.851805210113525 \t KL: 0.0\n",
            "Epoch: 504/1000  -  Loss: 5.851809501647949 \t Rec: 5.851809501647949 \t KL: 6.478765857131918e-10\n",
            "Epoch: 505/1000  -  Loss: 5.851803302764893 \t Rec: 5.851803302764893 \t KL: 8.638354476175891e-10\n",
            "Epoch: 506/1000  -  Loss: 5.851806163787842 \t Rec: 5.851806163787842 \t KL: 2.1595886190439728e-10\n",
            "Epoch: 507/1000  -  Loss: 5.851800441741943 \t Rec: 5.851800441741943 \t KL: 8.638354476175891e-10\n",
            "Epoch: 508/1000  -  Loss: 5.851806640625 \t Rec: 5.851806640625 \t KL: 1.0797942540108352e-09\n",
            "Epoch: 509/1000  -  Loss: 5.851809501647949 \t Rec: 5.851809501647949 \t KL: 0.0\n",
            "Epoch: 510/1000  -  Loss: 5.8518147468566895 \t Rec: 5.8518147468566895 \t KL: 2.1595886190439728e-10\n",
            "Epoch: 511/1000  -  Loss: 5.8517961502075195 \t Rec: 5.8517961502075195 \t KL: 1.2957531714263837e-09\n",
            "Epoch: 512/1000  -  Loss: 5.851808071136475 \t Rec: 5.851808071136475 \t KL: 0.0\n",
            "Epoch: 513/1000  -  Loss: 5.851803302764893 \t Rec: 5.851803302764893 \t KL: 4.3191772380879456e-10\n",
            "Epoch: 514/1000  -  Loss: 5.851803302764893 \t Rec: 5.851803302764893 \t KL: 0.0\n",
            "Epoch: 515/1000  -  Loss: 5.851803779602051 \t Rec: 5.851803779602051 \t KL: 2.1595886190439728e-10\n",
            "Epoch: 516/1000  -  Loss: 5.85180139541626 \t Rec: 5.85180139541626 \t KL: 1.2957531714263837e-09\n",
            "Epoch: 517/1000  -  Loss: 5.851803779602051 \t Rec: 5.851803779602051 \t KL: 2.1595887300662753e-09\n",
            "Epoch: 518/1000  -  Loss: 5.85181188583374 \t Rec: 5.85181188583374 \t KL: 4.3191772380879456e-10\n",
            "Epoch: 519/1000  -  Loss: 5.851800441741943 \t Rec: 5.851800441741943 \t KL: 1.2957531714263837e-09\n",
            "Epoch: 520/1000  -  Loss: 5.851806640625 \t Rec: 5.851806640625 \t KL: 0.0\n",
            "Epoch: 521/1000  -  Loss: 5.851806163787842 \t Rec: 5.851806163787842 \t KL: 0.0\n",
            "Epoch: 522/1000  -  Loss: 5.8517985343933105 \t Rec: 5.8517985343933105 \t KL: 6.478765857131918e-10\n",
            "Epoch: 523/1000  -  Loss: 5.851805210113525 \t Rec: 5.851805210113525 \t KL: 4.319177016043341e-09\n",
            "Epoch: 524/1000  -  Loss: 5.851810455322266 \t Rec: 5.851810455322266 \t KL: 4.3191772380879456e-10\n",
            "Epoch: 525/1000  -  Loss: 5.851799488067627 \t Rec: 5.851799488067627 \t KL: 0.0\n",
            "Epoch: 526/1000  -  Loss: 5.85181188583374 \t Rec: 5.85181188583374 \t KL: 1.7276708952351783e-09\n",
            "Epoch: 527/1000  -  Loss: 5.85180139541626 \t Rec: 5.85180139541626 \t KL: 0.0\n",
            "Epoch: 528/1000  -  Loss: 5.851803302764893 \t Rec: 5.851803302764893 \t KL: 1.5117120888419322e-09\n",
            "Epoch: 529/1000  -  Loss: 5.851803302764893 \t Rec: 5.851803302764893 \t KL: 8.638354476175891e-10\n",
            "Epoch: 530/1000  -  Loss: 5.85181188583374 \t Rec: 5.85181188583374 \t KL: 4.3191772380879456e-10\n",
            "Epoch: 531/1000  -  Loss: 5.851798057556152 \t Rec: 5.851798057556152 \t KL: 3.2393827620325055e-09\n",
            "Epoch: 532/1000  -  Loss: 5.85180139541626 \t Rec: 5.85180139541626 \t KL: 2.8074649272014085e-09\n",
            "Epoch: 533/1000  -  Loss: 5.851807117462158 \t Rec: 5.851807117462158 \t KL: 0.0\n",
            "Epoch: 534/1000  -  Loss: 5.85180139541626 \t Rec: 5.85180139541626 \t KL: 1.5117120888419322e-09\n",
            "Epoch: 535/1000  -  Loss: 5.851803302764893 \t Rec: 5.851803302764893 \t KL: 4.3191772380879456e-10\n",
            "Epoch: 536/1000  -  Loss: 5.851813793182373 \t Rec: 5.851813793182373 \t KL: 2.1595886190439728e-10\n",
            "Epoch: 537/1000  -  Loss: 5.851806163787842 \t Rec: 5.851806163787842 \t KL: 1.0797943650331376e-09\n",
            "Epoch: 538/1000  -  Loss: 5.851803302764893 \t Rec: 5.851803302764893 \t KL: 3.4553417904703565e-09\n",
            "Epoch: 539/1000  -  Loss: 5.851801872253418 \t Rec: 5.851801872253418 \t KL: 2.5915063428527674e-09\n",
            "Epoch: 540/1000  -  Loss: 5.851813316345215 \t Rec: 5.851813316345215 \t KL: 1.9436297016284243e-09\n",
            "Epoch: 541/1000  -  Loss: 5.851806640625 \t Rec: 5.851806640625 \t KL: 6.478765857131918e-10\n",
            "Epoch: 542/1000  -  Loss: 5.851804733276367 \t Rec: 5.851804733276367 \t KL: 8.638354476175891e-10\n",
            "Epoch: 543/1000  -  Loss: 5.851808547973633 \t Rec: 5.851808547973633 \t KL: 0.0\n",
            "Epoch: 544/1000  -  Loss: 5.851801872253418 \t Rec: 5.851801872253418 \t KL: 2.1595886190439728e-10\n",
            "Epoch: 545/1000  -  Loss: 5.851810455322266 \t Rec: 5.851810455322266 \t KL: 0.0\n",
            "Epoch: 546/1000  -  Loss: 5.851803302764893 \t Rec: 5.851803302764893 \t KL: 2.1595887300662753e-09\n",
            "Epoch: 547/1000  -  Loss: 5.851804733276367 \t Rec: 5.851804733276367 \t KL: 0.0\n",
            "Epoch: 548/1000  -  Loss: 5.851821422576904 \t Rec: 5.851821422576904 \t KL: 1.2957531714263837e-09\n",
            "Epoch: 549/1000  -  Loss: 5.851795196533203 \t Rec: 5.851795196533203 \t KL: 1.9436299236730292e-09\n",
            "Epoch: 550/1000  -  Loss: 5.851806640625 \t Rec: 5.851806640625 \t KL: 6.478765857131918e-10\n",
            "Epoch: 551/1000  -  Loss: 5.851799488067627 \t Rec: 5.851799488067627 \t KL: 0.0\n",
            "Epoch: 552/1000  -  Loss: 5.851802825927734 \t Rec: 5.851802825927734 \t KL: 4.3191772380879456e-10\n",
            "Epoch: 553/1000  -  Loss: 5.851803779602051 \t Rec: 5.851803779602051 \t KL: 0.0\n",
            "Epoch: 554/1000  -  Loss: 5.851807117462158 \t Rec: 5.851807117462158 \t KL: 0.0\n",
            "Epoch: 555/1000  -  Loss: 5.851800441741943 \t Rec: 5.851800441741943 \t KL: 4.3191772380879456e-10\n",
            "Epoch: 556/1000  -  Loss: 5.851806163787842 \t Rec: 5.851806163787842 \t KL: 0.0\n",
            "Epoch: 557/1000  -  Loss: 5.851808547973633 \t Rec: 5.851808547973633 \t KL: 2.1595887300662753e-09\n",
            "Epoch: 558/1000  -  Loss: 5.851807117462158 \t Rec: 5.851807117462158 \t KL: 1.2957531714263837e-09\n",
            "Epoch: 559/1000  -  Loss: 5.851803779602051 \t Rec: 5.851803779602051 \t KL: 4.3191772380879456e-10\n",
            "Epoch: 560/1000  -  Loss: 5.851801872253418 \t Rec: 5.851801872253418 \t KL: 8.638354476175891e-10\n",
            "Epoch: 561/1000  -  Loss: 5.851803779602051 \t Rec: 5.851803779602051 \t KL: 0.0\n",
            "Epoch: 562/1000  -  Loss: 5.851803302764893 \t Rec: 5.851803302764893 \t KL: 0.0\n",
            "Epoch: 563/1000  -  Loss: 5.851809501647949 \t Rec: 5.851809501647949 \t KL: 6.478765857131918e-10\n",
            "Epoch: 564/1000  -  Loss: 5.85180139541626 \t Rec: 5.85180139541626 \t KL: 1.5117119778196297e-09\n",
            "Epoch: 565/1000  -  Loss: 5.851804733276367 \t Rec: 5.851804733276367 \t KL: 4.3191772380879456e-10\n",
            "Epoch: 566/1000  -  Loss: 5.851811408996582 \t Rec: 5.851811408996582 \t KL: 0.0\n",
            "Epoch: 567/1000  -  Loss: 5.851800441741943 \t Rec: 5.851800441741943 \t KL: 6.478765857131918e-10\n",
            "Epoch: 568/1000  -  Loss: 5.851802825927734 \t Rec: 5.851802825927734 \t KL: 4.3191772380879456e-10\n",
            "Epoch: 569/1000  -  Loss: 5.851804733276367 \t Rec: 5.851804733276367 \t KL: 1.7276707842128758e-09\n",
            "Epoch: 570/1000  -  Loss: 5.851808071136475 \t Rec: 5.851808071136475 \t KL: 4.3191772380879456e-10\n",
            "Epoch: 571/1000  -  Loss: 5.851810455322266 \t Rec: 5.851810455322266 \t KL: 1.2957531714263837e-09\n",
            "Epoch: 572/1000  -  Loss: 5.851799964904785 \t Rec: 5.851799964904785 \t KL: 2.1595886190439728e-10\n",
            "Epoch: 573/1000  -  Loss: 5.851803779602051 \t Rec: 5.851803779602051 \t KL: 2.1595886190439728e-10\n",
            "Epoch: 574/1000  -  Loss: 5.85181188583374 \t Rec: 5.85181188583374 \t KL: 6.478765857131918e-10\n",
            "Epoch: 575/1000  -  Loss: 5.851803302764893 \t Rec: 5.851803302764893 \t KL: 1.5117119778196297e-09\n",
            "Epoch: 576/1000  -  Loss: 5.851803302764893 \t Rec: 5.851803302764893 \t KL: 2.1595885080216703e-09\n",
            "Epoch: 577/1000  -  Loss: 5.851805210113525 \t Rec: 5.851805210113525 \t KL: 1.2957531714263837e-09\n",
            "Epoch: 578/1000  -  Loss: 5.851807117462158 \t Rec: 5.851807117462158 \t KL: 1.5117120888419322e-09\n",
            "Epoch: 579/1000  -  Loss: 5.851809501647949 \t Rec: 5.851809501647949 \t KL: 2.3755473144149164e-09\n",
            "Epoch: 580/1000  -  Loss: 5.85180139541626 \t Rec: 5.85180139541626 \t KL: 4.3191772380879456e-10\n",
            "Epoch: 581/1000  -  Loss: 5.851808071136475 \t Rec: 5.851808071136475 \t KL: 0.0\n",
            "Epoch: 582/1000  -  Loss: 5.851803779602051 \t Rec: 5.851803779602051 \t KL: 1.2957531714263837e-09\n",
            "Epoch: 583/1000  -  Loss: 5.851809978485107 \t Rec: 5.851809978485107 \t KL: 4.3191772380879456e-10\n",
            "Epoch: 584/1000  -  Loss: 5.851799488067627 \t Rec: 5.851799488067627 \t KL: 6.478765857131918e-10\n",
            "Epoch: 585/1000  -  Loss: 5.851811408996582 \t Rec: 5.851811408996582 \t KL: 8.638354476175891e-10\n",
            "Epoch: 586/1000  -  Loss: 5.851806163787842 \t Rec: 5.851806163787842 \t KL: 1.9436299236730292e-09\n",
            "Epoch: 587/1000  -  Loss: 5.851809501647949 \t Rec: 5.851809501647949 \t KL: 1.9436294795838194e-09\n",
            "Epoch: 588/1000  -  Loss: 5.851802825927734 \t Rec: 5.851802825927734 \t KL: 1.5117120888419322e-09\n",
            "Epoch: 589/1000  -  Loss: 5.8517961502075195 \t Rec: 5.8517961502075195 \t KL: 1.0797943650331376e-09\n",
            "Epoch: 590/1000  -  Loss: 5.85180139541626 \t Rec: 5.85180139541626 \t KL: 6.478765857131918e-10\n",
            "Epoch: 591/1000  -  Loss: 5.85181188583374 \t Rec: 5.85181188583374 \t KL: 4.3191772380879456e-10\n",
            "Epoch: 592/1000  -  Loss: 5.851802825927734 \t Rec: 5.851802825927734 \t KL: 2.1595886190439728e-10\n",
            "Epoch: 593/1000  -  Loss: 5.851809501647949 \t Rec: 5.851809501647949 \t KL: 1.2957531714263837e-09\n",
            "Epoch: 594/1000  -  Loss: 5.851801872253418 \t Rec: 5.851801872253418 \t KL: 8.638354476175891e-10\n",
            "Epoch: 595/1000  -  Loss: 5.85180139541626 \t Rec: 5.85180139541626 \t KL: 2.1595885080216703e-09\n",
            "Epoch: 596/1000  -  Loss: 5.851813316345215 \t Rec: 5.851813316345215 \t KL: 6.478765857131918e-10\n",
            "Epoch: 597/1000  -  Loss: 5.851803779602051 \t Rec: 5.851803779602051 \t KL: 8.638354476175891e-10\n",
            "Epoch: 598/1000  -  Loss: 5.851805210113525 \t Rec: 5.851805210113525 \t KL: 1.5117119778196297e-09\n",
            "Epoch: 599/1000  -  Loss: 5.851800441741943 \t Rec: 5.851800441741943 \t KL: 0.0\n",
            "Epoch: 600/1000  -  Loss: 5.851807117462158 \t Rec: 5.851807117462158 \t KL: 0.0\n",
            "Epoch: 601/1000  -  Loss: 5.851805210113525 \t Rec: 5.851805210113525 \t KL: 1.7276708952351783e-09\n",
            "Epoch: 602/1000  -  Loss: 5.851811408996582 \t Rec: 5.851811408996582 \t KL: 3.6713003748189976e-09\n",
            "Epoch: 603/1000  -  Loss: 5.851801872253418 \t Rec: 5.851801872253418 \t KL: 2.8074651492460134e-09\n",
            "Epoch: 604/1000  -  Loss: 5.851797580718994 \t Rec: 5.851797580718994 \t KL: 2.8074649272014085e-09\n",
            "Epoch: 605/1000  -  Loss: 5.851811408996582 \t Rec: 5.851811408996582 \t KL: 8.638354476175891e-10\n",
            "Epoch: 606/1000  -  Loss: 5.851799964904785 \t Rec: 5.851799964904785 \t KL: 8.638354476175891e-10\n",
            "Epoch: 607/1000  -  Loss: 5.851806640625 \t Rec: 5.851806640625 \t KL: 8.638354476175891e-10\n",
            "Epoch: 608/1000  -  Loss: 5.851802825927734 \t Rec: 5.851802825927734 \t KL: 1.0797943650331376e-09\n",
            "Epoch: 609/1000  -  Loss: 5.851807117462158 \t Rec: 5.851807117462158 \t KL: 1.9436297016284243e-09\n",
            "Epoch: 610/1000  -  Loss: 5.85181188583374 \t Rec: 5.85181188583374 \t KL: 1.5117119778196297e-09\n",
            "Epoch: 611/1000  -  Loss: 5.851794242858887 \t Rec: 5.851794242858887 \t KL: 1.0797943650331376e-09\n",
            "Epoch: 612/1000  -  Loss: 5.851806163787842 \t Rec: 5.851806163787842 \t KL: 4.3191772380879456e-10\n",
            "Epoch: 613/1000  -  Loss: 5.85181188583374 \t Rec: 5.85181188583374 \t KL: 8.638354476175891e-10\n",
            "Epoch: 614/1000  -  Loss: 5.851801872253418 \t Rec: 5.851801872253418 \t KL: 6.478765857131918e-10\n",
            "Epoch: 615/1000  -  Loss: 5.851794242858887 \t Rec: 5.851794242858887 \t KL: 6.478765857131918e-10\n",
            "Epoch: 616/1000  -  Loss: 5.851813316345215 \t Rec: 5.851813316345215 \t KL: 2.1595885080216703e-09\n",
            "Epoch: 617/1000  -  Loss: 5.851803302764893 \t Rec: 5.851803302764893 \t KL: 2.3755473144149164e-09\n",
            "Epoch: 618/1000  -  Loss: 5.8518147468566895 \t Rec: 5.8518147468566895 \t KL: 8.638354476175891e-10\n",
            "Epoch: 619/1000  -  Loss: 5.851802825927734 \t Rec: 5.851802825927734 \t KL: 4.3191772380879456e-10\n",
            "Epoch: 620/1000  -  Loss: 5.851802825927734 \t Rec: 5.851802825927734 \t KL: 1.0797943650331376e-09\n",
            "Epoch: 621/1000  -  Loss: 5.851803302764893 \t Rec: 5.851803302764893 \t KL: 2.1595886190439728e-10\n",
            "Epoch: 622/1000  -  Loss: 5.851803302764893 \t Rec: 5.851803302764893 \t KL: 1.2957531714263837e-09\n",
            "Epoch: 623/1000  -  Loss: 5.851804733276367 \t Rec: 5.851804733276367 \t KL: 1.2957531714263837e-09\n",
            "Epoch: 624/1000  -  Loss: 5.851805210113525 \t Rec: 5.851805210113525 \t KL: 1.2957531714263837e-09\n",
            "Epoch: 625/1000  -  Loss: 5.851804733276367 \t Rec: 5.851804733276367 \t KL: 1.2957531714263837e-09\n",
            "Epoch: 626/1000  -  Loss: 5.851803302764893 \t Rec: 5.851803302764893 \t KL: 8.638354476175891e-10\n",
            "Epoch: 627/1000  -  Loss: 5.851808547973633 \t Rec: 5.851808547973633 \t KL: 1.7276708952351783e-09\n",
            "Epoch: 628/1000  -  Loss: 5.851800441741943 \t Rec: 5.851800441741943 \t KL: 0.0\n",
            "Epoch: 629/1000  -  Loss: 5.851806640625 \t Rec: 5.851806640625 \t KL: 8.638354476175891e-10\n",
            "Epoch: 630/1000  -  Loss: 5.85180139541626 \t Rec: 5.85180139541626 \t KL: 6.478765857131918e-10\n",
            "Epoch: 631/1000  -  Loss: 5.851804733276367 \t Rec: 5.851804733276367 \t KL: 3.0234241776838644e-09\n",
            "Epoch: 632/1000  -  Loss: 5.851806640625 \t Rec: 5.851806640625 \t KL: 1.7276708952351783e-09\n",
            "Epoch: 633/1000  -  Loss: 5.851799488067627 \t Rec: 5.851799488067627 \t KL: 8.638354476175891e-10\n",
            "Epoch: 634/1000  -  Loss: 5.851813793182373 \t Rec: 5.851813793182373 \t KL: 4.3191772380879456e-10\n",
            "Epoch: 635/1000  -  Loss: 5.851799964904785 \t Rec: 5.851799964904785 \t KL: 1.2957531714263837e-09\n",
            "Epoch: 636/1000  -  Loss: 5.851806163787842 \t Rec: 5.851806163787842 \t KL: 1.9436297016284243e-09\n",
            "Epoch: 637/1000  -  Loss: 5.851807117462158 \t Rec: 5.851807117462158 \t KL: 2.1595887300662753e-09\n",
            "Epoch: 638/1000  -  Loss: 5.851813793182373 \t Rec: 5.851813793182373 \t KL: 1.5117120888419322e-09\n",
            "Epoch: 639/1000  -  Loss: 5.851802825927734 \t Rec: 5.851802825927734 \t KL: 4.3191772380879456e-10\n",
            "Epoch: 640/1000  -  Loss: 5.851802825927734 \t Rec: 5.851802825927734 \t KL: 4.3191772380879456e-10\n",
            "Epoch: 641/1000  -  Loss: 5.85180139541626 \t Rec: 5.85180139541626 \t KL: 2.1595886190439728e-10\n",
            "Epoch: 642/1000  -  Loss: 5.851803302764893 \t Rec: 5.851803302764893 \t KL: 2.1595886190439728e-10\n",
            "Epoch: 643/1000  -  Loss: 5.851805210113525 \t Rec: 5.851805210113525 \t KL: 4.3191772380879456e-10\n",
            "Epoch: 644/1000  -  Loss: 5.8517985343933105 \t Rec: 5.8517985343933105 \t KL: 6.478765857131918e-10\n",
            "Epoch: 645/1000  -  Loss: 5.851809501647949 \t Rec: 5.851809501647949 \t KL: 1.0797943650331376e-09\n",
            "Epoch: 646/1000  -  Loss: 5.851806163787842 \t Rec: 5.851806163787842 \t KL: 6.478765857131918e-10\n",
            "Epoch: 647/1000  -  Loss: 5.851806163787842 \t Rec: 5.851806163787842 \t KL: 8.638354476175891e-10\n",
            "Epoch: 648/1000  -  Loss: 5.851807117462158 \t Rec: 5.851807117462158 \t KL: 2.1595886190439728e-10\n",
            "Epoch: 649/1000  -  Loss: 5.851806163787842 \t Rec: 5.851806163787842 \t KL: 2.8074651492460134e-09\n",
            "Epoch: 650/1000  -  Loss: 5.851801872253418 \t Rec: 5.851801872253418 \t KL: 8.638354476175891e-10\n",
            "Epoch: 651/1000  -  Loss: 5.851799488067627 \t Rec: 5.851799488067627 \t KL: 6.478765857131918e-10\n",
            "Epoch: 652/1000  -  Loss: 5.851806640625 \t Rec: 5.851806640625 \t KL: 0.0\n",
            "Epoch: 653/1000  -  Loss: 5.851808071136475 \t Rec: 5.851808071136475 \t KL: 4.3191772380879456e-10\n",
            "Epoch: 654/1000  -  Loss: 5.85181188583374 \t Rec: 5.85181188583374 \t KL: 4.3191772380879456e-10\n",
            "Epoch: 655/1000  -  Loss: 5.851806640625 \t Rec: 5.851806640625 \t KL: 3.0234239556392595e-09\n",
            "Epoch: 656/1000  -  Loss: 5.851798057556152 \t Rec: 5.851798057556152 \t KL: 6.478765857131918e-10\n",
            "Epoch: 657/1000  -  Loss: 5.851813793182373 \t Rec: 5.851813793182373 \t KL: 4.3191772380879456e-10\n",
            "Epoch: 658/1000  -  Loss: 5.851802825927734 \t Rec: 5.851802825927734 \t KL: 3.4553417904703565e-09\n",
            "Epoch: 659/1000  -  Loss: 5.851806163787842 \t Rec: 5.851806163787842 \t KL: 4.3191772380879456e-10\n",
            "Epoch: 660/1000  -  Loss: 5.851805210113525 \t Rec: 5.851805210113525 \t KL: 3.0234241776838644e-09\n",
            "Epoch: 661/1000  -  Loss: 5.851809501647949 \t Rec: 5.851809501647949 \t KL: 1.0797943650331376e-09\n",
            "Epoch: 662/1000  -  Loss: 5.851800441741943 \t Rec: 5.851800441741943 \t KL: 2.1595886190439728e-10\n",
            "Epoch: 663/1000  -  Loss: 5.851802825927734 \t Rec: 5.851802825927734 \t KL: 1.5117120888419322e-09\n",
            "Epoch: 664/1000  -  Loss: 5.851803302764893 \t Rec: 5.851803302764893 \t KL: 2.1595886190439728e-10\n",
            "Epoch: 665/1000  -  Loss: 5.851813316345215 \t Rec: 5.851813316345215 \t KL: 0.0\n",
            "Epoch: 666/1000  -  Loss: 5.8517961502075195 \t Rec: 5.8517961502075195 \t KL: 1.9436297016284243e-09\n",
            "Epoch: 667/1000  -  Loss: 5.851808547973633 \t Rec: 5.851808547973633 \t KL: 2.1595886190439728e-10\n",
            "Epoch: 668/1000  -  Loss: 5.851808547973633 \t Rec: 5.851808547973633 \t KL: 1.9436297016284243e-09\n",
            "Epoch: 669/1000  -  Loss: 5.851800441741943 \t Rec: 5.851800441741943 \t KL: 4.3191772380879456e-10\n",
            "Epoch: 670/1000  -  Loss: 5.851799964904785 \t Rec: 5.851799964904785 \t KL: 2.1595886190439728e-10\n",
            "Epoch: 671/1000  -  Loss: 5.851802825927734 \t Rec: 5.851802825927734 \t KL: 2.3755475364595213e-09\n",
            "Epoch: 672/1000  -  Loss: 5.851810455322266 \t Rec: 5.851810455322266 \t KL: 6.478765857131918e-10\n",
            "Epoch: 673/1000  -  Loss: 5.8517985343933105 \t Rec: 5.8517985343933105 \t KL: 1.2957531714263837e-09\n",
            "Epoch: 674/1000  -  Loss: 5.851802825927734 \t Rec: 5.851802825927734 \t KL: 1.5117120888419322e-09\n",
            "Epoch: 675/1000  -  Loss: 5.851810455322266 \t Rec: 5.851810455322266 \t KL: 3.0234241776838644e-09\n",
            "Epoch: 676/1000  -  Loss: 5.851800441741943 \t Rec: 5.851800441741943 \t KL: 6.478765857131918e-10\n",
            "Epoch: 677/1000  -  Loss: 5.851807117462158 \t Rec: 5.851807117462158 \t KL: 2.1595886190439728e-10\n",
            "Epoch: 678/1000  -  Loss: 5.8517985343933105 \t Rec: 5.8517985343933105 \t KL: 0.0\n",
            "Epoch: 679/1000  -  Loss: 5.851809978485107 \t Rec: 5.851809978485107 \t KL: 2.1595886190439728e-10\n",
            "Epoch: 680/1000  -  Loss: 5.851796627044678 \t Rec: 5.851796627044678 \t KL: 1.2957531714263837e-09\n",
            "Epoch: 681/1000  -  Loss: 5.851808547973633 \t Rec: 5.851808547973633 \t KL: 1.2957531714263837e-09\n",
            "Epoch: 682/1000  -  Loss: 5.851806640625 \t Rec: 5.851806640625 \t KL: 2.1595885080216703e-09\n",
            "Epoch: 683/1000  -  Loss: 5.851804733276367 \t Rec: 5.851804733276367 \t KL: 1.0797943650331376e-09\n",
            "Epoch: 684/1000  -  Loss: 5.851806163787842 \t Rec: 5.851806163787842 \t KL: 1.2957531714263837e-09\n",
            "Epoch: 685/1000  -  Loss: 5.85181188583374 \t Rec: 5.85181188583374 \t KL: 6.478765857131918e-10\n",
            "Epoch: 686/1000  -  Loss: 5.851804733276367 \t Rec: 5.851804733276367 \t KL: 4.3191772380879456e-10\n",
            "Epoch: 687/1000  -  Loss: 5.851802825927734 \t Rec: 5.851802825927734 \t KL: 6.478765857131918e-10\n",
            "Epoch: 688/1000  -  Loss: 5.85181188583374 \t Rec: 5.85181188583374 \t KL: 1.5117120888419322e-09\n",
            "Epoch: 689/1000  -  Loss: 5.8517961502075195 \t Rec: 5.8517961502075195 \t KL: 2.3755475364595213e-09\n",
            "Epoch: 690/1000  -  Loss: 5.851799964904785 \t Rec: 5.851799964904785 \t KL: 1.0797943650331376e-09\n",
            "Epoch: 691/1000  -  Loss: 5.851812839508057 \t Rec: 5.851812839508057 \t KL: 2.1595886190439728e-10\n",
            "Epoch: 692/1000  -  Loss: 5.851807117462158 \t Rec: 5.851807117462158 \t KL: 3.6713008189082075e-09\n",
            "Epoch: 693/1000  -  Loss: 5.851806640625 \t Rec: 5.851806640625 \t KL: 1.7276708952351783e-09\n",
            "Epoch: 694/1000  -  Loss: 5.851801872253418 \t Rec: 5.851801872253418 \t KL: 6.478765857131918e-10\n",
            "Epoch: 695/1000  -  Loss: 5.851807117462158 \t Rec: 5.851807117462158 \t KL: 1.2957531714263837e-09\n",
            "Epoch: 696/1000  -  Loss: 5.851800441741943 \t Rec: 5.851800441741943 \t KL: 8.638354476175891e-10\n",
            "Epoch: 697/1000  -  Loss: 5.851802825927734 \t Rec: 5.851802825927734 \t KL: 8.638354476175891e-10\n",
            "Epoch: 698/1000  -  Loss: 5.8518147468566895 \t Rec: 5.8518147468566895 \t KL: 0.0\n",
            "Epoch: 699/1000  -  Loss: 5.851804733276367 \t Rec: 5.851804733276367 \t KL: 8.638354476175891e-10\n",
            "Epoch: 700/1000  -  Loss: 5.851803779602051 \t Rec: 5.851803779602051 \t KL: 8.638354476175891e-10\n",
            "Epoch: 701/1000  -  Loss: 5.851808547973633 \t Rec: 5.851808547973633 \t KL: 2.1595886190439728e-10\n",
            "Epoch: 702/1000  -  Loss: 5.851801872253418 \t Rec: 5.851801872253418 \t KL: 1.5117120888419322e-09\n",
            "Epoch: 703/1000  -  Loss: 5.851803302764893 \t Rec: 5.851803302764893 \t KL: 3.6713003748189976e-09\n",
            "Epoch: 704/1000  -  Loss: 5.851803779602051 \t Rec: 5.851803779602051 \t KL: 2.1595886190439728e-10\n",
            "Epoch: 705/1000  -  Loss: 5.851808547973633 \t Rec: 5.851808547973633 \t KL: 2.1595885080216703e-09\n",
            "Epoch: 706/1000  -  Loss: 5.851803302764893 \t Rec: 5.851803302764893 \t KL: 6.478765857131918e-10\n",
            "Epoch: 707/1000  -  Loss: 5.851801872253418 \t Rec: 5.851801872253418 \t KL: 2.1595886190439728e-10\n",
            "Epoch: 708/1000  -  Loss: 5.85181188583374 \t Rec: 5.85181188583374 \t KL: 2.1595886190439728e-10\n",
            "Epoch: 709/1000  -  Loss: 5.851802825927734 \t Rec: 5.851802825927734 \t KL: 6.478765857131918e-10\n",
            "Epoch: 710/1000  -  Loss: 5.851808547973633 \t Rec: 5.851808547973633 \t KL: 1.0797943650331376e-09\n",
            "Epoch: 711/1000  -  Loss: 5.851803779602051 \t Rec: 5.851803779602051 \t KL: 1.9436297016284243e-09\n",
            "Epoch: 712/1000  -  Loss: 5.851800441741943 \t Rec: 5.851800441741943 \t KL: 6.478765857131918e-10\n",
            "Epoch: 713/1000  -  Loss: 5.8518147468566895 \t Rec: 5.8518147468566895 \t KL: 4.3191772380879456e-10\n",
            "Epoch: 714/1000  -  Loss: 5.851803779602051 \t Rec: 5.851803779602051 \t KL: 1.0797943650331376e-09\n",
            "Epoch: 715/1000  -  Loss: 5.851802825927734 \t Rec: 5.851802825927734 \t KL: 4.3191772380879456e-10\n",
            "Epoch: 716/1000  -  Loss: 5.851809501647949 \t Rec: 5.851809501647949 \t KL: 1.0797943650331376e-09\n",
            "Epoch: 717/1000  -  Loss: 5.851799488067627 \t Rec: 5.851799488067627 \t KL: 1.9436297016284243e-09\n",
            "Epoch: 718/1000  -  Loss: 5.851812839508057 \t Rec: 5.851812839508057 \t KL: 4.3191772380879456e-10\n",
            "Epoch: 719/1000  -  Loss: 5.851799964904785 \t Rec: 5.851799964904785 \t KL: 6.478765857131918e-10\n",
            "Epoch: 720/1000  -  Loss: 5.851806640625 \t Rec: 5.851806640625 \t KL: 8.638354476175891e-10\n",
            "Epoch: 721/1000  -  Loss: 5.851804733276367 \t Rec: 5.851804733276367 \t KL: 6.478765857131918e-10\n",
            "Epoch: 722/1000  -  Loss: 5.851808547973633 \t Rec: 5.851808547973633 \t KL: 2.1595886190439728e-10\n",
            "Epoch: 723/1000  -  Loss: 5.851805210113525 \t Rec: 5.851805210113525 \t KL: 0.0\n",
            "Epoch: 724/1000  -  Loss: 5.851802825927734 \t Rec: 5.851802825927734 \t KL: 2.1595887300662753e-09\n",
            "Epoch: 725/1000  -  Loss: 5.851805210113525 \t Rec: 5.851805210113525 \t KL: 2.1595886190439728e-10\n",
            "Epoch: 726/1000  -  Loss: 5.851804733276367 \t Rec: 5.851804733276367 \t KL: 3.0234239556392595e-09\n",
            "Epoch: 727/1000  -  Loss: 5.85180139541626 \t Rec: 5.85180139541626 \t KL: 4.3191772380879456e-10\n",
            "Epoch: 728/1000  -  Loss: 5.851808547973633 \t Rec: 5.851808547973633 \t KL: 6.478765857131918e-10\n",
            "Epoch: 729/1000  -  Loss: 5.851804733276367 \t Rec: 5.851804733276367 \t KL: 2.1595886190439728e-10\n",
            "Epoch: 730/1000  -  Loss: 5.851803302764893 \t Rec: 5.851803302764893 \t KL: 8.638354476175891e-10\n",
            "Epoch: 731/1000  -  Loss: 5.851803302764893 \t Rec: 5.851803302764893 \t KL: 2.1595886190439728e-10\n",
            "Epoch: 732/1000  -  Loss: 5.851809501647949 \t Rec: 5.851809501647949 \t KL: 2.5915063428527674e-09\n",
            "Epoch: 733/1000  -  Loss: 5.851803302764893 \t Rec: 5.851803302764893 \t KL: 4.319177016043341e-09\n",
            "Epoch: 734/1000  -  Loss: 5.851807117462158 \t Rec: 5.851807117462158 \t KL: 6.478765857131918e-10\n",
            "Epoch: 735/1000  -  Loss: 5.851806163787842 \t Rec: 5.851806163787842 \t KL: 0.0\n",
            "Epoch: 736/1000  -  Loss: 5.85180139541626 \t Rec: 5.85180139541626 \t KL: 8.638354476175891e-10\n",
            "Epoch: 737/1000  -  Loss: 5.851806163787842 \t Rec: 5.851806163787842 \t KL: 8.638354476175891e-10\n",
            "Epoch: 738/1000  -  Loss: 5.851808547973633 \t Rec: 5.851808547973633 \t KL: 1.9436297016284243e-09\n",
            "Epoch: 739/1000  -  Loss: 5.851806163787842 \t Rec: 5.851806163787842 \t KL: 1.2957531714263837e-09\n",
            "Epoch: 740/1000  -  Loss: 5.851804733276367 \t Rec: 5.851804733276367 \t KL: 6.478765857131918e-10\n",
            "Epoch: 741/1000  -  Loss: 5.851802825927734 \t Rec: 5.851802825927734 \t KL: 1.7276708952351783e-09\n",
            "Epoch: 742/1000  -  Loss: 5.851804733276367 \t Rec: 5.851804733276367 \t KL: 6.478765857131918e-10\n",
            "Epoch: 743/1000  -  Loss: 5.85181188583374 \t Rec: 5.85181188583374 \t KL: 6.478765857131918e-10\n",
            "Epoch: 744/1000  -  Loss: 5.851805210113525 \t Rec: 5.851805210113525 \t KL: 1.2957531714263837e-09\n",
            "Epoch: 745/1000  -  Loss: 5.8517985343933105 \t Rec: 5.8517985343933105 \t KL: 2.1595887300662753e-09\n",
            "Epoch: 746/1000  -  Loss: 5.851799488067627 \t Rec: 5.851799488067627 \t KL: 3.0234239556392595e-09\n",
            "Epoch: 747/1000  -  Loss: 5.851805210113525 \t Rec: 5.851805210113525 \t KL: 1.0797943650331376e-09\n",
            "Epoch: 748/1000  -  Loss: 5.851815223693848 \t Rec: 5.851815223693848 \t KL: 2.3755475364595213e-09\n",
            "Epoch: 749/1000  -  Loss: 5.85180139541626 \t Rec: 5.85180139541626 \t KL: 1.2957531714263837e-09\n",
            "Epoch: 750/1000  -  Loss: 5.851808547973633 \t Rec: 5.851808547973633 \t KL: 4.3191772380879456e-10\n",
            "Epoch: 751/1000  -  Loss: 5.851809978485107 \t Rec: 5.851809978485107 \t KL: 4.3191772380879456e-10\n",
            "Epoch: 752/1000  -  Loss: 5.8517961502075195 \t Rec: 5.8517961502075195 \t KL: 0.0\n",
            "Epoch: 753/1000  -  Loss: 5.851818084716797 \t Rec: 5.851818084716797 \t KL: 4.751094628829833e-09\n",
            "Epoch: 754/1000  -  Loss: 5.851803779602051 \t Rec: 5.851803779602051 \t KL: 2.1595886190439728e-10\n",
            "Epoch: 755/1000  -  Loss: 5.851807117462158 \t Rec: 5.851807117462158 \t KL: 1.0797943650331376e-09\n",
            "Epoch: 756/1000  -  Loss: 5.851803779602051 \t Rec: 5.851803779602051 \t KL: 1.9436297016284243e-09\n",
            "Epoch: 757/1000  -  Loss: 5.85180139541626 \t Rec: 5.85180139541626 \t KL: 2.3755475364595213e-09\n",
            "Epoch: 758/1000  -  Loss: 5.851808547973633 \t Rec: 5.851808547973633 \t KL: 8.638354476175891e-10\n",
            "Epoch: 759/1000  -  Loss: 5.851804733276367 \t Rec: 5.851804733276367 \t KL: 2.3755475364595213e-09\n",
            "Epoch: 760/1000  -  Loss: 5.851803302764893 \t Rec: 5.851803302764893 \t KL: 1.0797943650331376e-09\n",
            "Epoch: 761/1000  -  Loss: 5.851801872253418 \t Rec: 5.851801872253418 \t KL: 1.5117120888419322e-09\n",
            "Epoch: 762/1000  -  Loss: 5.851808547973633 \t Rec: 5.851808547973633 \t KL: 0.0\n",
            "Epoch: 763/1000  -  Loss: 5.851805210113525 \t Rec: 5.851805210113525 \t KL: 2.5915063428527674e-09\n",
            "Epoch: 764/1000  -  Loss: 5.851809501647949 \t Rec: 5.851809501647949 \t KL: 8.638354476175891e-10\n",
            "Epoch: 765/1000  -  Loss: 5.8517961502075195 \t Rec: 5.8517961502075195 \t KL: 1.2957531714263837e-09\n",
            "Epoch: 766/1000  -  Loss: 5.851809978485107 \t Rec: 5.851809978485107 \t KL: 0.0\n",
            "Epoch: 767/1000  -  Loss: 5.851802825927734 \t Rec: 5.851802825927734 \t KL: 1.9436297016284243e-09\n",
            "Epoch: 768/1000  -  Loss: 5.851809978485107 \t Rec: 5.851809978485107 \t KL: 4.3191772380879456e-10\n",
            "Epoch: 769/1000  -  Loss: 5.85180139541626 \t Rec: 5.85180139541626 \t KL: 1.5117119778196297e-09\n",
            "Epoch: 770/1000  -  Loss: 5.851799964904785 \t Rec: 5.851799964904785 \t KL: 8.638354476175891e-10\n",
            "Epoch: 771/1000  -  Loss: 5.851806163787842 \t Rec: 5.851806163787842 \t KL: 8.638354476175891e-10\n",
            "Epoch: 772/1000  -  Loss: 5.85181188583374 \t Rec: 5.85181188583374 \t KL: 8.638354476175891e-10\n",
            "Epoch: 773/1000  -  Loss: 5.851806163787842 \t Rec: 5.851806163787842 \t KL: 2.1595887300662753e-09\n",
            "Epoch: 774/1000  -  Loss: 5.851799964904785 \t Rec: 5.851799964904785 \t KL: 4.3191772380879456e-10\n",
            "Epoch: 775/1000  -  Loss: 5.851809501647949 \t Rec: 5.851809501647949 \t KL: 6.478765857131918e-10\n",
            "Epoch: 776/1000  -  Loss: 5.851809978485107 \t Rec: 5.851809978485107 \t KL: 4.3191772380879456e-10\n",
            "Epoch: 777/1000  -  Loss: 5.851808547973633 \t Rec: 5.851808547973633 \t KL: 1.9436299236730292e-09\n",
            "Epoch: 778/1000  -  Loss: 5.851798057556152 \t Rec: 5.851798057556152 \t KL: 4.3191772380879456e-10\n",
            "Epoch: 779/1000  -  Loss: 5.851808547973633 \t Rec: 5.851808547973633 \t KL: 8.638354476175891e-10\n",
            "Epoch: 780/1000  -  Loss: 5.851808071136475 \t Rec: 5.851808071136475 \t KL: 1.5117120888419322e-09\n",
            "Epoch: 781/1000  -  Loss: 5.85180139541626 \t Rec: 5.85180139541626 \t KL: 3.4553417904703565e-09\n",
            "Epoch: 782/1000  -  Loss: 5.851805210113525 \t Rec: 5.851805210113525 \t KL: 8.638354476175891e-10\n",
            "Epoch: 783/1000  -  Loss: 5.851805210113525 \t Rec: 5.851805210113525 \t KL: 6.478765857131918e-10\n",
            "Epoch: 784/1000  -  Loss: 5.851808071136475 \t Rec: 5.851808071136475 \t KL: 2.1595886190439728e-10\n",
            "Epoch: 785/1000  -  Loss: 5.851806163787842 \t Rec: 5.851806163787842 \t KL: 1.2957531714263837e-09\n",
            "Epoch: 786/1000  -  Loss: 5.851803302764893 \t Rec: 5.851803302764893 \t KL: 3.0234239556392595e-09\n",
            "Epoch: 787/1000  -  Loss: 5.85180139541626 \t Rec: 5.85180139541626 \t KL: 6.478765857131918e-10\n",
            "Epoch: 788/1000  -  Loss: 5.851799488067627 \t Rec: 5.851799488067627 \t KL: 1.2957531714263837e-09\n",
            "Epoch: 789/1000  -  Loss: 5.851806640625 \t Rec: 5.851806640625 \t KL: 6.478765857131918e-10\n",
            "Epoch: 790/1000  -  Loss: 5.851808547973633 \t Rec: 5.851808547973633 \t KL: 1.2957531714263837e-09\n",
            "Epoch: 791/1000  -  Loss: 5.851810455322266 \t Rec: 5.851810455322266 \t KL: 1.7276707842128758e-09\n",
            "Epoch: 792/1000  -  Loss: 5.851800441741943 \t Rec: 5.851800441741943 \t KL: 1.2957531714263837e-09\n",
            "Epoch: 793/1000  -  Loss: 5.851808071136475 \t Rec: 5.851808071136475 \t KL: 1.2957531714263837e-09\n",
            "Epoch: 794/1000  -  Loss: 5.851803302764893 \t Rec: 5.851803302764893 \t KL: 4.3191772380879456e-10\n",
            "Epoch: 795/1000  -  Loss: 5.85180139541626 \t Rec: 5.85180139541626 \t KL: 4.103218209650095e-09\n",
            "Epoch: 796/1000  -  Loss: 5.851804733276367 \t Rec: 5.851804733276367 \t KL: 3.2393827620325055e-09\n",
            "Epoch: 797/1000  -  Loss: 5.851810455322266 \t Rec: 5.851810455322266 \t KL: 1.7276708952351783e-09\n",
            "Epoch: 798/1000  -  Loss: 5.851800441741943 \t Rec: 5.851800441741943 \t KL: 2.1595885080216703e-09\n",
            "Epoch: 799/1000  -  Loss: 5.851804733276367 \t Rec: 5.851804733276367 \t KL: 0.0\n",
            "Epoch: 800/1000  -  Loss: 5.851806640625 \t Rec: 5.851806640625 \t KL: 6.478765857131918e-10\n",
            "Epoch: 801/1000  -  Loss: 5.851809978485107 \t Rec: 5.851809978485107 \t KL: 0.0\n",
            "Epoch: 802/1000  -  Loss: 5.851801872253418 \t Rec: 5.851801872253418 \t KL: 6.478765857131918e-10\n",
            "Epoch: 803/1000  -  Loss: 5.851806163787842 \t Rec: 5.851806163787842 \t KL: 1.0797943650331376e-09\n",
            "Epoch: 804/1000  -  Loss: 5.851806640625 \t Rec: 5.851806640625 \t KL: 2.1595886190439728e-10\n",
            "Epoch: 805/1000  -  Loss: 5.851801872253418 \t Rec: 5.851801872253418 \t KL: 0.0\n",
            "Epoch: 806/1000  -  Loss: 5.851806640625 \t Rec: 5.851806640625 \t KL: 1.9436297016284243e-09\n",
            "Epoch: 807/1000  -  Loss: 5.851803302764893 \t Rec: 5.851803302764893 \t KL: 6.478765857131918e-10\n",
            "Epoch: 808/1000  -  Loss: 5.851799964904785 \t Rec: 5.851799964904785 \t KL: 2.8074651492460134e-09\n",
            "Epoch: 809/1000  -  Loss: 5.851804733276367 \t Rec: 5.851804733276367 \t KL: 2.1595887300662753e-09\n",
            "Epoch: 810/1000  -  Loss: 5.851803779602051 \t Rec: 5.851803779602051 \t KL: 8.638354476175891e-10\n",
            "Epoch: 811/1000  -  Loss: 5.851804733276367 \t Rec: 5.851804733276367 \t KL: 4.3191772380879456e-10\n",
            "Epoch: 812/1000  -  Loss: 5.851803779602051 \t Rec: 5.851803779602051 \t KL: 4.3191772380879456e-10\n",
            "Epoch: 813/1000  -  Loss: 5.851806163787842 \t Rec: 5.851806163787842 \t KL: 0.0\n",
            "Epoch: 814/1000  -  Loss: 5.85179328918457 \t Rec: 5.85179328918457 \t KL: 1.5117120888419322e-09\n",
            "Epoch: 815/1000  -  Loss: 5.851809501647949 \t Rec: 5.851809501647949 \t KL: 1.7276708952351783e-09\n",
            "Epoch: 816/1000  -  Loss: 5.851809501647949 \t Rec: 5.851809501647949 \t KL: 0.0\n",
            "Epoch: 817/1000  -  Loss: 5.851799488067627 \t Rec: 5.851799488067627 \t KL: 4.3191772380879456e-10\n",
            "Epoch: 818/1000  -  Loss: 5.851803779602051 \t Rec: 5.851803779602051 \t KL: 2.8074651492460134e-09\n",
            "Epoch: 819/1000  -  Loss: 5.851799488067627 \t Rec: 5.851799488067627 \t KL: 1.9436297016284243e-09\n",
            "Epoch: 820/1000  -  Loss: 5.851810455322266 \t Rec: 5.851810455322266 \t KL: 0.0\n",
            "Epoch: 821/1000  -  Loss: 5.851800441741943 \t Rec: 5.851800441741943 \t KL: 0.0\n",
            "Epoch: 822/1000  -  Loss: 5.851803779602051 \t Rec: 5.851803779602051 \t KL: 1.9436299236730292e-09\n",
            "Epoch: 823/1000  -  Loss: 5.851808071136475 \t Rec: 5.851808071136475 \t KL: 1.2957531714263837e-09\n",
            "Epoch: 824/1000  -  Loss: 5.851799488067627 \t Rec: 5.851799488067627 \t KL: 1.0797943650331376e-09\n",
            "Epoch: 825/1000  -  Loss: 5.851812839508057 \t Rec: 5.851812839508057 \t KL: 0.0\n",
            "Epoch: 826/1000  -  Loss: 5.851802825927734 \t Rec: 5.851802825927734 \t KL: 1.5117119778196297e-09\n",
            "Epoch: 827/1000  -  Loss: 5.851808071136475 \t Rec: 5.851808071136475 \t KL: 2.5915063428527674e-09\n",
            "Epoch: 828/1000  -  Loss: 5.851804733276367 \t Rec: 5.851804733276367 \t KL: 1.2957531714263837e-09\n",
            "Epoch: 829/1000  -  Loss: 5.851808071136475 \t Rec: 5.851808071136475 \t KL: 8.638354476175891e-10\n",
            "Epoch: 830/1000  -  Loss: 5.8518171310424805 \t Rec: 5.8518171310424805 \t KL: 1.7276708952351783e-09\n",
            "Epoch: 831/1000  -  Loss: 5.851796627044678 \t Rec: 5.851796627044678 \t KL: 8.638354476175891e-10\n",
            "Epoch: 832/1000  -  Loss: 5.851804733276367 \t Rec: 5.851804733276367 \t KL: 4.3191772380879456e-10\n",
            "Epoch: 833/1000  -  Loss: 5.851808547973633 \t Rec: 5.851808547973633 \t KL: 3.2393827620325055e-09\n",
            "Epoch: 834/1000  -  Loss: 5.851806163787842 \t Rec: 5.851806163787842 \t KL: 1.9436297016284243e-09\n",
            "Epoch: 835/1000  -  Loss: 5.851799964904785 \t Rec: 5.851799964904785 \t KL: 1.9436297016284243e-09\n",
            "Epoch: 836/1000  -  Loss: 5.851806163787842 \t Rec: 5.851806163787842 \t KL: 0.0\n",
            "Epoch: 837/1000  -  Loss: 5.851808547973633 \t Rec: 5.851808547973633 \t KL: 2.5915063428527674e-09\n",
            "Epoch: 838/1000  -  Loss: 5.8517985343933105 \t Rec: 5.8517985343933105 \t KL: 6.478765857131918e-10\n",
            "Epoch: 839/1000  -  Loss: 5.851808547973633 \t Rec: 5.851808547973633 \t KL: 2.1595886190439728e-10\n",
            "Epoch: 840/1000  -  Loss: 5.851804733276367 \t Rec: 5.851804733276367 \t KL: 4.3191772380879456e-10\n",
            "Epoch: 841/1000  -  Loss: 5.851808547973633 \t Rec: 5.851808547973633 \t KL: 2.1595886190439728e-10\n",
            "Epoch: 842/1000  -  Loss: 5.851808547973633 \t Rec: 5.851808547973633 \t KL: 2.1595885080216703e-09\n",
            "Epoch: 843/1000  -  Loss: 5.851801872253418 \t Rec: 5.851801872253418 \t KL: 3.0234239556392595e-09\n",
            "Epoch: 844/1000  -  Loss: 5.851806163787842 \t Rec: 5.851806163787842 \t KL: 6.478765857131918e-10\n",
            "Epoch: 845/1000  -  Loss: 5.851805210113525 \t Rec: 5.851805210113525 \t KL: 4.3191772380879456e-10\n",
            "Epoch: 846/1000  -  Loss: 5.851799488067627 \t Rec: 5.851799488067627 \t KL: 2.1595886190439728e-10\n",
            "Epoch: 847/1000  -  Loss: 5.851805210113525 \t Rec: 5.851805210113525 \t KL: 2.3755475364595213e-09\n",
            "Epoch: 848/1000  -  Loss: 5.851806640625 \t Rec: 5.851806640625 \t KL: 1.7276707842128758e-09\n",
            "Epoch: 849/1000  -  Loss: 5.851800441741943 \t Rec: 5.851800441741943 \t KL: 0.0\n",
            "Epoch: 850/1000  -  Loss: 5.851804733276367 \t Rec: 5.851804733276367 \t KL: 0.0\n",
            "Epoch: 851/1000  -  Loss: 5.851799964904785 \t Rec: 5.851799964904785 \t KL: 1.0797943650331376e-09\n",
            "Epoch: 852/1000  -  Loss: 5.85181188583374 \t Rec: 5.85181188583374 \t KL: 4.3191772380879456e-10\n",
            "Epoch: 853/1000  -  Loss: 5.851799964904785 \t Rec: 5.851799964904785 \t KL: 0.0\n",
            "Epoch: 854/1000  -  Loss: 5.851806163787842 \t Rec: 5.851806163787842 \t KL: 1.0797943650331376e-09\n",
            "Epoch: 855/1000  -  Loss: 5.851805210113525 \t Rec: 5.851805210113525 \t KL: 8.638354476175891e-10\n",
            "Epoch: 856/1000  -  Loss: 5.851806640625 \t Rec: 5.851806640625 \t KL: 1.5117119778196297e-09\n",
            "Epoch: 857/1000  -  Loss: 5.851803302764893 \t Rec: 5.851803302764893 \t KL: 8.638354476175891e-10\n",
            "Epoch: 858/1000  -  Loss: 5.85181188583374 \t Rec: 5.85181188583374 \t KL: 3.2393827620325055e-09\n",
            "Epoch: 859/1000  -  Loss: 5.851802825927734 \t Rec: 5.851802825927734 \t KL: 0.0\n",
            "Epoch: 860/1000  -  Loss: 5.851801872253418 \t Rec: 5.851801872253418 \t KL: 1.7276708952351783e-09\n",
            "Epoch: 861/1000  -  Loss: 5.851801872253418 \t Rec: 5.851801872253418 \t KL: 2.1595886190439728e-10\n",
            "Epoch: 862/1000  -  Loss: 5.851807117462158 \t Rec: 5.851807117462158 \t KL: 1.7276708952351783e-09\n",
            "Epoch: 863/1000  -  Loss: 5.85181188583374 \t Rec: 5.85181188583374 \t KL: 0.0\n",
            "Epoch: 864/1000  -  Loss: 5.851805210113525 \t Rec: 5.851805210113525 \t KL: 8.638354476175891e-10\n",
            "Epoch: 865/1000  -  Loss: 5.851806640625 \t Rec: 5.851806640625 \t KL: 6.478765857131918e-10\n",
            "Epoch: 866/1000  -  Loss: 5.851799964904785 \t Rec: 5.851799964904785 \t KL: 6.478765857131918e-10\n",
            "Epoch: 867/1000  -  Loss: 5.851808071136475 \t Rec: 5.851808071136475 \t KL: 2.5915063428527674e-09\n",
            "Epoch: 868/1000  -  Loss: 5.851804733276367 \t Rec: 5.851804733276367 \t KL: 1.7276708952351783e-09\n",
            "Epoch: 869/1000  -  Loss: 5.85181188583374 \t Rec: 5.85181188583374 \t KL: 3.6713003748189976e-09\n",
            "Epoch: 870/1000  -  Loss: 5.851800441741943 \t Rec: 5.851800441741943 \t KL: 4.3191772380879456e-10\n",
            "Epoch: 871/1000  -  Loss: 5.85180139541626 \t Rec: 5.85180139541626 \t KL: 1.0797943650331376e-09\n",
            "Epoch: 872/1000  -  Loss: 5.851806163787842 \t Rec: 5.851806163787842 \t KL: 1.2957531714263837e-09\n",
            "Epoch: 873/1000  -  Loss: 5.851806163787842 \t Rec: 5.851806163787842 \t KL: 2.1595885080216703e-09\n",
            "Epoch: 874/1000  -  Loss: 5.851808071136475 \t Rec: 5.851808071136475 \t KL: 4.3191772380879456e-10\n",
            "Epoch: 875/1000  -  Loss: 5.851808547973633 \t Rec: 5.851808547973633 \t KL: 8.638354476175891e-10\n",
            "Epoch: 876/1000  -  Loss: 5.851806640625 \t Rec: 5.851806640625 \t KL: 2.1595886190439728e-10\n",
            "Epoch: 877/1000  -  Loss: 5.851803779602051 \t Rec: 5.851803779602051 \t KL: 0.0\n",
            "Epoch: 878/1000  -  Loss: 5.851809501647949 \t Rec: 5.851809501647949 \t KL: 2.1595886190439728e-10\n",
            "Epoch: 879/1000  -  Loss: 5.851806163787842 \t Rec: 5.851806163787842 \t KL: 1.2957531714263837e-09\n",
            "Epoch: 880/1000  -  Loss: 5.851801872253418 \t Rec: 5.851801872253418 \t KL: 4.3191772380879456e-10\n",
            "Epoch: 881/1000  -  Loss: 5.851808071136475 \t Rec: 5.851808071136475 \t KL: 6.478765857131918e-10\n",
            "Epoch: 882/1000  -  Loss: 5.851807117462158 \t Rec: 5.851807117462158 \t KL: 4.3191772380879456e-10\n",
            "Epoch: 883/1000  -  Loss: 5.851796627044678 \t Rec: 5.851796627044678 \t KL: 2.1595886190439728e-10\n",
            "Epoch: 884/1000  -  Loss: 5.851810455322266 \t Rec: 5.851810455322266 \t KL: 2.1595886190439728e-10\n",
            "Epoch: 885/1000  -  Loss: 5.851800441741943 \t Rec: 5.851800441741943 \t KL: 1.9436297016284243e-09\n",
            "Epoch: 886/1000  -  Loss: 5.8518147468566895 \t Rec: 5.8518147468566895 \t KL: 4.3191772380879456e-10\n",
            "Epoch: 887/1000  -  Loss: 5.851801872253418 \t Rec: 5.851801872253418 \t KL: 4.3191772380879456e-10\n",
            "Epoch: 888/1000  -  Loss: 5.851796627044678 \t Rec: 5.851796627044678 \t KL: 4.3191772380879456e-10\n",
            "Epoch: 889/1000  -  Loss: 5.851806163787842 \t Rec: 5.851806163787842 \t KL: 2.3755475364595213e-09\n",
            "Epoch: 890/1000  -  Loss: 5.851804733276367 \t Rec: 5.851804733276367 \t KL: 6.478765857131918e-10\n",
            "Epoch: 891/1000  -  Loss: 5.851803779602051 \t Rec: 5.851803779602051 \t KL: 1.2957531714263837e-09\n",
            "Epoch: 892/1000  -  Loss: 5.851803302764893 \t Rec: 5.851803302764893 \t KL: 1.2957531714263837e-09\n",
            "Epoch: 893/1000  -  Loss: 5.851806640625 \t Rec: 5.851806640625 \t KL: 6.478765857131918e-10\n",
            "Epoch: 894/1000  -  Loss: 5.851803302764893 \t Rec: 5.851803302764893 \t KL: 2.3755473144149164e-09\n",
            "Epoch: 895/1000  -  Loss: 5.851807117462158 \t Rec: 5.851807117462158 \t KL: 2.5915065648973723e-09\n",
            "Epoch: 896/1000  -  Loss: 5.851806163787842 \t Rec: 5.851806163787842 \t KL: 6.478765857131918e-10\n",
            "Epoch: 897/1000  -  Loss: 5.85180139541626 \t Rec: 5.85180139541626 \t KL: 8.638354476175891e-10\n",
            "Epoch: 898/1000  -  Loss: 5.851813316345215 \t Rec: 5.851813316345215 \t KL: 1.2957531714263837e-09\n",
            "Epoch: 899/1000  -  Loss: 5.8517985343933105 \t Rec: 5.8517985343933105 \t KL: 1.0797943650331376e-09\n",
            "Epoch: 900/1000  -  Loss: 5.851804733276367 \t Rec: 5.851804733276367 \t KL: 8.638354476175891e-10\n",
            "Epoch: 901/1000  -  Loss: 5.85181188583374 \t Rec: 5.85181188583374 \t KL: 2.5915063428527674e-09\n",
            "Epoch: 902/1000  -  Loss: 5.8517961502075195 \t Rec: 5.8517961502075195 \t KL: 8.638354476175891e-10\n",
            "Epoch: 903/1000  -  Loss: 5.851803302764893 \t Rec: 5.851803302764893 \t KL: 1.9436294795838194e-09\n",
            "Epoch: 904/1000  -  Loss: 5.851808547973633 \t Rec: 5.851808547973633 \t KL: 2.1595886190439728e-10\n",
            "Epoch: 905/1000  -  Loss: 5.851805210113525 \t Rec: 5.851805210113525 \t KL: 4.3191772380879456e-10\n",
            "Epoch: 906/1000  -  Loss: 5.851801872253418 \t Rec: 5.851801872253418 \t KL: 2.3755470923703115e-09\n",
            "Epoch: 907/1000  -  Loss: 5.851810455322266 \t Rec: 5.851810455322266 \t KL: 0.0\n",
            "Epoch: 908/1000  -  Loss: 5.851804733276367 \t Rec: 5.851804733276367 \t KL: 2.1595886190439728e-10\n",
            "Epoch: 909/1000  -  Loss: 5.851808071136475 \t Rec: 5.851808071136475 \t KL: 2.1595887300662753e-09\n",
            "Epoch: 910/1000  -  Loss: 5.851800441741943 \t Rec: 5.851800441741943 \t KL: 1.0797943650331376e-09\n",
            "Epoch: 911/1000  -  Loss: 5.851810455322266 \t Rec: 5.851810455322266 \t KL: 6.478765857131918e-10\n",
            "Epoch: 912/1000  -  Loss: 5.851801872253418 \t Rec: 5.851801872253418 \t KL: 1.0797943650331376e-09\n",
            "Epoch: 913/1000  -  Loss: 5.851803302764893 \t Rec: 5.851803302764893 \t KL: 1.7276708952351783e-09\n",
            "Epoch: 914/1000  -  Loss: 5.851799488067627 \t Rec: 5.851799488067627 \t KL: 0.0\n",
            "Epoch: 915/1000  -  Loss: 5.851808071136475 \t Rec: 5.851808071136475 \t KL: 2.1595885080216703e-09\n",
            "Epoch: 916/1000  -  Loss: 5.851803779602051 \t Rec: 5.851803779602051 \t KL: 8.638354476175891e-10\n",
            "Epoch: 917/1000  -  Loss: 5.851801872253418 \t Rec: 5.851801872253418 \t KL: 2.1595885080216703e-09\n",
            "Epoch: 918/1000  -  Loss: 5.851809501647949 \t Rec: 5.851809501647949 \t KL: 4.3191772380879456e-10\n",
            "Epoch: 919/1000  -  Loss: 5.851798057556152 \t Rec: 5.851798057556152 \t KL: 2.1595886190439728e-10\n",
            "Epoch: 920/1000  -  Loss: 5.851803302764893 \t Rec: 5.851803302764893 \t KL: 2.1595885080216703e-09\n",
            "Epoch: 921/1000  -  Loss: 5.851808071136475 \t Rec: 5.851808071136475 \t KL: 1.5117119778196297e-09\n",
            "Epoch: 922/1000  -  Loss: 5.851813793182373 \t Rec: 5.851813793182373 \t KL: 1.0797943650331376e-09\n",
            "Epoch: 923/1000  -  Loss: 5.851799964904785 \t Rec: 5.851799964904785 \t KL: 6.478765857131918e-10\n",
            "Epoch: 924/1000  -  Loss: 5.851800441741943 \t Rec: 5.851800441741943 \t KL: 1.5117119778196297e-09\n",
            "Epoch: 925/1000  -  Loss: 5.851810455322266 \t Rec: 5.851810455322266 \t KL: 1.0797943650331376e-09\n",
            "Epoch: 926/1000  -  Loss: 5.851799488067627 \t Rec: 5.851799488067627 \t KL: 2.1595886190439728e-10\n",
            "Epoch: 927/1000  -  Loss: 5.851805210113525 \t Rec: 5.851805210113525 \t KL: 0.0\n",
            "Epoch: 928/1000  -  Loss: 5.851806640625 \t Rec: 5.851806640625 \t KL: 1.5117120888419322e-09\n",
            "Epoch: 929/1000  -  Loss: 5.851803779602051 \t Rec: 5.851803779602051 \t KL: 1.0797943650331376e-09\n",
            "Epoch: 930/1000  -  Loss: 5.851809501647949 \t Rec: 5.851809501647949 \t KL: 2.8074651492460134e-09\n",
            "Epoch: 931/1000  -  Loss: 5.851803302764893 \t Rec: 5.851803302764893 \t KL: 1.0797943650331376e-09\n",
            "Epoch: 932/1000  -  Loss: 5.851803302764893 \t Rec: 5.851803302764893 \t KL: 2.8074651492460134e-09\n",
            "Epoch: 933/1000  -  Loss: 5.851801872253418 \t Rec: 5.851801872253418 \t KL: 4.3191772380879456e-10\n",
            "Epoch: 934/1000  -  Loss: 5.8518147468566895 \t Rec: 5.8518147468566895 \t KL: 6.478765857131918e-10\n",
            "Epoch: 935/1000  -  Loss: 5.851799964904785 \t Rec: 5.851799964904785 \t KL: 8.638354476175891e-10\n",
            "Epoch: 936/1000  -  Loss: 5.851803779602051 \t Rec: 5.851803779602051 \t KL: 1.0797943650331376e-09\n",
            "Epoch: 937/1000  -  Loss: 5.851808071136475 \t Rec: 5.851808071136475 \t KL: 6.478765857131918e-10\n",
            "Epoch: 938/1000  -  Loss: 5.851801872253418 \t Rec: 5.851801872253418 \t KL: 2.1595886190439728e-10\n",
            "Epoch: 939/1000  -  Loss: 5.851805210113525 \t Rec: 5.851805210113525 \t KL: 1.0797943650331376e-09\n",
            "Epoch: 940/1000  -  Loss: 5.851801872253418 \t Rec: 5.851801872253418 \t KL: 2.3755475364595213e-09\n",
            "Epoch: 941/1000  -  Loss: 5.851804733276367 \t Rec: 5.851804733276367 \t KL: 3.4553415684257516e-09\n",
            "Epoch: 942/1000  -  Loss: 5.851802825927734 \t Rec: 5.851802825927734 \t KL: 0.0\n",
            "Epoch: 943/1000  -  Loss: 5.8517985343933105 \t Rec: 5.8517985343933105 \t KL: 6.478765857131918e-10\n",
            "Epoch: 944/1000  -  Loss: 5.851796627044678 \t Rec: 5.851796627044678 \t KL: 1.0797943650331376e-09\n",
            "Epoch: 945/1000  -  Loss: 5.851803779602051 \t Rec: 5.851803779602051 \t KL: 3.0234241776838644e-09\n",
            "Epoch: 946/1000  -  Loss: 5.851808547973633 \t Rec: 5.851808547973633 \t KL: 1.0797943650331376e-09\n",
            "Epoch: 947/1000  -  Loss: 5.851804733276367 \t Rec: 5.851804733276367 \t KL: 4.3191772380879456e-10\n",
            "Epoch: 948/1000  -  Loss: 5.851800441741943 \t Rec: 5.851800441741943 \t KL: 1.5117120888419322e-09\n",
            "Epoch: 949/1000  -  Loss: 5.851807117462158 \t Rec: 5.851807117462158 \t KL: 4.3191772380879456e-10\n",
            "Epoch: 950/1000  -  Loss: 5.851808071136475 \t Rec: 5.851808071136475 \t KL: 0.0\n",
            "Epoch: 951/1000  -  Loss: 5.851804733276367 \t Rec: 5.851804733276367 \t KL: 1.9436297016284243e-09\n",
            "Epoch: 952/1000  -  Loss: 5.8517985343933105 \t Rec: 5.8517985343933105 \t KL: 1.7276707842128758e-09\n",
            "Epoch: 953/1000  -  Loss: 5.851801872253418 \t Rec: 5.851801872253418 \t KL: 2.1595886190439728e-10\n",
            "Epoch: 954/1000  -  Loss: 5.851804733276367 \t Rec: 5.851804733276367 \t KL: 4.751094628829833e-09\n",
            "Epoch: 955/1000  -  Loss: 5.851803302764893 \t Rec: 5.851803302764893 \t KL: 6.478765857131918e-10\n",
            "Epoch: 956/1000  -  Loss: 5.851808547973633 \t Rec: 5.851808547973633 \t KL: 2.1595886190439728e-10\n",
            "Epoch: 957/1000  -  Loss: 5.851800441741943 \t Rec: 5.851800441741943 \t KL: 1.2957531714263837e-09\n",
            "Epoch: 958/1000  -  Loss: 5.851802825927734 \t Rec: 5.851802825927734 \t KL: 3.0234241776838644e-09\n",
            "Epoch: 959/1000  -  Loss: 5.851801872253418 \t Rec: 5.851801872253418 \t KL: 2.1595886190439728e-10\n",
            "Epoch: 960/1000  -  Loss: 5.85181188583374 \t Rec: 5.85181188583374 \t KL: 4.3191772380879456e-10\n",
            "Epoch: 961/1000  -  Loss: 5.851803302764893 \t Rec: 5.851803302764893 \t KL: 4.3191772380879456e-10\n",
            "Epoch: 962/1000  -  Loss: 5.851801872253418 \t Rec: 5.851801872253418 \t KL: 1.5117120888419322e-09\n",
            "Epoch: 963/1000  -  Loss: 5.851802825927734 \t Rec: 5.851802825927734 \t KL: 2.5915061208081624e-09\n",
            "Epoch: 964/1000  -  Loss: 5.851811408996582 \t Rec: 5.851811408996582 \t KL: 2.8074651492460134e-09\n",
            "Epoch: 965/1000  -  Loss: 5.851803302764893 \t Rec: 5.851803302764893 \t KL: 1.2957531714263837e-09\n",
            "Epoch: 966/1000  -  Loss: 5.851808071136475 \t Rec: 5.851808071136475 \t KL: 2.1595886190439728e-10\n",
            "Epoch: 967/1000  -  Loss: 5.851803302764893 \t Rec: 5.851803302764893 \t KL: 2.1595886190439728e-10\n",
            "Epoch: 968/1000  -  Loss: 5.851797580718994 \t Rec: 5.851797580718994 \t KL: 0.0\n",
            "Epoch: 969/1000  -  Loss: 5.851813316345215 \t Rec: 5.851813316345215 \t KL: 4.3191772380879456e-10\n",
            "Epoch: 970/1000  -  Loss: 5.85180139541626 \t Rec: 5.85180139541626 \t KL: 1.0797943650331376e-09\n",
            "Epoch: 971/1000  -  Loss: 5.851803302764893 \t Rec: 5.851803302764893 \t KL: 2.1595886190439728e-10\n",
            "Epoch: 972/1000  -  Loss: 5.851808547973633 \t Rec: 5.851808547973633 \t KL: 4.3191772380879456e-10\n",
            "Epoch: 973/1000  -  Loss: 5.851810455322266 \t Rec: 5.851810455322266 \t KL: 4.3191772380879456e-10\n",
            "Epoch: 974/1000  -  Loss: 5.851809978485107 \t Rec: 5.851809978485107 \t KL: 2.1595887300662753e-09\n",
            "Epoch: 975/1000  -  Loss: 5.851801872253418 \t Rec: 5.851801872253418 \t KL: 2.8074651492460134e-09\n",
            "Epoch: 976/1000  -  Loss: 5.851804733276367 \t Rec: 5.851804733276367 \t KL: 6.478765857131918e-10\n",
            "Epoch: 977/1000  -  Loss: 5.851809501647949 \t Rec: 5.851809501647949 \t KL: 3.0234239556392595e-09\n",
            "Epoch: 978/1000  -  Loss: 5.851803779602051 \t Rec: 5.851803779602051 \t KL: 6.478765857131918e-10\n",
            "Epoch: 979/1000  -  Loss: 5.851808071136475 \t Rec: 5.851808071136475 \t KL: 1.9436297016284243e-09\n",
            "Epoch: 980/1000  -  Loss: 5.851803302764893 \t Rec: 5.851803302764893 \t KL: 8.638354476175891e-10\n",
            "Epoch: 981/1000  -  Loss: 5.851805210113525 \t Rec: 5.851805210113525 \t KL: 4.3191772380879456e-10\n",
            "Epoch: 982/1000  -  Loss: 5.851806640625 \t Rec: 5.851806640625 \t KL: 6.478765857131918e-10\n",
            "Epoch: 983/1000  -  Loss: 5.851806640625 \t Rec: 5.851806640625 \t KL: 6.478765857131918e-10\n",
            "Epoch: 984/1000  -  Loss: 5.851807117462158 \t Rec: 5.851807117462158 \t KL: 6.478765857131918e-10\n",
            "Epoch: 985/1000  -  Loss: 5.851794719696045 \t Rec: 5.851794719696045 \t KL: 1.0797943650331376e-09\n",
            "Epoch: 986/1000  -  Loss: 5.851811408996582 \t Rec: 5.851811408996582 \t KL: 1.9436297016284243e-09\n",
            "Epoch: 987/1000  -  Loss: 5.851806163787842 \t Rec: 5.851806163787842 \t KL: 0.0\n",
            "Epoch: 988/1000  -  Loss: 5.851806640625 \t Rec: 5.851806640625 \t KL: 1.2957531714263837e-09\n",
            "Epoch: 989/1000  -  Loss: 5.851812839508057 \t Rec: 5.851812839508057 \t KL: 6.478765857131918e-10\n",
            "Epoch: 990/1000  -  Loss: 5.851796627044678 \t Rec: 5.851796627044678 \t KL: 8.638354476175891e-10\n",
            "Epoch: 991/1000  -  Loss: 5.851805210113525 \t Rec: 5.851805210113525 \t KL: 3.887259403256849e-09\n",
            "Epoch: 992/1000  -  Loss: 5.851803779602051 \t Rec: 5.851803779602051 \t KL: 1.0797943650331376e-09\n",
            "Epoch: 993/1000  -  Loss: 5.851799964904785 \t Rec: 5.851799964904785 \t KL: 4.3191772380879456e-10\n",
            "Epoch: 994/1000  -  Loss: 5.851800441741943 \t Rec: 5.851800441741943 \t KL: 1.0797943650331376e-09\n",
            "Epoch: 995/1000  -  Loss: 5.851806640625 \t Rec: 5.851806640625 \t KL: 1.0797943650331376e-09\n",
            "Epoch: 996/1000  -  Loss: 5.851808547973633 \t Rec: 5.851808547973633 \t KL: 1.2957531714263837e-09\n",
            "Epoch: 997/1000  -  Loss: 5.851803302764893 \t Rec: 5.851803302764893 \t KL: 4.3191772380879456e-10\n",
            "Epoch: 998/1000  -  Loss: 5.851803779602051 \t Rec: 5.851803779602051 \t KL: 4.3191772380879456e-10\n",
            "Epoch: 999/1000  -  Loss: 5.851809978485107 \t Rec: 5.851809978485107 \t KL: 1.7276708952351783e-09\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "# start training\n",
        "train_class = TrainETM().train(\n",
        "    etm_model,\n",
        "    vocab_size, \n",
        "    train_args, optimizer_args, train_set, \n",
        "    normalize_data = True) \n",
        "    #num_topics, t_hidden_size, rho_size, emb_size, theta_act, embedding_data, 0.5)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "notebook_replication.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}