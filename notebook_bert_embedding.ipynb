{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "BERT_Embedding_Notebook.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNDQ7cmDx9cQupyiDXOEgou",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hanhluukim/replication-topic-modelling-in-embedding-space/blob/main/notebook_bert_embedding.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pEt5DyniPBcW",
        "outputId": "d63d69ce-6c01-47b9-b475-95fcde264fb6"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.7/dist-packages (4.19.2)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.64.0)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.11.3)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.21.6)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.7.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.13,>=0.11.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.12.1)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.1.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.6.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (4.2.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.9)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.8.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2021.10.8)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install stop-words"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t-I7OQILPvGv",
        "outputId": "2aeb04e2-03a4-4342-9e82-0c459a52ff4b"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: stop-words in /usr/local/lib/python3.7/dist-packages (2018.7.23)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from transformers import BertTokenizer, BertModel\n",
        "from sklearn.datasets import fetch_20newsgroups\n",
        "import re\n",
        "from nltk.tokenize import word_tokenize\n",
        "import nltk\n",
        "import string\n",
        "nltk.download('punkt')\n",
        "from stop_words import get_stop_words\n",
        "stop_words = get_stop_words('en')\n",
        "    \n",
        "newsgroups_train = fetch_20newsgroups(subset='train')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8EJnBCguQeWE",
        "outputId": "ef07acfe-1cd1-42cb-dbb8-b0e20b678bc9"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Datenvorbearbeitung fÃ¼r BERT-Modell**"
      ],
      "metadata": {
        "id": "Hdos3ORw_Ec0"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "iX21MYTEObtF"
      },
      "outputs": [],
      "source": [
        "# read train_data from 20newsgroups\n",
        "def read_raw_documents():\n",
        "    raw_documents = []\n",
        "    raw_labels = []\n",
        "    for i in range(0,len(newsgroups_train.data)):\n",
        "        raw_documents.append(newsgroups_train.data[i])\n",
        "        raw_labels.append(newsgroups_train.target[i])\n",
        "    return raw_documents, raw_labels\n",
        "\n",
        "def simple_preprocess(raw_documents):\n",
        "    def only_letters(tested_string):\n",
        "        for letter in tested_string:\n",
        "            if letter not in \"abcdefghijklmnopqrstuvwxyz\":\n",
        "                return False\n",
        "        return True\n",
        "    def clean_doc_for_bert(doc): \n",
        "        doc = doc.replace(\">\",\"\").lower()\n",
        "        word_list = word_tokenize(doc) #only using empty space and punctation for tokenization\n",
        "        cleaned = []\n",
        "        for w in word_list:\n",
        "            if w not in stop_words:\n",
        "                if w in string.punctuation or only_letters(w): #using only character from punctation and alpha characters\n",
        "                    if w in string.punctuation or len( set(w) ) > 1: #punctation with len 1 allowed but alpha word must be longer then 1\n",
        "                        cleaned.append( w)\n",
        "        return \" \".join(cleaned), cleaned  #save doc in string and in token-list         \n",
        "       \n",
        "    cleaned_documents = []\n",
        "    for doc in raw_documents:\n",
        "        doc_in_string, doc_in_token_list = clean_doc_for_bert(doc)\n",
        "        cleaned_documents.append(doc_in_string)\n",
        "    return cleaned_documents\n",
        "\n",
        "def transform_to_sentences_with_labels():\n",
        "    # we will not use labels\n",
        "    sentences_with_labels = []\n",
        "    return sentences_with_labels\n",
        "\n",
        "def fine_tune_bert():\n",
        "    # should to be trained?\n",
        "    # no, because for topic modelling, that is usupervised problem. We just find topics for the documents\n",
        "    # topic modelling no targets\n",
        "    return True\n",
        "\n",
        "def transform_to_sentences(docs): #no labels\n",
        "    data_as_sentences = []\n",
        "    for doc in docs:\n",
        "      for sent in doc.split(\". \"): #make sentences\n",
        "        updated_sent = \" \".join([t for t in sent.split(\" \") if len(t) > 1])\n",
        "        if len(updated_sent.split(\" \")) > 1:\n",
        "            data_as_sentences.append(updated_sent)\n",
        "        else:\n",
        "            if updated_sent not in data_as_sentences:\n",
        "                data_as_sentences.append(updated_sent)\n",
        "    return data_as_sentences\n",
        "\n",
        "def split_long_sentence(splitted_sent, given_len):\n",
        "    subsents = []\n",
        "   #for i in range(0,len(splitted_sent), given_len):\n",
        "    i=0\n",
        "    while i < len(splitted_sent): \n",
        "        if i == 0:\n",
        "            sub = \" \".join(splitted_sent[i:i+given_len])\n",
        "            subsents.append(sub)\n",
        "            i = i + given_len\n",
        "        if i!=0:\n",
        "            j = i + given_len - 5 #windown 5\n",
        "            if j + given_len <= len(splitted_sent):\n",
        "                sub = \" \".join(splitted_sent[j:j + given_len])\n",
        "                subsents.append(sub)\n",
        "            else:\n",
        "                sub = \" \".join(splitted_sent[j:])\n",
        "                if len(sub)>1:\n",
        "                    subsents.append(sub)\n",
        "            i = j + given_len\n",
        "    return subsents\n",
        "\n",
        "def handle_long_sentences(sentences, given_len):\n",
        "    # overlapped splitting sentence windown 5\n",
        "    subsents = []\n",
        "    deleted_long_sents = []\n",
        "    for sent in sentences:\n",
        "        splitted_sent = sent.split(\" \")\n",
        "        if len(splitted_sent) > given_len:\n",
        "          long_sent_subsents = split_long_sentence(splitted_sent, given_len)\n",
        "          subsents.extend(long_sent_subsents)\n",
        "          deleted_long_sents.append(sent)\n",
        "    # update sentences: remove and add subsents\n",
        "    for del_sent in deleted_long_sents:\n",
        "        sentences.remove(del_sent)\n",
        "    for add_sent in subsents:\n",
        "        sentences.append(add_sent)\n",
        "    return sentences\n",
        "\n",
        "def create_marked_senteces(sentences):\n",
        "    return ['[CLS] ' + sent.strip() + ' [SEP]' for sent in sentences]\n",
        "def save_sents_to_txt(shorted_sentences):\n",
        "    with open(r'./bert_sentences.txt', 'w') as fp:\n",
        "      for sent in shorted_sentences:\n",
        "          # write each item on a new line\n",
        "          fp.write(f'{sent} \\n')\n",
        "      print('saving sentences from bert-processing')\n",
        "    return True"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"reading data:...\")\n",
        "raw_documents, _ = read_raw_documents()\n",
        "print(len(raw_documents))\n",
        "print(\"preprocess data:...\")\n",
        "preprocessed_docs = simple_preprocess(raw_documents)\n",
        "print(len(preprocessed_docs))\n",
        "print(\"transform to sentences:...\")\n",
        "sentences = transform_to_sentences(preprocessed_docs)\n",
        "print(\"split sentences to 128 tokens:...\")\n",
        "shorted_sentences =  handle_long_sentences(sentences, 128)\n",
        "marked_shorted_sentences = create_marked_senteces(shorted_sentences)\n",
        "# write sentences to txt files\n",
        "with open(r'bert_sentences.txt', 'w') as fp:\n",
        "    for sent in shorted_sentences:\n",
        "        # write each item on a new line\n",
        "        fp.write(f'{sent} \\n')\n",
        "    print('saving sentences from bert-processing')\n",
        "print(\"finished: ...\")\n",
        "\n"
      ],
      "metadata": {
        "id": "lBqLI7sVQPQ-",
        "outputId": "87d6c7f7-c5ab-4364-f631-8694a453cc4b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "reading data:...\n",
            "11314\n",
            "preprocess data:...\n",
            "11314\n",
            "transform to sentences:...\n",
            "split sentences to 128 tokens:...\n",
            "saving sentences from bert-processing\n",
            "finished: ...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Bert-Modell and Bert-TokenizerFast**"
      ],
      "metadata": {
        "id": "ktZVaf0YVDIF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import BertTokenizerFast, BertTokenizer\n",
        "from transformers import BertTokenizerFast\n",
        "\n",
        "tokenizerfast = BertTokenizerFast.from_pretrained('bert-base-uncased')\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
        "\n",
        "model = BertModel.from_pretrained('bert-base-uncased', output_hidden_states = True)\n",
        "model.eval()"
      ],
      "metadata": {
        "id": "scUleQQQXbJr",
        "outputId": "675e4fca-1a24-4966-a864-b22dea70d508",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.weight', 'cls.predictions.bias', 'cls.seq_relationship.bias', 'cls.predictions.decoder.weight']\n",
            "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BertModel(\n",
              "  (embeddings): BertEmbeddings(\n",
              "    (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
              "    (position_embeddings): Embedding(512, 768)\n",
              "    (token_type_embeddings): Embedding(2, 768)\n",
              "    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "    (dropout): Dropout(p=0.1, inplace=False)\n",
              "  )\n",
              "  (encoder): BertEncoder(\n",
              "    (layer): ModuleList(\n",
              "      (0): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (intermediate_act_fn): GELUActivation()\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (1): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (intermediate_act_fn): GELUActivation()\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (2): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (intermediate_act_fn): GELUActivation()\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (3): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (intermediate_act_fn): GELUActivation()\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (4): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (intermediate_act_fn): GELUActivation()\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (5): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (intermediate_act_fn): GELUActivation()\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (6): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (intermediate_act_fn): GELUActivation()\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (7): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (intermediate_act_fn): GELUActivation()\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (8): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (intermediate_act_fn): GELUActivation()\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (9): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (intermediate_act_fn): GELUActivation()\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (10): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (intermediate_act_fn): GELUActivation()\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (11): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (intermediate_act_fn): GELUActivation()\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (pooler): BertPooler(\n",
              "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "    (activation): Tanh()\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Funktionen fÃ¼r Bert-Embeddings**"
      ],
      "metadata": {
        "id": "28n_S3YdYngR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def tokenizerfast_for_a_sent(sent, tokenizer):\n",
        "  this_sent_tokenizer = tokenizer(sent)\n",
        "  # index of token in the vocabulary\n",
        "  indexed_tokens = this_sent_tokenizer.input_ids\n",
        "  segments_ids = [1] * len(indexed_tokens)\n",
        "  # Convert inputs to PyTorch tensors\n",
        "  tokens_tensor = torch.tensor([indexed_tokens])\n",
        "  segments_tensors = torch.tensor([segments_ids])\n",
        "  tokens_ids_with_belonging_information = this_sent_tokenizer.word_ids()\n",
        "  return tokens_tensor, segments_tensors, tokens_ids_with_belonging_information\n",
        "  \n",
        "def reform_token_embeddings_of_sentence(full_outputs):\n",
        "  hidden_states = outputs[2]\n",
        "  token_embeddings = torch.stack(hidden_states, dim=0)\n",
        "  #print(token_embeddings.shape)\n",
        "  token_embeddings = torch.squeeze(token_embeddings, dim=1) # size= (n_hidden_layers, n_tokens, 768)\n",
        "  #print(token_embeddings.shape)\n",
        "  token_embeddings = token_embeddings.permute(1,0,2) # size= (n_tokens, n_hidden_layers, 768)\n",
        "  #print(token_embeddings.shape)\n",
        "  return token_embeddings \n",
        "\n",
        "def get_token_embeddings(reformed_token_embeddings):\n",
        "  # using sum four last layers\n",
        "  token_vecs_sum = []\n",
        "  #print(f'get-token-embedding-function: {reformed_token_embeddings.shape}')\n",
        "  for i, token in enumerate(reformed_token_embeddings): \n",
        "    sum_vec = torch.sum(token[-4:], dim=0)\n",
        "    token_vecs_sum.append(sum_vec)\n",
        "    #print(f'original {token.shape} and token-emb after sum {sum_vec.shape}')\n",
        "  return token_vecs_sum # size: n_tokens: 768\n",
        "\n",
        "def get_subwords_embeddings_of_word(bert_unique_token_id, tokenized_indices, tokens_embeddings):\n",
        "    belongging_embeddings_of_word = []\n",
        "    for idx, tokenizer_idx in enumerate(tokenized_indices):\n",
        "        if tokenizer_idx == bert_unique_token_id:\n",
        "            belongging_embeddings_of_word.append(tokens_embeddings[idx])\n",
        "    return torch.stack(belongging_embeddings_of_word, dim=0)\n",
        "\n",
        "def get_unique_embedding(embeddings=None, methode=\"mean\"):\n",
        "    #print(embeddings[0].shape)\n",
        "    if methode == \"mean\":\n",
        "        if embeddings.shape[0] == 1:\n",
        "          return torch.squeeze(embeddings, dim=0)\n",
        "        else:\n",
        "          mean_embedding = torch.mean(embeddings, dim=0) #torch.tensor([embeddings])#.mean()\n",
        "          return mean_embedding\n",
        "\n",
        "def need_to_update(sent_tokens_ids):\n",
        "    special_ids = [101, 102] #of CLS and SEP\n",
        "    for e in sent_tokens_ids:\n",
        "        if e in special_ids:\n",
        "            sent_tokens_ids.remove(e)\n",
        "    return sent_tokens_ids\n",
        "  \n",
        "def get_multiple_embeddings_for_words_in_sent(sent_tokens_ids, sent_outputs_tokens_embeddings):\n",
        "    # a word can be one time oder multiple times in a sentence\n",
        "    #print(f'tokens-ids in get_multiple_embeddings_: {sent_tokens_ids}')\n",
        "    sent_tokens_ids = need_to_update(sent_tokens_ids)\n",
        "    multiple_words_embeddings = []\n",
        "    unique_words_ids = list(set(sent_tokens_ids))\n",
        "    for unique_id in unique_words_ids:\n",
        "        belong_embeddings = get_subwords_embeddings_of_word(unique_id, sent_tokens_ids, sent_outputs_tokens_embeddings)\n",
        "        print(f'word-id: {unique_id} - beling-embeddings shape: {belong_embeddings.shape}')\n",
        "        # mean of belonging_embeddings to get embedding of whole word\n",
        "        word_embedding = get_unique_embedding(belong_embeddings, \"mean\")\n",
        "        #print(f'mean-word-id {unique_id} word-embedding {word_embedding.shape}')\n",
        "        multiple_words_embeddings.append(word_embedding)\n",
        "        #print(\"----------------------------------------------------------\")\n",
        "    return torch.stack(multiple_words_embeddings, dim=0)\n",
        "\n",
        "def get_indices_of_word_in_original_sent(word, splitted_original_sent):\n",
        "    indices = []\n",
        "    for i, e in enumerate(splitted_original_sent):\n",
        "        if e == word:\n",
        "            indices.append(i)\n",
        "    return indices\n",
        "\n",
        "def get_final_words_embeddings_in_sent(original_sent, sent_tokens_ids, sent_outputs_tokens_embeddings):\n",
        "    #import numpy as np\n",
        "    print(f'sentence-tokenizerfast-word-ids: {sent_tokens_ids}')\n",
        "    not_unique_words_embeddings = get_multiple_embeddings_for_words_in_sent(sent_tokens_ids, sent_outputs_tokens_embeddings)\n",
        "    print(f'total found embeddings in sent: {not_unique_words_embeddings.shape}')\n",
        "    original_words_list = original_sent.split(\" \")\n",
        "    print(f'original-splitted: {original_words_list}')\n",
        "    set_original_words_list = []\n",
        "    for e in original_words_list:\n",
        "        if e not in set_original_words_list:\n",
        "            set_original_words_list.append(e) #[e for e in original_sent if e not in ]\n",
        "    words_embeddings_in_sent_dict = {}\n",
        "    for word in set_original_words_list:\n",
        "        if word not in ['[CLS]', '[SEP]']:\n",
        "          word_indices = get_indices_of_word_in_original_sent(word, original_words_list)\n",
        "          print(f'word---- {word} ---- indices in original sent: {word_indices}')\n",
        "          # a word can have different-word-embeddings in the sentence, because a word can occur multple times\n",
        "          # each occurance has a different embedding for this word\n",
        "          different_occurrences_embeddings_of_word = not_unique_words_embeddings[word_indices]\n",
        "          print(f'test: {different_occurrences_embeddings_of_word.shape}')\n",
        "          mean_unique_word_embedding = get_unique_embedding(torch.tensor(different_occurrences_embeddings_of_word), \"mean\")\n",
        "          words_embeddings_in_sent_dict[word] = mean_unique_word_embedding\n",
        "    return words_embeddings_in_sent_dict\n",
        "\n",
        "def save_embeddings_in_sent_to_text(sent_id, words_embeddings_in_sent_dict):\n",
        "    with open(f'./sent_{str(sent_id)}_words_embeddings.txt', 'w') as fp:\n",
        "        for word, vector in words_embeddings_in_sent_dict.items():\n",
        "            # write each item on a new line\n",
        "            fp.write(f'{word}\\t')\n",
        "            for e in vector.tolist():\n",
        "                fp.write(f'{e} ')\n",
        "            fp.write(\"\\n\")\n",
        "        print('saving embeddings')\n",
        "    return True\n",
        "\n",
        "def save_embeddings_to_text(words_embeddings_in_sent_dict):\n",
        "    with open(r'./bert_words_embeddings.txt', 'a') as fp:\n",
        "      for word, vector in words_embeddings_in_sent_dict.items():\n",
        "          fp.write(f'{word}\\t')\n",
        "          for e in vector.tolist():\n",
        "            fp.write(f'{e} ')\n",
        "          fp.write(\"\\n\")\n",
        "      print('saving embeddings')\n",
        "    return True\n",
        "\n",
        "def vocabulary_embeddings_to_text(vocab_embeddings):\n",
        "    with open(r'./bert_vocab_embeddings.txt', 'w') as fp:\n",
        "      for word, vector in vocab_embeddings.items():\n",
        "          fp.write(f'{word}\\t')\n",
        "          for e in vector.tolist():\n",
        "            fp.write(f'{e} ')\n",
        "          fp.write(\"\\n\")\n",
        "      print('saving embeddings')\n",
        "    return True"
      ],
      "metadata": {
        "id": "blyG2KaZWn2C"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **BertTokenizerFast**"
      ],
      "metadata": {
        "id": "EzlHez2rm3yE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ex_sent = marked_shorted_sentences[0]\n",
        "tokens_tensor, segments_tensors, tokens_ids_with_belonging_information = tokenizerfast_for_a_sent(ex_sent, tokenizerfast)\n",
        "\n",
        "with torch.no_grad():\n",
        "    outputs = model(tokens_tensor, segments_tensors)\n",
        "    reformed = reform_token_embeddings_of_sentence(outputs)\n",
        "    sent_tokens_embeddings = get_token_embeddings(reformed)\n",
        "    print(f'number of found embeddings: {len(sent_tokens_embeddings)}')\n",
        "    words_embeddings_in_sent_dict = get_final_words_embeddings_in_sent(ex_sent, tokens_ids_with_belonging_information, sent_tokens_embeddings)\n",
        "    save_embeddings_in_sent_to_text(0, words_embeddings_in_sent_dict)\n",
        "  "
      ],
      "metadata": {
        "id": "uz7IQKoQgQny",
        "outputId": "51eecba4-6146-4cb8-9059-90923fe64555",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "number of found embeddings: 25\n",
            "sentence-tokenizerfast-word-ids: [None, 0, 1, 1, 1, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 13, 13, 14, 15, 16, 17, None]\n",
            "word-id: 0 - beling-embeddings shape: torch.Size([1, 768])\n",
            "word-id: 1 - beling-embeddings shape: torch.Size([4, 768])\n",
            "word-id: 2 - beling-embeddings shape: torch.Size([1, 768])\n",
            "word-id: 3 - beling-embeddings shape: torch.Size([1, 768])\n",
            "word-id: 4 - beling-embeddings shape: torch.Size([1, 768])\n",
            "word-id: 5 - beling-embeddings shape: torch.Size([1, 768])\n",
            "word-id: 6 - beling-embeddings shape: torch.Size([1, 768])\n",
            "word-id: 7 - beling-embeddings shape: torch.Size([1, 768])\n",
            "word-id: 8 - beling-embeddings shape: torch.Size([1, 768])\n",
            "word-id: 9 - beling-embeddings shape: torch.Size([1, 768])\n",
            "word-id: 10 - beling-embeddings shape: torch.Size([1, 768])\n",
            "word-id: 11 - beling-embeddings shape: torch.Size([1, 768])\n",
            "word-id: 12 - beling-embeddings shape: torch.Size([1, 768])\n",
            "word-id: 13 - beling-embeddings shape: torch.Size([3, 768])\n",
            "word-id: 14 - beling-embeddings shape: torch.Size([1, 768])\n",
            "word-id: 15 - beling-embeddings shape: torch.Size([1, 768])\n",
            "word-id: 16 - beling-embeddings shape: torch.Size([1, 768])\n",
            "word-id: 17 - beling-embeddings shape: torch.Size([1, 768])\n",
            "word-id: None - beling-embeddings shape: torch.Size([2, 768])\n",
            "total found embeddings in sent: torch.Size([19, 768])\n",
            "original-splitted: ['[CLS]', 'lerxst', 'thing', 'subject', 'car', 'organization', 'university', 'maryland', 'college', 'park', 'lines', 'wondering', 'anyone', 'enlighten', 'car', 'saw', 'day', '[SEP]']\n",
            "word---- lerxst ---- indices in original sent: [1]\n",
            "test: torch.Size([1, 768])\n",
            "word---- thing ---- indices in original sent: [2]\n",
            "test: torch.Size([1, 768])\n",
            "word---- subject ---- indices in original sent: [3]\n",
            "test: torch.Size([1, 768])\n",
            "word---- car ---- indices in original sent: [4, 14]\n",
            "test: torch.Size([2, 768])\n",
            "word---- organization ---- indices in original sent: [5]\n",
            "test: torch.Size([1, 768])\n",
            "word---- university ---- indices in original sent: [6]\n",
            "test: torch.Size([1, 768])\n",
            "word---- maryland ---- indices in original sent: [7]\n",
            "test: torch.Size([1, 768])\n",
            "word---- college ---- indices in original sent: [8]\n",
            "test: torch.Size([1, 768])\n",
            "word---- park ---- indices in original sent: [9]\n",
            "test: torch.Size([1, 768])\n",
            "word---- lines ---- indices in original sent: [10]\n",
            "test: torch.Size([1, 768])\n",
            "word---- wondering ---- indices in original sent: [11]\n",
            "test: torch.Size([1, 768])\n",
            "word---- anyone ---- indices in original sent: [12]\n",
            "test: torch.Size([1, 768])\n",
            "word---- enlighten ---- indices in original sent: [13]\n",
            "test: torch.Size([1, 768])\n",
            "word---- saw ---- indices in original sent: [15]\n",
            "test: torch.Size([1, 768])\n",
            "word---- day ---- indices in original sent: [16]\n",
            "test: torch.Size([1, 768])\n",
            "saving embeddings\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:98: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vocab = {}\n",
        "\n",
        "for marked_sent in marked_shorted_sentences[:2]:\n",
        "  print(marked_sent)\n",
        "  tokens_tensor, segments_tensors, tokens_ids_with_belonging_information = tokenizerFast_for_a_sent(marked_sent, tokenizerfast)\n",
        "  with torch.no_grad():\n",
        "      outputs = model(tokens_tensor, segments_tensors)\n",
        "      reformed = reform_token_embeddings_of_sentence(outputs)\n",
        "      sent_tokens_embeddings = get_token_embeddings(reformed)\n",
        "      print(f'number of found embeddings: {len(sent_tokens_embeddings)}')\n",
        "      words_embeddings_in_sent_dict = get_final_words_embeddings_in_sent(marked_sent, tokens_ids_with_belonging_information, sent_tokens_embeddings)\n",
        "      save_embeddings_to_text(words_embeddings_in_sent_dict)\n",
        "      for word, vector in words_embeddings_in_sent_dict.items():\n",
        "        #print(word)\n",
        "        if word in vocab.keys():\n",
        "          #print(vector[:2])\n",
        "          sum_vector = vocab[word][1] + vector\n",
        "          #print(sum_vector)\n",
        "          count = vocab[word][0] + 1\n",
        "          vocab[word] = (count, sum_vector)\n",
        "        else:\n",
        "          #print(vector[:2])\n",
        "          vocab[word] = (1, vector)\n",
        "\n",
        "      del tokens_tensor\n",
        "      del segments_tensors\n",
        "      del outputs\n",
        "      del reformed\n",
        "      del sent_tokens_embeddings\n",
        "      del words_embeddings_in_sent_dict\n",
        "  print(\"---------------------------------------------------------------------------------------\")\n",
        "\n",
        "#update vocab over all sentences\n",
        "updated_vocab = {}\n",
        "for word, (count, sum_vector) in vocab.items():\n",
        "  updated_vocab[word] = (sum_vector/count)\n",
        "vocabulary_embeddings_to_text(updated_vocab)"
      ],
      "metadata": {
        "id": "ZCyXezVQDc2y",
        "outputId": "175df2e5-99c2-49ff-ba0d-2411303be6eb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CLS] lerxst thing subject car organization university maryland college park lines wondering anyone enlighten car saw day [SEP]\n",
            "number of found embeddings: 25\n",
            "sentence-tokenizerfast-word-ids: [None, 0, 1, 1, 1, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 13, 13, 14, 15, 16, 17, None]\n",
            "word-id: 0 - beling-embeddings shape: torch.Size([1, 768])\n",
            "word-id: 1 - beling-embeddings shape: torch.Size([4, 768])\n",
            "word-id: 2 - beling-embeddings shape: torch.Size([1, 768])\n",
            "word-id: 3 - beling-embeddings shape: torch.Size([1, 768])\n",
            "word-id: 4 - beling-embeddings shape: torch.Size([1, 768])\n",
            "word-id: 5 - beling-embeddings shape: torch.Size([1, 768])\n",
            "word-id: 6 - beling-embeddings shape: torch.Size([1, 768])\n",
            "word-id: 7 - beling-embeddings shape: torch.Size([1, 768])\n",
            "word-id: 8 - beling-embeddings shape: torch.Size([1, 768])\n",
            "word-id: 9 - beling-embeddings shape: torch.Size([1, 768])\n",
            "word-id: 10 - beling-embeddings shape: torch.Size([1, 768])\n",
            "word-id: 11 - beling-embeddings shape: torch.Size([1, 768])\n",
            "word-id: 12 - beling-embeddings shape: torch.Size([1, 768])\n",
            "word-id: 13 - beling-embeddings shape: torch.Size([3, 768])\n",
            "word-id: 14 - beling-embeddings shape: torch.Size([1, 768])\n",
            "word-id: 15 - beling-embeddings shape: torch.Size([1, 768])\n",
            "word-id: 16 - beling-embeddings shape: torch.Size([1, 768])\n",
            "word-id: 17 - beling-embeddings shape: torch.Size([1, 768])\n",
            "word-id: None - beling-embeddings shape: torch.Size([2, 768])\n",
            "total found embeddings in sent: torch.Size([19, 768])\n",
            "original-splitted: ['[CLS]', 'lerxst', 'thing', 'subject', 'car', 'organization', 'university', 'maryland', 'college', 'park', 'lines', 'wondering', 'anyone', 'enlighten', 'car', 'saw', 'day', '[SEP]']\n",
            "word---- lerxst ---- indices in original sent: [1]\n",
            "test: torch.Size([1, 768])\n",
            "word---- thing ---- indices in original sent: [2]\n",
            "test: torch.Size([1, 768])\n",
            "word---- subject ---- indices in original sent: [3]\n",
            "test: torch.Size([1, 768])\n",
            "word---- car ---- indices in original sent: [4, 14]\n",
            "test: torch.Size([2, 768])\n",
            "word---- organization ---- indices in original sent: [5]\n",
            "test: torch.Size([1, 768])\n",
            "word---- university ---- indices in original sent: [6]\n",
            "test: torch.Size([1, 768])\n",
            "word---- maryland ---- indices in original sent: [7]\n",
            "test: torch.Size([1, 768])\n",
            "word---- college ---- indices in original sent: [8]\n",
            "test: torch.Size([1, 768])\n",
            "word---- park ---- indices in original sent: [9]\n",
            "test: torch.Size([1, 768])\n",
            "word---- lines ---- indices in original sent: [10]\n",
            "test: torch.Size([1, 768])\n",
            "word---- wondering ---- indices in original sent: [11]\n",
            "test: torch.Size([1, 768])\n",
            "word---- anyone ---- indices in original sent: [12]\n",
            "test: torch.Size([1, 768])\n",
            "word---- enlighten ---- indices in original sent: [13]\n",
            "test: torch.Size([1, 768])\n",
            "word---- saw ---- indices in original sent: [15]\n",
            "test: torch.Size([1, 768])\n",
            "word---- day ---- indices in original sent: [16]\n",
            "test: torch.Size([1, 768])\n",
            "saving embeddings\n",
            "---------------------------------------------------------------------------------------\n",
            "[CLS] sports car looked late early [SEP]\n",
            "number of found embeddings: 9\n",
            "sentence-tokenizerfast-word-ids: [None, 0, 1, 2, 3, 4, 5, 6, None]\n",
            "word-id: 0 - beling-embeddings shape: torch.Size([1, 768])\n",
            "word-id: 1 - beling-embeddings shape: torch.Size([1, 768])\n",
            "word-id: 2 - beling-embeddings shape: torch.Size([1, 768])\n",
            "word-id: 3 - beling-embeddings shape: torch.Size([1, 768])\n",
            "word-id: 4 - beling-embeddings shape: torch.Size([1, 768])\n",
            "word-id: 5 - beling-embeddings shape: torch.Size([1, 768])\n",
            "word-id: None - beling-embeddings shape: torch.Size([2, 768])\n",
            "word-id: 6 - beling-embeddings shape: torch.Size([1, 768])\n",
            "total found embeddings in sent: torch.Size([8, 768])\n",
            "original-splitted: ['[CLS]', 'sports', 'car', 'looked', 'late', 'early', '[SEP]']\n",
            "word---- sports ---- indices in original sent: [1]\n",
            "test: torch.Size([1, 768])\n",
            "word---- car ---- indices in original sent: [2]\n",
            "test: torch.Size([1, 768])\n",
            "word---- looked ---- indices in original sent: [3]\n",
            "test: torch.Size([1, 768])\n",
            "word---- late ---- indices in original sent: [4]\n",
            "test: torch.Size([1, 768])\n",
            "word---- early ---- indices in original sent: [5]\n",
            "test: torch.Size([1, 768])\n",
            "saving embeddings\n",
            "---------------------------------------------------------------------------------------\n",
            "saving embeddings\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:98: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **BertTokenizer**"
      ],
      "metadata": {
        "id": "obsA4Eirmzp0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# using BertTokenizer\n",
        "tokens = tokenizer.tokenize(ex_sent)\n",
        "print(tokens)\n",
        "print(len(tokens))\n",
        "indexed_tokens = tokenizer.convert_tokens_to_ids(tokens)\n",
        "print(indexed_tokens)\n",
        "segments_ids = [1] * len(tokens)\n",
        "print(segments_ids)\n",
        "tokens_tensor = torch.tensor([indexed_tokens])\n",
        "segments_tensors = torch.tensor([segments_ids])\n",
        "with torch.no_grad():\n",
        "    outputs = model(tokens_tensor, segments_tensors)\n",
        "    hidden_states = outputs[2]\n",
        "    print(len(hidden_states))\n",
        "    #token_embeddings = torch.stack(hidden_states, dim=0)\n",
        "    #print(token_embeddings.size())\n",
        "    #token_embeddings = torch.squeeze(token_embeddings, dim=1)\n",
        "    #print(token_embeddings.size())\n",
        "    #print(hidden_states.shape)\n",
        "# using BertTokenizerFast\n",
        "    reformed = reform_token_embeddings_of_sentence(outputs)\n",
        "    sent_tokens_embeddings = get_token_embeddings(reformed)"
      ],
      "metadata": {
        "id": "i327MIAIYxvz",
        "outputId": "d7cb5b17-65f9-4089-f8ec-0a76094b03ea",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['[CLS]', 'le', '##r', '##x', '##st', 'thing', 'subject', 'car', 'organization', 'university', 'maryland', 'college', 'park', 'lines', 'wondering', 'anyone', 'en', '##light', '##en', 'car', 'saw', 'day', '[SEP]']\n",
            "23\n",
            "[101, 3393, 2099, 2595, 3367, 2518, 3395, 2482, 3029, 2118, 5374, 2267, 2380, 3210, 6603, 3087, 4372, 7138, 2368, 2482, 2387, 2154, 102]\n",
            "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
            "13\n"
          ]
        }
      ]
    }
  ]
}