{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Topic-Modelling mit LDA\n",
    "\n",
    "1. F체r Topic Modelling mit LDA benutzen wir das Paket: `gensim.models.LdaModel`\n",
    "2. Die benutzten Funktionen f체r die Vorbereitung von Daten wurden in dem Ordner: `src\\prepare_data.py`\n",
    "    - Rohdaten wurden von dem sklearn aufgerufen `load_tokenize_texts()`und vorverarbeitet: `preprocess_text()`\n",
    "    - Das Vocabular wurden von dem Trainset erstellt\n",
    "    - Die Bags-Of-Words Repr채sentationen wurden in `split_and_create_voca_from_trainset` erstellt\n",
    "3. Die benutzen Funktionen f체r Evaluation befinden sich in `src/evaluierung.py`:\n",
    "    - Topic Coherence\n",
    "    - Topic Diversity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import clear_output\n",
    "import pandas as pd\n",
    "from gensim.parsing.preprocessing import preprocess_string, strip_punctuation, strip_numeric\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "import gensim\n",
    "from gensim.models import LdaModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.prepare_dataset import TextDataLoader\n",
    "from src.evaluierung import topicCoherence2, topicDiversity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(min_df):\n",
    "    stopwords_filter = True\n",
    "    textsloader = TextDataLoader(source=\"20newsgroups\", \n",
    "                             train_size=None, test_size=None)\n",
    "    textsloader.load_tokenize_texts(\"20newsgroups\")\n",
    "    textsloader.preprocess_texts(length_one_remove=True, \n",
    "                                 punctuation_lower = True, \n",
    "                                 stopwords_filter = stopwords_filter)\n",
    "    textsloader.split_and_create_voca_from_trainset(max_df=0.7, min_df=min_df, \n",
    "                                                    stopwords_remove_from_voca=stopwords_filter)\n",
    "\n",
    "    for_lda_model = True\n",
    "    word2id, id2word, train_set, test_set, val_set = textsloader.create_bow_and_savebow_for_each_set(for_lda_model=for_lda_model, \n",
    "                                                                                                     normalize = True)\n",
    "    docs_tr, _, _ = textsloader.get_docs_in_words_for_each_set()\n",
    "    textsloader.write_info_vocab_to_text()\n",
    "    del textsloader\n",
    "    return docs_tr, train_set, id2word\n",
    "\n",
    "def get_lda_topics(train_set, id2word, num_topics):\n",
    "    myid2word = id2word\n",
    "    ldamodel = LdaModel(train_set, num_topics= num_topics, id2word = id2word, random_state = 42)\n",
    "    lda_topics = ldamodel.show_topics(num_topics= num_topics, num_words=25)\n",
    "    topics = []\n",
    "    filters = [lambda x: x.lower(), strip_punctuation, strip_numeric]\n",
    "    for topic in lda_topics:\n",
    "        topics.append(preprocess_string(topic[1], filters))\n",
    "    del ldamodel\n",
    "    del lda_topics\n",
    "    return topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading texts: ...\n",
      "train-size after loading: 11314\n",
      "test-size after loading: 7532\n",
      "finished load!\n",
      "start: preprocessing: ...\n",
      "finised: preprocessing!\n",
      "vocab-size in df: 57326\n",
      "start creating vocabulary ...\n",
      "length of the vocabulary: 54318\n",
      "length word2id list: 54318\n",
      "length id2word list: 54318\n",
      "finished: creating vocabulary\n",
      "train-size-after-all: 11214\n",
      "test-size-after-all: 7532\n",
      "validation-size-after-all: 100\n",
      "test-size-after-all: 11214\n",
      "test-indices-length: 11214\n",
      "test-size-after-all: 100\n",
      "test-indices-length: 100\n",
      "test-size-after-all: 7532\n",
      "test-indices-length: 7532\n",
      "length train-documents-indices : 1420825\n",
      "length of the vocabulary: 54318\n",
      "\n",
      "\n",
      "start: creating bow representation...\n",
      "finised creating bow input!\n",
      "\n",
      "start: creating bow representation...\n",
      "finised creating bow input!\n",
      "\n",
      "start: creating bow representation...\n",
      "finised creating bow input!\n",
      "\n",
      "start: creating bow representation...\n",
      "finised creating bow input!\n",
      "\n",
      "start: creating bow representation...\n",
      "finised creating bow input!\n",
      "\n",
      "compact representation for LDA\n",
      "topic: 0 writes article posting host nntp university car good time access sale cs distribution ca problem make gatech usa year back health work net people number\n",
      "topic: 1 max turkish armenians armenian pl jews wm armenia turks jewish argic serdar sl chz ottoman muslim greek russian writes giz soviet paragraph zuma mr genocide\n",
      "topic: 2 writes article posting nntp host cs pitt caltech reply gordon university problem banks gary gamma geb computer cover good ca system myers halat cc keith\n",
      "topic: 3 people god writes article time good christian make university world question things bible point christians religion church true read fact cs posting ca human thing\n",
      "topic: 4 key clipper encryption public government chip israel information article keys university writes israeli ripem people security technology data number cramer arab mail system list algorithm\n",
      "topic: 5 article writes posting university nntp host people distribution world ca time news cs kuwait state make reply good sun ac car usa cc uk point\n",
      "topic: 6 people writes article university posting host nntp state time scsi mr government gun drive president good year make fire fbi cs day distribution back usa\n",
      "topic: 7 space nasa writes article god gov posting people host nntp university time life jesus henry good christ make earth day toronto world org years hell\n",
      "topic: 8 pit game team det hockey ca season bos win writes university chi nhl tor play buffalo period article nntp games cal host posting la year\n",
      "topic: 9 windows system file dos university software pc drive graphics host posting program ca problem nntp computer window version data mail files card disk writes work\n",
      "loading texts: ...\n",
      "train-size after loading: 11314\n",
      "test-size after loading: 7532\n",
      "finished load!\n",
      "start: preprocessing: ...\n",
      "finised: preprocessing!\n",
      "vocab-size in df: 29915\n",
      "start creating vocabulary ...\n",
      "length of the vocabulary: 29874\n",
      "length word2id list: 29874\n",
      "length id2word list: 29874\n",
      "finished: creating vocabulary\n",
      "train-size-after-all: 11214\n",
      "test-size-after-all: 7532\n",
      "validation-size-after-all: 100\n",
      "test-size-after-all: 11214\n",
      "test-indices-length: 11214\n",
      "test-size-after-all: 100\n",
      "test-indices-length: 100\n",
      "test-size-after-all: 7532\n",
      "test-indices-length: 7532\n",
      "length train-documents-indices : 1362298\n",
      "length of the vocabulary: 29874\n",
      "\n",
      "\n",
      "start: creating bow representation...\n",
      "finised creating bow input!\n",
      "\n",
      "start: creating bow representation...\n",
      "finised creating bow input!\n",
      "\n",
      "start: creating bow representation...\n",
      "finised creating bow input!\n",
      "\n",
      "start: creating bow representation...\n",
      "finised creating bow input!\n",
      "\n",
      "start: creating bow representation...\n",
      "finised creating bow input!\n",
      "\n",
      "compact representation for LDA\n",
      "topic: 0 max scsi pl wm sl chz giz ide bxn isa okz mr bhj bus hb mq key gk bj ah halat mu tm mb fij\n",
      "topic: 1 people armenians armenian turkish university armenia government world greek article killed turks history writes time work russian argic serdar jews soviet war years muslim muslims\n",
      "topic: 2 pit det university games bos ca win buffalo chi season team tor posting writes nntp game cal host van play hockey period st la mon\n",
      "topic: 3 writes israel university article nasa ca israeli kuwait arab posting gov host uk nntp jews people time center cs ac gm reply arabs research org\n",
      "topic: 4 key writes article people time good government make posting game university clipper host nntp chip president mr encryption cs year back work public computer ca\n",
      "topic: 5 writes article posting university host people nntp cs sgi year time good virginia world medical uiuc make years jon baseball frank study msg system disease\n",
      "topic: 6 windows system file dos software posting university host data program nntp graphics ca problem pc mail computer version files window time work writes card information\n",
      "topic: 7 writes article posting nntp host car university state people distribution time good usa bike back ca reply ohio org cwru make news bill cleveland cs\n",
      "topic: 8 god people writes article jesus life christian time good bible things make christ point christians human church love university question religion read true law world\n",
      "topic: 9 drive sun university article posting space host nntp writes ibm drives world distribution cs scsi hard ide slave science information nasa power work people state\n",
      "loading texts: ...\n",
      "train-size after loading: 11314\n",
      "test-size after loading: 7532\n",
      "finished load!\n",
      "start: preprocessing: ...\n",
      "finised: preprocessing!\n",
      "vocab-size in df: 18677\n",
      "start creating vocabulary ...\n",
      "length of the vocabulary: 18677\n",
      "length word2id list: 18677\n",
      "length id2word list: 18677\n",
      "finished: creating vocabulary\n",
      "train-size-after-all: 11214\n",
      "test-size-after-all: 7532\n",
      "validation-size-after-all: 100\n",
      "test-size-after-all: 11214\n",
      "test-indices-length: 11214\n",
      "test-size-after-all: 100\n",
      "test-indices-length: 100\n",
      "test-size-after-all: 7532\n",
      "test-indices-length: 7532\n",
      "length train-documents-indices : 1299485\n",
      "length of the vocabulary: 18677\n",
      "\n",
      "\n",
      "start: creating bow representation...\n",
      "finised creating bow input!\n",
      "\n",
      "start: creating bow representation...\n",
      "finised creating bow input!\n",
      "\n",
      "start: creating bow representation...\n",
      "finised creating bow input!\n",
      "\n",
      "start: creating bow representation...\n",
      "finised creating bow input!\n",
      "\n",
      "start: creating bow representation...\n",
      "finised creating bow input!\n",
      "\n",
      "compact representation for LDA\n",
      "topic: 0 god people jesus writes bible christian christ church time christians article faith life love good world things religion man christianity university book read jewish de\n",
      "topic: 1 writes article university posting host nntp car state good distribution time work space usa power back make cs bike henry ohio nasa problem long toronto\n",
      "topic: 2 people article writes time gun mr government president make children armenians law armenian made guns rights fire world work good years things fbi kuwait day\n",
      "topic: 3 max game team year pit games university writes season hockey det win article players pl league play baseball bos good cs ca time chi tor\n",
      "topic: 4 key writes clipper chip posting encryption article host nntp government cs keys system access public org andrew computer des information cmu people technology ripem security\n",
      "topic: 5 posting university nntp host window font washington csd pat fonts people time writes harris article question mit problem find utexas rwing reply event usl cs\n",
      "topic: 6 windows drive system file software dos university program pc host data posting mail nntp graphics computer scsi problem ac version disk ca writes files mac\n",
      "topic: 7 writes article ca posting university nntp people host cs cc time reply canada world make sandvik caltech opinions indiana good hp post columbia sun apple\n",
      "topic: 8 writes article people israel university posting host nntp cleveland israeli case jews point world objective sgi state morality arab make time drugs cwru freenet moral\n",
      "topic: 9 article posting card host nntp writes university stratus drivers bus reply windows cs harvard problem gov ti driver sw cards nasa computer bit bill video\n",
      "loading texts: ...\n",
      "train-size after loading: 11314\n",
      "test-size after loading: 7532\n",
      "finished load!\n",
      "start: preprocessing: ...\n",
      "finised: preprocessing!\n",
      "vocab-size in df: 8496\n",
      "start creating vocabulary ...\n",
      "length of the vocabulary: 8496\n",
      "length word2id list: 8496\n",
      "length id2word list: 8496\n",
      "finished: creating vocabulary\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train-size-after-all: 11214\n",
      "test-size-after-all: 7532\n",
      "validation-size-after-all: 100\n",
      "test-size-after-all: 11214\n",
      "test-indices-length: 11214\n",
      "test-size-after-all: 100\n",
      "test-indices-length: 100\n",
      "test-size-after-all: 7532\n",
      "test-indices-length: 7532\n",
      "length train-documents-indices : 1150368\n",
      "length of the vocabulary: 8496\n",
      "\n",
      "\n",
      "start: creating bow representation...\n",
      "finised creating bow input!\n",
      "\n",
      "start: creating bow representation...\n",
      "finised creating bow input!\n",
      "\n",
      "start: creating bow representation...\n",
      "finised creating bow input!\n",
      "\n",
      "start: creating bow representation...\n",
      "finised creating bow input!\n",
      "\n",
      "start: creating bow representation...\n",
      "finised creating bow input!\n",
      "\n",
      "compact representation for LDA\n",
      "topic: 0 max university posting nntp writes host article pl colorado washington wm uiuc ca distribution sl cso hp edm db de time se alaska cars apr\n",
      "topic: 1 mr writes people article president time kuwait university org key government cs back state posting made nntp host law good question fbi years today day\n",
      "topic: 2 writes article posting host nntp ca university distribution bike back access time good system reply usa car make cc computer net sgi world people digex\n",
      "topic: 3 armenians jews armenian world university israel turkish people jewish article posting writes war host nntp arab muslims ca israeli armenia sun muslim turks time arabs\n",
      "topic: 4 god people writes jesus article christian life time bible christ christians church good make point things religion faith true love christianity world man fact truth\n",
      "topic: 5 game writes team article year key university pit ca games good clipper hockey encryption season win cs posting host time det chip nntp players play\n",
      "topic: 6 people writes article gun government time make good guns police university years state rights control point american posting law thing batf medical work number health\n",
      "topic: 7 nasa writes space article gov university state henry ohio posting uk toronto virginia distribution nntp host world netcom acs news information magnus research center ibm\n",
      "topic: 8 university sale power list cs information distribution computer mail posting price file system shipping radio host usa work send time nntp cd make mil box\n",
      "topic: 9 windows drive system posting dos software host nntp file university problem data graphics program pc mail version article window bit writes scsi computer card disk\n",
      "loading texts: ...\n",
      "train-size after loading: 11314\n",
      "test-size after loading: 7532\n",
      "finished load!\n",
      "start: preprocessing: ...\n",
      "finised: preprocessing!\n",
      "vocab-size in df: 3102\n",
      "start creating vocabulary ...\n",
      "length of the vocabulary: 3102\n",
      "length word2id list: 3102\n",
      "length id2word list: 3102\n",
      "finished: creating vocabulary\n",
      "train-size-after-all: 11214\n",
      "test-size-after-all: 7532\n",
      "validation-size-after-all: 100\n",
      "test-size-after-all: 11214\n",
      "test-indices-length: 11214\n",
      "test-size-after-all: 100\n",
      "test-indices-length: 100\n",
      "test-size-after-all: 7532\n",
      "test-indices-length: 7532\n",
      "length train-documents-indices : 896087\n",
      "length of the vocabulary: 3102\n",
      "\n",
      "\n",
      "start: creating bow representation...\n",
      "finised creating bow input!\n",
      "\n",
      "start: creating bow representation...\n",
      "finised creating bow input!\n",
      "\n",
      "start: creating bow representation...\n",
      "finised creating bow input!\n",
      "\n",
      "start: creating bow representation...\n",
      "finised creating bow input!\n",
      "\n",
      "start: creating bow representation...\n",
      "finised creating bow input!\n",
      "\n",
      "compact representation for LDA\n",
      "topic: 0 nasa gov space data file window information graphics program image ohio time state code software line posting host writes files system nntp problem center systems\n",
      "topic: 1 university de turkish armenians armenian writes posting host nntp world article se distribution uni armenia ed work turks argic system serdar drive power sale germany\n",
      "topic: 2 key clipper chip encryption posting government keys system host nntp public writes information university phone netcom security article des computer cleveland mail message algorithm pgp\n",
      "topic: 3 article writes people gun space israel time president government jews police years state rights work israeli war arab back military american day university killed posting\n",
      "topic: 4 people god writes article time jesus life christian good point make things bible church world question christ christians fact made religion man true love evidence\n",
      "topic: 5 max mit university writes article mr file virginia indiana motif gatech widget host posting nntp program xv internet georgia ai hp set uk mail ftp\n",
      "topic: 6 ca article ibm writes university health sun canada research posting nntp host news number cs medical reply insurance radio distribution world care time questions austin\n",
      "topic: 7 writes article game year university posting team host nntp good time people ca games cs win hockey season toronto play back players baseball make league\n",
      "topic: 8 windows posting host nntp drive university writes dos article system cs computer pc software scsi card version distribution problem ac mail reply work uk disk\n",
      "topic: 9 writes article car posting university host nntp cc uiuc good cars people time mail rochester reply cs distribution engine make science world price cso state\n"
     ]
    }
   ],
   "source": [
    "num_topics = 10\n",
    "min_dfs = [2,5,10,30,100]\n",
    "\n",
    "df = pd.DataFrame()\n",
    "df['min_df'] = min_dfs\n",
    "vocab_sizes = []\n",
    "coherences = []\n",
    "diversities = []\n",
    "\n",
    "for min_df in min_dfs:\n",
    "    print(100*\"-\")\n",
    "    docs_tr, train_set, id2word = get_data(min_df)\n",
    "    vocab_sizes.append(len(id2word.keys()))\n",
    "    topics = get_lda_topics(train_set, id2word, num_topics)\n",
    "    for i, topic in enumerate(topics):\n",
    "        ws = \" \".join(topic)\n",
    "        print(f'topic: {i} {ws}')\n",
    "    tc = topicCoherence2(topics,len(topics),docs_tr,len(docs_tr))\n",
    "    td = topicDiversity(topics)\n",
    "    coherences.append(tc)\n",
    "    diversities.append(td)\n",
    "    print(100*\"-\")\n",
    "    \n",
    "df['vocab_size'] = vocab_sizes\n",
    "df['coherence'] = coherences\n",
    "df['diversity'] = diversities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>min_df</th>\n",
       "      <th>vocab_size</th>\n",
       "      <th>coherence</th>\n",
       "      <th>diversity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>54318</td>\n",
       "      <td>0.140694</td>\n",
       "      <td>0.608</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>29874</td>\n",
       "      <td>0.143413</td>\n",
       "      <td>0.640</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10</td>\n",
       "      <td>18677</td>\n",
       "      <td>0.162169</td>\n",
       "      <td>0.664</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>30</td>\n",
       "      <td>8496</td>\n",
       "      <td>0.125755</td>\n",
       "      <td>0.632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>100</td>\n",
       "      <td>3102</td>\n",
       "      <td>0.130940</td>\n",
       "      <td>0.636</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   min_df  vocab_size  coherence  diversity\n",
       "0       2       54318   0.140694      0.608\n",
       "1       5       29874   0.143413      0.640\n",
       "2      10       18677   0.162169      0.664\n",
       "3      30        8496   0.125755      0.632\n",
       "4     100        3102   0.130940      0.636"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
